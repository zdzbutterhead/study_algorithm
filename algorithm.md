![Hello 算法](https://www.hello-algo.com/assets/covers/chapter_hello_algo.jpg)

## 第 0 章  前言

### 0.1  关于本书

![前言](https://www.hello-algo.com/assets/covers/chapter_preface.jpg)

算法犹如美妙的交响乐，每一行代码都像韵律般流淌。

![本书主要内容](https://www.hello-algo.com/chapter_preface/about_the_book.assets/hello_algo_mindmap.png)

### 0.2  如何使用本书

#### 0.2.1  行文风格约定

- 标题后标注 `*` 的是选读章节，内容相对困难。如果你的时间有限，可以先跳过。
- 专业术语会使用黑体（纸质版和 PDF 版）或添加下划线（网页版），例如数组（array）。建议记住它们，以便阅读文献。
- 重点内容和总结性语句会 **加粗**，这类文字值得特别关注。
- 有特指含义的词句会使用“引号”标注，以避免歧义。
- 当涉及编程语言之间不一致的名词时，本书均以 Python 为准，例如使用 `None` 来表示“空”。
- 本书部分放弃了编程语言的注释规范，以换取更加紧凑的内容排版。注释主要分为三种类型：标题注释、内容注释、多行注释。

#### 0.2.3  在代码实践中加深理解

本书的配套代码托管在 [GitHub 仓库](https://github.com/krahets/hello-algo)。如图 0-3 所示，**源代码附有测试样例，可一键运行**。

如果时间允许，**建议你参照代码自行敲一遍**。如果学习时间有限，请至少通读并运行所有代码。

与阅读代码相比，编写代码的过程往往能带来更多收获。**动手学，才是真的学**。

运行代码的前置工作主要分为三步。

**第一步：安装本地编程环境**。请参照附录所示的[教程](https://www.hello-algo.com/chapter_appendix/installation/)进行安装，如果已安装，则可跳过此步骤。

**第二步：克隆或下载代码仓库**。前往 [GitHub 仓库](https://github.com/krahets/hello-algo)。如果已经安装 [Git](https://git-scm.com/downloads) ，可以通过以下命令克隆本仓库：

```
git clone https://github.com/krahets/hello-algo.git
```

当然，你也可以在图 0-4 所示的位置，点击“Download ZIP”按钮直接下载代码压缩包，然后在本地解压即可。

[![克隆仓库与下载代码](https://www.hello-algo.com/chapter_preface/suggestions.assets/download_code.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/download_code.png)

图 0-4  克隆仓库与下载代码

**第三步：运行源代码**。如图 0-5 所示，对于顶部标有文件名称的代码块，我们可以在仓库的 `codes` 文件夹内找到对应的源代码文件。源代码文件可一键运行，将帮助你节省不必要的调试时间，让你能够专注于学习内容。

[![代码块与对应的源代码文件](https://www.hello-algo.com/chapter_preface/suggestions.assets/code_md_to_repo.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/code_md_to_repo.png)

图 0-5  代码块与对应的源代码文件

除了本地运行代码，**网页版还支持 Python 代码的可视化运行**（基于 [pythontutor](https://pythontutor.com/) 实现）。如图 0-6 所示，你可以点击代码块下方的“可视化运行”来展开视图，观察算法代码的执行过程；也可以点击“全屏观看”，以获得更好的阅览体验。

[![Python 代码的可视化运行](https://www.hello-algo.com/chapter_preface/suggestions.assets/pythontutor_example.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/pythontutor_example.png)

图 0-6  Python 代码的可视化运行

#### 0.2.5  算法学习路线

从总体上看，我们可以将学习数据结构与算法的过程划分为三个阶段。

1. **阶段一：算法入门**。我们需要熟悉各种数据结构的特点和用法，学习不同算法的原理、流程、用途和效率等方面的内容。
2. **阶段二：刷算法题**。建议从热门题目开刷，先积累至少 100 道题目，熟悉主流的算法问题。初次刷题时，“知识遗忘”可能是一个挑战，但请放心，这是很正常的。我们可以按照“艾宾浩斯遗忘曲线”来复习题目，通常在进行 3～5 轮的重复后，就能将其牢记在心。推荐的题单和刷题计划请见此 [GitHub 仓库](https://github.com/krahets/LeetCode-Book)。
3. **阶段三：搭建知识体系**。在学习方面，我们可以阅读算法专栏文章、解题框架和算法教材，以不断丰富知识体系。在刷题方面，可以尝试采用进阶刷题策略，如按专题分类、一题多解、一解多题等，相关的刷题心得可以在各个社区找到。

如图 0-8 所示，本书内容主要涵盖“阶段一”，旨在帮助你更高效地展开阶段二和阶段三的学习。

[![算法学习路线](https://www.hello-algo.com/chapter_preface/suggestions.assets/learning_route.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/learning_route.png)

图 0-8  算法学习路线

## 第 1 章  初识算法 

![初识算法](https://www.hello-algo.com/assets/covers/chapter_introduction.jpg)

### 1.1  算法无处不在

**例一：查字典**。在字典里，每个汉字都对应一个拼音，而字典是按照拼音字母顺序排列的。假设我们需要查找一个拼音首字母为 的字，通常会按照图 1-1 所示的方式实现。

1. 翻开字典约一半的页数，查看该页的首字母是什么，假设首字母为 。
2. 由于在拼音字母表中 位于 之后，所以排除字典前半部分，查找范围缩小到后半部分。
3. 不断重复步骤 `1.` 和步骤 `2.` ，直至找到拼音首字母为 的页码为止。

查字典这个小学生必备技能，实际上就是著名的“二分查找”算法。从数据结构的角度，我们可以把字典视为一个已排序的“数组”；从算法的角度，我们可以将上述查字典的一系列操作看作“二分查找”。

**例二：整理扑克**。我们在打牌时，每局都需要整理手中的扑克牌，使其从小到大排列，实现流程如图 1-2 所示。

1. 将扑克牌划分为“有序”和“无序”两部分，并假设初始状态下最左 1 张扑克牌已经有序。
2. 在无序部分抽出一张扑克牌，插入至有序部分的正确位置；完成后最左 2 张扑克已经有序。
3. 不断循环步骤 `2.` ，每一轮将一张扑克牌从无序部分插入至有序部分，直至所有扑克牌都有序。

[![扑克排序步骤](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/playing_cards_sorting.png)](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/playing_cards_sorting.png)

图 1-2  扑克排序步骤

上述整理扑克牌的方法本质上是“插入排序”算法，它在处理小型数据集时非常高效。许多编程语言的排序库函数中都有插入排序的身影。

**例三：货币找零**。假设我们在超市购买了 元的商品，给了收银员 元，则收银员需要找我们 元。他会很自然地完成如图 1-3 所示的思考。

1. 可选项是比31元面值更小的货币，包括1元、5元、10元、20元。
2. 从可选项中拿出最大的20元，剩余31-20=11元。
3. 从剩余可选项中拿出最大的10元，剩余11-10=1元。
4. 从剩余可选项中拿出最大的1元，剩余1-1=0元。
5. 完成找零，方案为20+10+1=31元。

[![货币找零过程](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/greedy_change.png)](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/greedy_change.png)

图 1-3  货币找零过程

在以上步骤中，我们每一步都采取当前看来最好的选择（尽可能用大面额的货币），最终得到了可行的找零方案。从数据结构与算法的角度看，这种方法本质上是“贪心”算法。

### 1.2  算法是什么

#### 1.2.1  算法定义

算法（algorithm）是在有限时间内解决特定问题的一组指令或操作步骤，它具有以下特性。

- 问题是明确的，包含清晰的输入和输出定义。
- 具有可行性，能够在有限步骤、时间和内存空间下完成。
- 各步骤都有确定的含义，在相同的输入和运行条件下，输出始终相同。

#### 1.2.2  数据结构定义

数据结构（data structure）是组织和存储数据的方式，涵盖数据内容、数据之间关系和数据操作方法，它具有以下设计目标。

- 空间占用尽量少，以节省计算机内存。
- 数据操作尽可能快速，涵盖数据访问、添加、删除、更新等。
- 提供简洁的数据表示和逻辑信息，以便算法高效运行。

**数据结构设计是一个充满权衡的过程**。如果想在某方面取得提升，往往需要在另一方面作出妥协。下面举两个例子。

- 链表相较于数组，在数据添加和删除操作上更加便捷，但牺牲了数据访问速度。
- 图相较于链表，提供了更丰富的逻辑信息，但需要占用更大的内存空间。

#### 1.2.3  数据结构与算法的关系

- 数据结构是算法的基石。数据结构为算法提供了结构化存储的数据，以及操作数据的方法。
- 算法为数据结构注入生命力。数据结构本身仅存储数据信息，结合算法才能解决特定问题。
- 算法通常可以基于不同的数据结构实现，但执行效率可能相差很大，选择合适的数据结构是关键。

[![数据结构与算法的关系](https://www.hello-algo.com/chapter_introduction/what_is_dsa.assets/relationship_between_data_structure_and_algorithm.png)](https://www.hello-algo.com/chapter_introduction/what_is_dsa.assets/relationship_between_data_structure_and_algorithm.png)

图 1-4  数据结构与算法的关系

数据结构与算法犹如拼装积木。一套积木，除了包含许多零件之外，还附有详细的组装说明书。我们按照说明书一步步操作，就能组装出精美的积木模型。

两者的详细对应关系如表 1-1 所示。

表 1-1  将数据结构与算法类比为拼装积木

| 数据结构与算法 | 拼装积木                                 |
| :------------- | :--------------------------------------- |
| 输入数据       | 未拼装的积木                             |
| 数据结构       | 积木组织形式，包括形状、大小、连接方式等 |
| 算法           | 把积木拼成目标形态的一系列操作步骤       |
| 输出数据       | 积木模型                                 |

值得说明的是，数据结构与算法是独立于编程语言的。正因如此，本书得以提供基于多种编程语言的实现。

在实际讨论时，我们通常会将“数据结构与算法”简称为“算法”。比如众所周知的 LeetCode 算法题目，实际上同时考查数据结构和算法两方面的知识。

我认为学算法（以及其他基础科目）的意义不是在于在工作中从零实现它，而是基于学到的知识，在解决问题时能够作出专业的反应和判断，从而提升工作的整体质量。

在工程领域中，大量问题是难以达到最优解的，许多问题只是被“差不多”地解决了。问题的难易程度一方面取决于问题本身的性质，另一方面也取决于观测问题的人的知识储备。人的知识越完备、经验越多，分析问题就会越深入，问题就能被解决得更优雅。

## 第 2 章  复杂度分析

![复杂度分析](https://www.hello-algo.com/assets/covers/chapter_complexity_analysis.jpg)

（第一眼以为三体的封面）

### 2.1  算法效率评估

在算法设计中，我们先后追求以下两个层面的目标。

1. **找到问题解法**：算法需要在规定的输入范围内可靠地求得问题的正确解。
2. **寻求最优解法**：同一个问题可能存在多种解法，我们希望找到尽可能高效的算法。

也就是说，在能够解决问题的前提下，算法效率已成为衡量算法优劣的主要评价指标，它包括以下两个维度。

- **时间效率**：算法运行时间的长短。
- **空间效率**：算法占用内存空间的大小。

效率评估方法主要分为两种：实际测试、理论估算。

#### 2.1.1  实际测试

假设我们现在有算法 `A` 和算法 `B` ，它们都能解决同一问题，现在需要对比这两个算法的效率。最直接的方法是找一台计算机，运行这两个算法，并监控记录它们的运行时间和内存占用情况。这种评估方式能够反映真实情况，但也存在较大的局限性。

一方面，**难以排除测试环境的干扰因素**。硬件配置会影响算法的性能表现。比如一个算法的并行度较高，那么它就更适合在多核 CPU 上运行，一个算法的内存操作密集，那么它在高性能内存上的表现就会更好。也就是说，算法在不同的机器上的测试结果可能是不一致的。这意味着我们需要在各种机器上进行测试，统计平均效率，而这是不现实的。

另一方面，**展开完整测试非常耗费资源**。随着输入数据量的变化，算法会表现出不同的效率。例如，在输入数据量较小时，算法 `A` 的运行时间比算法 `B` 短；而在输入数据量较大时，测试结果可能恰恰相反。因此，为了得到有说服力的结论，我们需要测试各种规模的输入数据，而这需要耗费大量的计算资源。

#### 2.1.2  理论估算

由于实际测试具有较大的局限性，我们可以考虑仅通过一些计算来评估算法的效率。这种估算方法被称为渐近复杂度分析（asymptotic complexity analysis），简称复杂度分析。

复杂度分析能够体现算法运行所需的时间和空间资源与输入数据大小之间的关系。**它描述了随着输入数据大小的增加，算法执行所需时间和空间的增长趋势**。这个定义有些拗口，我们可以将其分为三个重点来理解。

- “时间和空间资源”分别对应时间复杂度（time complexity）和空间复杂度（space complexity）。
- “随着输入数据大小的增加”意味着复杂度反映了算法运行效率与输入数据体量之间的关系。
- “时间和空间的增长趋势”表示复杂度分析关注的不是运行时间或占用空间的具体值，而是时间或空间增长的“快慢”。

**复杂度分析克服了实际测试方法的弊端**，体现在以下几个方面。

- 它无需实际运行代码，更加绿色节能。
- 它独立于测试环境，分析结果适用于所有运行平台。
- 它可以体现不同数据量下的算法效率，尤其是在大数据量下的算法性能。

#### Comment

作者认为：“时间效率”整体上指的就是算法在“时间”上的快慢，而非运行计算次数。还有人则说： 时间效率指算法运行的计算次数。

是的，原因很直接：我们提出时间效率这个概念，最终想要关心的是“时间”上的快慢，而不是“执行次数”。

执行次数更多和时间复杂度关联，它是反映时间效率的有效指标，但很有可能给出错误的结论。我们有时会遇到一种情况：算法 A 比算法 B 的时间复杂度更高（更差），但反而在给定数据下运行地更快（时间更短、效率更高）。一个典型的例子是插入排序 vs. 归并排序在数据量较小时的效率对比。

### 2.2  迭代与递归

在算法中，重复执行某个任务是很常见的，它与复杂度分析息息相关。因此，在介绍时间复杂度和空间复杂度之前，我们先来了解如何在程序中实现重复执行任务，即两种基本的程序控制结构：迭代、递归。

#### 2.2.1  迭代

迭代（iteration）是一种重复执行某个任务的控制结构。在迭代中，程序会在满足一定的条件下重复执行某段代码，直到这个条件不再满足。

1.  for 循环

`for` 循环是最常见的迭代形式之一，**适合在预先知道迭代次数时使用**。

2.  while 循环

与 `for` 循环类似，`while` 循环也是一种实现迭代的方法。在 `while` 循环中，程序每轮都会先检查条件，如果条件为真，则继续执行，否则就结束循环。

**`while` 循环比 `for` 循环的自由度更高**。在 `while` 循环中，我们可以自由地设计条件变量的初始化和更新步骤。

总的来说，**`for` 循环的代码更加紧凑，`while` 循环更加灵活**，两者都可以实现迭代结构。选择使用哪一个应该根据特定问题的需求来决定。

3. 嵌套循环

我们可以在一个循环结构内嵌套另一个循环结构

```python
def nested_for_loop(n: int) -> str:
    """双层 for 循环"""
    res = ""
    # 循环 i = 1, 2, ..., n-1, n
    for i in range(1, n + 1):
        # 循环 j = 1, 2, ..., n-1, n
        for j in range(1, n + 1):
            res += f"({i}, {j}), "
    return res
```

`res += f"({i}, {j}), "` 是一个使用 Python **f-strings**（格式化字符串）的赋值语句，用于动态构建字符串。

#### 2.2.2  递归

递归（recursion）是一种算法策略，通过函数调用自身来解决问题。它主要包含两个阶段。

1. **递**：程序不断深入地调用自身，通常传入更小或更简化的参数，直到达到“终止条件”。
2. **归**：触发“终止条件”后，程序从最深层的递归函数开始逐层返回，汇聚每一层的结果。

而从实现的角度看，递归代码主要包含三个要素。

1. **终止条件**：用于决定什么时候由“递”转“归”。
2. **递归调用**：对应“递”，函数调用自身，通常输入更小或更简化的参数。
3. **返回结果**：对应“归”，将当前递归层级的结果返回至上一层。

虽然从计算角度看，迭代与递归可以得到相同的结果，**但它们代表了两种完全不同的思考和解决问题的范式**。

- **迭代**：“自下而上”地解决问题。从最基础的步骤开始，然后不断重复或累加这些步骤，直到任务完成。
- **递归**：“自上而下”地解决问题。将原问题分解为更小的子问题，这些子问题和原问题具有相同的形式。接下来将子问题继续分解为更小的子问题，直到基本情况时停止（基本情况的解是已知的）。

1.  调用栈

递归函数每次调用自身时，系统都会为新开启的函数分配内存，以存储局部变量、调用地址和其他信息等。这将导致两方面的结果。

- 函数的上下文数据都存储在称为“栈帧空间”的内存区域中，直至函数返回后才会被释放。因此，**递归通常比迭代更加耗费内存空间**。
- 递归调用函数会产生额外的开销。**因此递归通常比循环的时间效率更低**。

在实际中，编程语言允许的递归深度通常是有限的，过深的递归可能导致栈溢出错误。

2. 尾递归

有趣的是，**如果函数在返回前的最后一步才进行递归调用**，则该函数可以被编译器或解释器优化，使其在空间效率上与迭代相当。这种情况被称为尾递归（tail recursion）。

- **普通递归**：当函数返回到上一层级的函数后，需要继续执行代码，因此系统需要保存上一层调用的上下文。
- **尾递归**：递归调用是函数返回前的最后一个操作，这意味着函数返回到上一层级后，无须继续执行其他操作，因此系统无须保存上一层函数的上下文。

```python
# 普通递归
def recur(n: int) -> int:
    """递归"""
    # 终止条件
    if n == 1:
        return 1
    # 递：递归调用
    res = recur(n - 1)
    # 归：返回结果
    return n + res
```

![求和函数的递归过程](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/recursion_sum.png)

```python
# 尾递归
def tail_recur(n, res):
    # 终止条件
    if n == 0:
        return res
    # 尾递归调用
    return tail_recur(n - 1, res + n)

# 不属于尾递归
def recursion(n:int)->int:
    if n == 1:
        return 1
    else:
        return n + recursion(n-1)
# 该递归函数不属于尾递归。尾递归的定义是：递归调用是函数的最后一个操作，且返回值直接传递给上层。而你的代码中，递归调用 recursion(n-1) 之后还需要执行加法操作 n + ...，因此不符合尾递归的条件。
'''
尾递归通常需要通过累加器参数来保存中间结果，避免递归返回后执行额外操作
累加器 acc：用于保存当前的累加和。
递归调用：直接返回 tail_recursion(...)，无后续操作。
'''
```

![尾递归过程](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/tail_recursion_sum.png)

> 请注意，许多编译器或解释器并不支持尾递归优化。例如，Python 默认不支持尾递归优化，因此即使函数是尾递归形式，仍然可能会遇到栈溢出问题。

3. 递归树

当处理与“分治”相关的算法问题时，递归往往比迭代的思路更加直观、代码更加易读。

```python
def fib(n: int) -> int:
    """斐波那契数列：递归"""
    # 终止条件 f(1) = 0, f(2) = 1
    if n == 1 or n == 2:
        return n - 1
    # 递归调用 f(n) = f(n-1) + f(n-2)
    res = fib(n - 1) + fib(n - 2)
    # 返回结果 f(n)
    return res
```

观察以上代码，我们在函数内递归调用了两个函数，**这意味着从一个调用产生了两个调用分支**。如图 2-6 所示，这样不断递归调用下去，最终将产生一棵层数为 的递归树（recursion tree）。

![斐波那契数列的递归树](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/recursion_tree.png)

图 2-6  斐波那契数列的递归树

递归的执行顺序是**深度优先、先左后右的 “后序处理”**

从本质上看，递归体现了“将问题分解为更小子问题”的思维范式，这种分治策略至关重要。

- 从算法角度看，搜索、排序、回溯、分治、动态规划等许多重要算法策略直接或间接地应用了这种思维方式。
- 从数据结构角度看，递归天然适合处理链表、树和图的相关问题，因为它们非常适合用分治思想进行分析。

#### 2.2.3  两者对比

表 2-1  迭代与递归特点对比

|          | 迭代                                   | 递归                                                         |
| :------- | :------------------------------------- | :----------------------------------------------------------- |
| 实现方式 | 循环结构                               | 函数调用自身                                                 |
| 时间效率 | 效率通常较高，无函数调用开销           | 每次函数调用都会产生开销                                     |
| 内存使用 | 通常使用固定大小的内存空间             | 累积函数调用可能使用大量的栈帧空间                           |
| 适用问题 | 适用于简单循环任务，代码直观、可读性好 | 适用于子问题分解，如树、图、分治、回溯等，代码结构简洁、清晰 |

那么，迭代和递归具有什么内在联系呢？以上述递归函数为例，求和操作在递归的“归”阶段进行。这意味着最初被调用的函数实际上是最后完成其求和操作的，**这种工作机制与栈的“先入后出”原则异曲同工**。

事实上，“调用栈”和“栈帧空间”这类递归术语已经暗示了递归与栈之间的密切关系。

1. **递**：当函数被调用时，系统会在“调用栈”上为该函数分配新的栈帧，用于存储函数的局部变量、参数、返回地址等数据。
2. **归**：当函数完成执行并返回时，对应的栈帧会被从“调用栈”上移除，恢复之前函数的执行环境。

尽管迭代和递归在很多情况下可以互相转化，但不一定值得这样做，有以下两点原因。

- 转化后的代码可能更加难以理解，可读性更差。
- 对于某些复杂问题，模拟系统调用栈的行为可能非常困难。

总之，**选择迭代还是递归取决于特定问题的性质**。在编程实践中，权衡两者的优劣并根据情境选择合适的方法至关重要。

#### Comment

事实上 [所有的递归都能被写成迭代](https://stackoverflow.com/questions/931762/can-every-recursion-be-converted-into-iteration) 。

**普通递归**和**尾递归**这两个概念有点不太好理解，我是不是可以这么想：

- 重要区别有两个：【什么时候**返回**】，【什么时候**计算**】

1. 普通递归，是一直**找到最底，找到了然后才逐层计算并返回结果**，需要记录过程数据📝

> 每次递归调用都会产生一个新的函数实例，每个实例都需要等待其子实例返回结果后才能进行计算并返回自己的结果。

> 这样一来，所有的函数实例都需要在内存中保持活跃状态，直到最底层的实例计算并返回结果，然后逐级传回。

> 因此，需要大量的内存空间来维护这个调用栈。

1. 尾递归，可以**边计算边返回**，不需要记录过程数据📝

> 由于递归调用是函数的最后一步操作，因此在进行递归调用时，不需要保留当前函数实例的状态，可以直接使用新的函数实例替换掉当前实例。

> 无论递归多少次，都只需要一个函数实例的内存空间，大大减少了内存消耗。这也是为什么尾递归对于处理大规模数据或深度递归时具有优势的原因。

当然，这里的`递归调用是函数的最后一步操作`我一开始也有点懵。

如果拿普通递归的代码 ：`return n + res` 和尾递归的代码`return tail_recur(n - 1, res + n)` 单独抽出来理解

- `return n + res` 的 res 是调用递归，整个大函数在调用递归之后还在”等待“，等res回来，要和 n 相加。也就是说，递归调用是函数操作的倒数第二步。
- 而`return tail_recur(n - 1, res + n)` 的 tail_recur(n - 1, res + n)是递归调用，直接就是返回的最后一步操作，对于函数来说，只需要返回这个调用就行，不需要做其他的任何操作，返回之后就结束了，和当前的函数没有任何关系了，可以“释放”了

然后我结合 ChatGPT 给到的类比做了一个优化。

递归这个事情，有点像**拆积木和堆积木**。把 `A 地`的积木拆开，然后**按照顺序**堆到 `B 地`。

1. "递归调用"对应于"拆积木"的动作
2. "返回结果"对应于"堆积木"的动作。
3. 普通递归：把 1、2、3 层的积木先拆开，按顺序摆在桌子上（记住顺序），然后找到最后一层，再开始堆。
4. 尾递归：一边拆积木，一边堆积木，不许要记住顺序，就拆完就堆。

### 2.3  时间复杂度

运行时间可以直观且准确地反映算法的效率。如果我们想准确预估一段代码的运行时间，应该如何操作呢？

1. **确定运行平台**，包括硬件配置、编程语言、系统环境等，这些因素都会影响代码的运行效率。
2. **评估各种计算操作所需的运行时间**，例如加法操作 `+` 需要 1 ns ，乘法操作 `*` 需要 10 ns ，打印操作 `print()` 需要 5 ns 等。
3. **统计代码中所有的计算操作**，并将所有操作的执行时间求和，从而得到运行时间。

但实际上，**统计算法的运行时间既不合理也不现实**。首先，我们不希望将预估时间和运行平台绑定，因为算法需要在各种不同的平台上运行。其次，我们很难获知每种操作的运行时间，这给预估过程带来了极大的难度。

#### 2.3.1  统计时间增长趋势

时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**。

```python
# 算法 A 的时间复杂度：常数阶
def algorithm_A(n: int):
    print(0)
# 算法 B 的时间复杂度：线性阶
def algorithm_B(n: int):
    for _ in range(n):
        print(0)
# 算法 C 的时间复杂度：常数阶
def algorithm_C(n: int):
    for _ in range(1000000):
        print(0)
```

图 2-7 展示了以上三个算法函数的时间复杂度。

- 算法 `A` 只有 个打印操作，算法运行时间不随着 增大而增长。我们称此算法的时间复杂度为“常数阶”。
- 算法 `B` 中的打印操作需要循环 次，算法运行时间随着 增大呈线性增长。此算法的时间复杂度被称为“线性阶”。
- 算法 `C` 中的打印操作需要循环 次，虽然运行时间很长，但它与输入数据大小 无关。因此 `C` 的时间复杂度和 `A` 相同，仍为“常数阶”。

[![算法 A、B 和 C 的时间增长趋势](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_simple_example.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_simple_example.png)

图 2-7  算法 A、B 和 C 的时间增长趋势

相较于直接统计算法的运行时间，时间复杂度分析有哪些特点呢？

- **时间复杂度能够有效评估算法效率**。例如，算法 `B` 的运行时间呈线性增长，在n>1时比算法 `A` 更慢，在n>1000000时比算法 `C` 更慢。事实上，只要输入数据大小n足够大，复杂度为“常数阶”的算法一定优于“线性阶”的算法，这正是时间增长趋势的含义。
- **时间复杂度的推算方法更简便**。显然，运行平台和计算操作类型都与算法运行时间的增长趋势无关。因此在时间复杂度分析中，我们可以简单地将所有计算操作的执行时间视为相同的“单位时间”，从而将“计算操作运行时间统计”简化为“计算操作数量统计”，这样一来估算难度就大大降低了。
- **时间复杂度也存在一定的局限性**。例如，尽管算法 `A` 和 `C` 的时间复杂度相同，但实际运行时间差别很大。同样，尽管算法 `B` 的时间复杂度比 `C` 高，但在输入数据大小n较小时，算法 `B` 明显优于算法 `C` 。对于此类情况，我们时常难以仅凭时间复杂度判断算法效率的高低。当然，尽管存在上述问题，复杂度分析仍然是评判算法效率最有效且常用的方法。

#### 2.3.2  函数渐近上界

```python
def algorithm(n: int):
    a = 1      # +1
    a = a + 1  # +1
    a = a * 2  # +1
    # 循环 n 次
    for i in range(n):  # +1
        print(0)        # +1
```

设算法的操作数量是一个关于输入数据大小n的函数，记为T(n)，则以上函数的操作数量为：T(n)=3+2n


T(n)是一次函数，说明其运行时间的增长趋势是线性的，因此它的时间复杂度是线性阶。

我们将线性阶的时间复杂度记为O(n)，这个数学符号称为大O记号（big-O notation），表示函数T(n)的渐近上界（asymptotic upper bound）。

时间复杂度分析本质上是计算“操作数量T(n)”的渐近上界，它具有明确的数学定义。

如图 2-8 所示，计算渐近上界就是寻找一个函数f(n)，使得当n趋向于无穷大时，T(n)和f(n)处于相同的增长级别，仅相差一个常数系数c。

[![函数的渐近上界](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/asymptotic_upper_bound.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/asymptotic_upper_bound.png)

图 2-8  函数的渐近上界

#### 2.3.3  推算方法

1. 第一步：统计操作数量(其实就是看最深层循环次数或递归次数)

   针对代码，逐行从上到下计算即可。然而，由于上述c*f(n)中的常数系数c可以取任意大小，**因此操作数量T(n)中的各种系数、常数项都可以忽略**。根据此原则，可以总结出以下计数简化技巧。

   1. **忽略T(n)中的常数**。因为它们都与n无关，所以对时间复杂度不产生影响。
   2. **省略所有系数**。例如，循环2n次、5n+1次等，都可以简化记为n次，因为n前面的系数对时间复杂度没有影响。
   3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 `1.` 点和第 `2.` 点的技巧。

2. 第二步：判断渐近上界

   **时间复杂度由T(n)中最高阶的项来决定**。这是因为在n趋于无穷大时，最高阶的项将发挥主导作用，其他项的影响都可以忽略。

#### 2.3.4  常见类型

设输入数据大小为n，常见的时间复杂度类型如图 2-9 所示（按照从低到高的顺序排列）。

O(1)<O($log n$)<O(n)<O($nlog n$)<O($n^2$)<O($2^n$)<O(n!)

常数阶<对数阶<线性阶<线性对数阶<平方阶<指数阶<阶乘阶

![常见的时间复杂度类型](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250715200425838.png)

图 2-9  常见的时间复杂度类型

1. 常数阶O(1)

   常数阶的操作数量与输入数据大小 无关，即不随着 的变化而变化。

2.  线性阶O(n)

    线性阶的操作数量相对于输入数据大小 以线性级别增长。线性阶通常出现在单层循环中：

3.  平方阶O($n^2$)

    平方阶的操作数量相对于输入数据大小n以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环的时间复杂度都为O(n)，因此总体的时间复杂度为O($n^2$)

4.  指数阶O($2^n$)

    生物学的“细胞分裂”是指数阶增长的典型例子：初始状态为1个细胞，分裂一轮后变为2个，分裂两轮后变为4个，以此类推，分裂n轮后有$2^n$个细胞。

    图 2-11 和以下代码模拟了细胞分裂的过程，时间复杂度为O($2^n$) 。请注意，输入n表示分裂轮数，返回值 `count` 表示总分裂次数。

    ```python
    def exponential(n: int) -> int:
        """指数阶（循环实现）"""
        count = 0
        base = 1
        # 细胞每轮一分为二，形成数列 1, 2, 4, 8, ..., 2^(n-1)
        for _ in range(n):
            for _ in range(base):
                count += 1
            base *= 2
        # count = 1 + 2 + 4 + 8 + .. + 2^(n-1) = 2^n - 1
        return count
    ```

    [![指数阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_exponential.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_exponential.png)

    图 2-11  指数阶的时间复杂度

    在实际算法中，指数阶常出现于递归函数中。例如在以下代码中，其递归地一分为二，经过 次分裂后停止：

    ```python
    def exp_recur(n: int) -> int:
        """指数阶（递归实现）"""
        if n == 1:
            return 1
        return exp_recur(n - 1) + exp_recur(n - 1) + 1
    ```

    指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。

5.  对数阶O($log n$)

    与指数阶相反，对数阶反映了“每轮缩减到一半”的情况。设输入数据大小为n，由于每轮缩减到一半，因此循环次数是$\log_2 n$，即$2^n$的反函数。

    图 2-12 和以下代码模拟了“每轮缩减到一半”的过程，时间复杂度为O($log_2 n$)，简记为O($log_ n$)：

    ```python
    def logarithmic(n: int) -> int:
        """对数阶（循环实现）"""
        count = 0
        while n > 1:
            n = n / 2
            count += 1
        return count
    ```

    ![对数阶的时间复杂度](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714165738224.png)

    图 2-12  对数阶的时间复杂度

    与指数阶类似，对数阶也常出现于递归函数中。以下代码形成了一棵高度为$log_2 n$的递归树

    ```python
    def log_recur(n: int) -> int:
        """对数阶（递归实现）"""
        if n <= 1:
            return 0
        return log_recur(n / 2) + 1
    ```

    对数阶常出现于基于分治策略的算法中，体现了“一分为多”和“化繁为简”的算法思想。它增长缓慢，是仅次于常数阶的理想的时间复杂度。

    ![image-20250714165946651](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714165946651.png)

6.  线性对数阶O($nlog n$)

    线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为O($log n$)和O(n)。

    ```python
    def linear_log_recur(n: int) -> int:
        """线性对数阶"""
        if n <= 1:
            return 1
        # 一分为二，子问题的规模减小一半
        count = linear_log_recur(n // 2) + linear_log_recur(n // 2)
        # 当前子问题包含 n 个操作
        for _ in range(n):
            count += 1
        return count
    ```

    图 2-13 展示了线性对数阶的生成方式。二叉树的每一层的操作总数都为n，树共有$log_2 n+1$层，因此时间复杂度为O($nlog n$)。

    [![线性对数阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_logarithmic_linear.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_logarithmic_linear.png)

    图 2-13  线性对数阶的时间复杂度

    主流排序算法的时间复杂度通常为O($nlog n$)，例如快速排序、归并排序、堆排序等。

7.  阶乘阶O(n!)

    阶乘阶对应数学上的“全排列”问题。给定n个互不重复的元素，求其所有可能的排列方案，方案数量为：
    $$
    n!=n*(n-1)*(n-2)*···*2*1
    $$
    阶乘通常使用递归实现。如图 2-14 和以下代码所示，第一层分裂出n个，第二层分裂出n-1个，以此类推，直至第n层时停止分裂

    ```python
    def factorial_recur(n: int) -> int:
        """阶乘阶（递归实现）"""
        if n == 0:
            return 1
        count = 0
        # 从 1 个分裂出 n 个
        for _ in range(n):
            count += factorial_recur(n - 1)
        return count
    ```

    [![阶乘阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_factorial.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_factorial.png)

    图 2-14  阶乘阶的时间复杂度

    请注意，因为当$n>=4$时恒有$n!>2^n$ ，所以阶乘阶比指数阶增长得更快，在n较大时也是不可接受的。

#### 2.3.5  最差、最佳、平均时间复杂度

“最差时间复杂度”对应函数渐近上界，使用大O记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用Ω记号表示：

值得说明的是，我们在实际中很少使用最佳时间复杂度，因为通常只有在很小概率下才能达到，可能会带来一定的误导性。**而最差时间复杂度更为实用，因为它给出了一个效率安全值**，让我们可以放心地使用算法。

从上述示例可以看出，最差时间复杂度和最佳时间复杂度只出现于“特殊的数据分布”，这些情况的出现概率可能很小，并不能真实地反映算法运行效率。相比之下，**平均时间复杂度可以体现算法在随机输入数据下的运行效率**，用Θ记号来表示。

对于部分算法，我们可以简单地推算出随机数据分布下的平均情况。比如上述示例，由于输入数组是被打乱的，因此元素1出现在任意索引的概率都是相等的，那么算法的平均循环次数就是数组长度的一半n/2，平均时间复杂度为Θ(n/2)=Θ(n) 。

但对于较为复杂的算法，计算平均时间复杂度往往比较困难，因为很难分析出在数据分布下的整体数学期望。在这种情况下，我们通常使用最差时间复杂度作为算法效率的评判标准。

![为什么很少看到Θ符号？](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714171708044.png)

### 2.4  空间复杂度

空间复杂度（space complexity）用于衡量算法占用内存空间随着数据量变大时的增长趋势。这个概念与时间复杂度非常类似，只需将“运行时间”替换为“占用内存空间”。

#### 2.4.1  算法相关空间

算法在运行过程中使用的内存空间主要包括以下几种。

- **输入空间**：用于存储算法的输入数据。
- **暂存空间**：用于存储算法在运行过程中的变量、对象、函数上下文等数据。
- **输出空间**：用于存储算法的输出数据。

一般情况下，空间复杂度的统计范围是“暂存空间”加上“输出空间”。

暂存空间可以进一步划分为三个部分。

- **暂存数据**：用于保存算法运行过程中的各种常量、变量、对象等。
- **栈帧空间**：用于保存调用函数的上下文数据。系统在每次调用函数时都会在栈顶部创建一个栈帧，函数返回后，栈帧空间会被释放。
- **指令空间**：用于保存编译后的程序指令，在实际统计中通常忽略不计。

在分析一段程序的空间复杂度时，**我们通常统计暂存数据、栈帧空间和输出数据三部分**，如图 2-15 所示。

[![算法使用的相关空间](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_types.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_types.png)

图 2-15  算法使用的相关空间

#### 2.4.2  推算方法

空间复杂度的推算方法与时间复杂度大致相同，只需将统计对象从“操作数量”转为“使用空间大小”。

而与时间复杂度不同的是，**我们通常只关注最差空间复杂度**。这是因为内存空间是一项硬性要求，我们必须确保在所有输入数据下都有足够的内存空间预留。

观察以下代码，最差空间复杂度中的“最差”有两层含义。

1. **以最差输入数据为准**：当n<10时，空间复杂度为O(1)；但当n>10时，初始化的数组 `nums` 占用O(n)空间，因此最差空间复杂度为O(n)。
2. **以算法运行中的峰值内存为准**：例如，程序在执行最后一行之前，占用O(1)空间；当初始化数组 `nums` 时，程序占用O(n)空间，因此最差空间复杂度为O(n)。

```python
def algorithm(n: int):
    a = 0               # O(1)
    b = [0] * 10000     # O(1)
    if n > 10:
        nums = [0] * n  # O(n)
```

**在递归函数中，需要注意统计栈帧空间**。观察以下代码：

```python
def function() -> int:
    # 执行某些操作
    return 0

def loop(n: int):
    """循环的空间复杂度为 O(1)"""
    for _ in range(n):
        function()

def recur(n: int):
    """递归的空间复杂度为 O(n)"""
    if n == 1:
        return
    return recur(n - 1)
```

函数 `loop()` 和 `recur()` 的时间复杂度都为O(n)，但空间复杂度不同。

- 函数 `loop()` 在循环中调用了n次 `function()` ，每轮中的 `function()` 都返回并释放了栈帧空间，因此空间复杂度仍为O(1)。
- 递归函数 `recur()` 在运行过程中会同时存在n个未返回的 `recur()` ，从而占用O(n)的栈帧空间。

#### 2.4.3  常见类型

设输入数据大小为n，图 2-16 展示了常见的空间复杂度类型（从低到高排列）。

O(1)<O($log_2 n$)<O(n)<O($n^2$)<O($2^n$)

常数阶 < 对数阶 < 线性阶 < 平方阶 < 指数阶

![常见的空间复杂度类型](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_common_types.png)

图 2-16  常见的空间复杂度类型

1. 常数阶O(1)

   常数阶常见于数量与输入数据大小n无关的常量、变量、对象。

   需要注意的是，在循环中初始化变量或调用函数而占用的内存，在进入下一循环后就会被释放，因此不会累积占用空间，空间复杂度仍为O(1)： 

   ```python
   def function() -> int:
       """函数"""
       # 执行某些操作
       return 0
   
   def constant(n: int):
       """常数阶"""
       # 常量、变量、对象占用 O(1) 空间
       a = 0
       nums = [0] * 10000
       node = ListNode(0)
       # 循环中的变量占用 O(1) 空间
       for _ in range(n):
           c = 0
       # 循环中的函数占用 O(1) 空间
       for _ in range(n):
           function()
   ```

2. 线性阶O(n)

   线性阶常见于元素数量与n成正比的数组、链表、栈、队列等：

   ```python
   def linear(n: int):
       """线性阶"""
       # 长度为 n 的列表占用 O(n) 空间
       nums = [0] * n
       # 长度为 n 的哈希表占用 O(n) 空间
       hmap = dict[int, str]()
       for i in range(n):
           hmap[i] = str(i)
   ```

   如图 2-17 所示，此函数的递归深度为n，即同时存在n个未返回的 `linear_recur()` 函数，使用O(n)大小的栈帧空间：

   ```python
   def linear_recur(n: int):
       """线性阶（递归实现）"""
       print("递归 n =", n)
       if n == 1:
           return
       linear_recur(n - 1)
   ```

   ![递归函数产生的线性阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_linear.png)

   图 2-17  递归函数产生的线性阶空间复杂度

3. 平方阶O($n^2$)

   ```python
   def quadratic(n: int):
       """平方阶"""
       # 二维列表占用 O(n^2) 空间
       num_matrix = [[0] * n for _ in range(n)]
   ```

   如图 2-18 所示，该函数的递归深度为n，在每个递归函数中都初始化了一个数组，长度分别为n、n-1、...、2、1 ，平均长度为n/2，因此总体占用O($n^2$)空间：

   ```python
   def quadratic_recur(n: int) -> int:
       """平方阶（递归实现）"""
       if n <= 0:
           return 0
       # 数组 nums 长度为 n, n-1, ..., 2, 1
       nums = [0] * n
       return quadratic_recur(n - 1)
   ```

   [![递归函数产生的平方阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_quadratic.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_quadratic.png)

   图 2-18  递归函数产生的平方阶空间复杂度

4. 指数阶O($2^n$)

   指数阶常见于二叉树。观察图 2-19 ，层数为n的“满二叉树”的节点数量为$2^n-1$，占用O($2^n$)空间：

   ```python
   def build_tree(n: int) -> TreeNode | None:
       """指数阶（建立满二叉树）"""
       if n == 0:
           return None
       root = TreeNode(0)
       root.left = build_tree(n - 1)
       root.right = build_tree(n - 1)
       return root
   ```

   [![满二叉树产生的指数阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_exponential.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_exponential.png)

   图 2-19  满二叉树产生的指数阶空间复杂度

5. 对数阶O($log n$)

   对数阶常见于分治算法。例如归并排序，输入长度为n的数组，每轮递归将数组从中点处划分为两半，形成高度为$log n$的递归树，使用O($log n$)栈帧空间。

   再例如将数字转化为字符串，输入一个正整数n，它的位数为$⌊log_{10}n⌋+1$，即对应字符串长度为$⌊log_{10}n⌋+1$，因此空间复杂度为 O($log_{10}n+1$)=O($log n$)。

#### 2.4.4  权衡时间与空间

理想情况下，我们希望算法的时间复杂度和空间复杂度都能达到最优。然而在实际情况中，同时优化时间复杂度和空间复杂度通常非常困难。

**降低时间复杂度通常需要以提升空间复杂度为代价，反之亦然**。我们将牺牲内存空间来提升算法运行速度的思路称为“以空间换时间”；反之，则称为“以时间换空间”。

选择哪种思路取决于我们更看重哪个方面。在大多数情况下，时间比空间更宝贵，因此“以空间换时间”通常是更常用的策略。当然，在数据量很大的情况下，控制空间复杂度也非常重要。

### 2.5  Q&A

**Q**：尾递归的空间复杂度是O(1)吗？

理论上，尾递归函数的空间复杂度可以优化至O(1)。不过绝大多数编程语言（例如 Java、Python、C++、Go、C# 等）不支持自动优化尾递归，因此通常认为空间复杂度是O(n)。

**Q**：函数和方法这两个术语的区别是什么？

函数（function）可以被独立执行，所有参数都以显式传递。方法（method）与一个对象关联，被隐式传递给调用它的对象，能够对类的实例中包含的数据进行操作。

下面以几种常见的编程语言为例来说明。

- C 语言是过程式编程语言，没有面向对象的概念，所以只有函数。但我们可以通过创建结构体（struct）来模拟面向对象编程，与结构体相关联的函数就相当于其他编程语言中的方法。
- Java 和 C# 是面向对象的编程语言，代码块（方法）通常作为某个类的一部分。静态方法的行为类似于函数，因为它被绑定在类上，不能访问特定的实例变量。
- C++ 和 Python 既支持过程式编程（函数），也支持面向对象编程（方法）。

**Q**：图解“常见的空间复杂度类型”反映的是否是占用空间的绝对大小？

不是，该图展示的是空间复杂度，其反映的是增长趋势，而不是占用空间的绝对大小。

假设取n=8，你可能会发现每条曲线的值与函数对应不上。这是因为每条曲线都包含一个常数项，用于将取值范围压缩到一个视觉舒适的范围内。

在实际中，因为我们通常不知道每个方法的“常数项”复杂度是多少，所以一般无法仅凭复杂度来选择n=8之下的最优解法。但对于n=8^5就很好选了，这时增长趋势已经占主导了。

## 第 3 章  数据结构

![数据结构](https://www.hello-algo.com/assets/covers/chapter_data_structure.jpg)

### 3.1  数据结构分类

常见的数据结构包括数组、链表、栈、队列、哈希表、树、堆、图，它们可以从“逻辑结构”和“物理结构”两个维度进行分类。

#### 3.1.1  逻辑结构：线性与非线性

**逻辑结构揭示了数据元素之间的逻辑关系**。在数组和链表中，数据按照一定顺序排列，体现了数据之间的线性关系；而在树中，数据从顶部向下按层次排列，表现出“祖先”与“后代”之间的派生关系；图则由节点和边构成，反映了复杂的网络关系。

如图 3-1 所示，逻辑结构可分为“线性”和“非线性”两大类。线性结构比较直观，指数据在逻辑关系上呈线性排列；非线性结构则相反，呈非线性排列。

- **线性数据结构**：数组、链表、栈、队列、哈希表，元素之间是一对一的顺序关系。
- **非线性数据结构**：树、堆、图、哈希表。

![线性数据结构与非线性数据结构](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_logic_structure.png)

图 3-1  线性数据结构与非线性数据结构

#### 3.1.2  物理结构：连续与分散

**当算法程序运行时，正在处理的数据主要存储在内存中**。图 3-2 展示了一个计算机内存条，其中每个黑色方块都包含一块内存空间。我们可以将内存想象成一个巨大的 Excel 表格，其中每个单元格都可以存储一定大小的数据。

**系统通过内存地址来访问目标位置的数据**。如图 3-2 所示，计算机根据特定规则为表格中的每个单元格分配编号，确保每个内存空间都有唯一的内存地址。有了这些地址，程序便可以访问内存中的数据。

[![内存条、内存空间、内存地址](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/computer_memory_location.png)](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/computer_memory_location.png)

图 3-2  内存条、内存空间、内存地址

> 值得说明的是，将内存比作 Excel 表格是一个简化的类比，实际内存的工作机制比较复杂，涉及地址空间、内存管理、缓存机制、虚拟内存和物理内存等概念。

内存是所有程序的共享资源，当某块内存被某个程序占用时，则通常无法被其他程序同时使用了。**因此在数据结构与算法的设计中，内存资源是一个重要的考虑因素**。比如，算法所占用的内存峰值不应超过系统剩余空闲内存；如果缺少连续大块的内存空间，那么所选用的数据结构必须能够存储在分散的内存空间内。

如图 3-3 所示，**物理结构反映了数据在计算机内存中的存储方式**，可分为连续空间存储（数组）和分散空间存储（链表）。物理结构从底层决定了数据的访问、更新、增删等操作方法，两种物理结构在时间效率和空间效率方面呈现出互补的特点。

[![连续空间存储与分散空间存储](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_phisical_structure.png)](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_phisical_structure.png)

图 3-3  连续空间存储与分散空间存储

值得说明的是，**所有数据结构都是基于数组、链表或二者的组合实现的**。例如，栈和队列既可以使用数组实现，也可以使用链表实现；而哈希表的实现可能同时包含数组和链表。

- **基于数组可实现**：栈、队列、哈希表、树、堆、图、矩阵、张量（维度 的数组）等。
- **基于链表可实现**：栈、队列、哈希表、树、堆、图等。

链表在初始化后，仍可以在程序运行过程中对其长度进行调整，因此也称“动态数据结构”。数组在初始化后长度不可变，因此也称“静态数据结构”。值得注意的是，数组可通过重新分配内存实现长度变化，从而具备一定的“动态性”。

#### Comment

假设我们初始化一个很大的数组。在虚拟内存中，数组的内存空间是连续的。这样我们才能通过首元素地址加偏移量的方式来访问数组中的任何元素。

然而，在物理内存中，数组可能并不连续。虚拟内存到物理内存的映射涉及到分页（paging）技术。操作系统通过分页系统，将虚拟内存和物理内存都划分为大小相等的页。每个虚拟页都可以单独映射到物理内存中的任意一页。所以，一个大的数组（占据多个虚拟内存页）在物理内存中可能是分散的，每个虚拟页在物理内存中的位置可能不连续。

值得强调的是，虽然物理内存中的连续性可能会对性能有影响，但在实际应用中，这通常并不是主要的性能瓶颈。现代的计算机系统已经采用了许多优化技术，例如缓存、预取等，以尽可能减小这种影响。

### 3.2  基本数据类型

当谈及计算机中的数据时，我们会想到文本、图片、视频、语音、3D 模型等各种形式。尽管这些数据的组织形式各异，但它们都由各种基本数据类型构成。

**基本数据类型是 CPU 可以直接进行运算的类型**，在算法中直接被使用，主要包括以下几种。

- 整数类型 `byte`、`short`、`int`、`long` 。
- 浮点数类型 `float`、`double` ，用于表示小数。
- 字符类型 `char` ，用于表示各种语言的字母、标点符号甚至表情符号等。
- 布尔类型 `bool` ，用于表示“是”与“否”判断。

**基本数据类型以二进制的形式存储在计算机中**。一个二进制位即为1比特。在绝大多数现代操作系统中，1字节（byte）由8比特（bit）组成。

基本数据类型的取值范围取决于其占用的空间大小。下面以 Java 为例。

- 整数类型 `byte` 占用1字节 =8比特 ，可以表示$2^8$个数字。
- 整数类型 `int` 占用4字节 =32比特 ，可以表示$2^{32}$个数字。

表 3-1 列举了 Java 中各种基本数据类型的占用空间、取值范围和默认值。此表格无须死记硬背，大致理解即可，需要时可以通过查表来回忆。

表 3-1  基本数据类型的占用空间和取值范围

![基本数据类型的占用空间和取值范围](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717184144152.png)

请注意，表 3-1 针对的是 Java 的基本数据类型的情况。每种编程语言都有各自的数据类型定义，它们的占用空间、取值范围和默认值可能会有所不同。

- 在 Python 中，整数类型 `int` 可以是任意大小，只受限于可用内存；浮点数 `float` 是双精度 64 位；没有 `char` 类型，单个字符实际上是长度为 1 的字符串 `str` 。
- C 和 C++ 未明确规定基本数据类型的大小，而因实现和平台各异。表 3-1 遵循 LP64 [数据模型](https://en.cppreference.com/w/cpp/language/types#Properties)，其用于包括 Linux 和 macOS 在内的 Unix 64 位操作系统。
- 字符 `char` 的大小在 C 和 C++ 中为 1 字节，在大多数编程语言中取决于特定的字符编码方法，详见“字符编码”章节。
- 即使表示布尔量仅需 1 位（0或1），它在内存中通常也存储为 1 字节。这是因为现代计算机 CPU 通常将 1 字节作为最小寻址内存单元。

那么，基本数据类型与数据结构之间有什么联系呢？我们知道，数据结构是在计算机中组织与存储数据的方式。这句话的主语是“结构”而非“数据”。

如果想表示“一排数字”，我们自然会想到使用数组。这是因为数组的线性结构可以表示数字的相邻关系和顺序关系，但至于存储的内容是整数 `int`、小数 `float` 还是字符 `char` ，则与“数据结构”无关。

换句话说，**基本数据类型提供了数据的“内容类型”，而数据结构提供了数据的“组织方式”**。例如以下代码，我们用相同的数据结构（数组）来存储与表示不同的基本数据类型，包括 `int`、`float`、`char`、`bool` 等。

```python
# 使用多种基本数据类型来初始化数组
numbers: list[int] = [0] * 5
decimals: list[float] = [0.0] * 5
# Python 的字符实际上是长度为 1 的字符串
characters: list[str] = ['0'] * 5
bools: list[bool] = [False] * 5
# Python 的列表可以自由存储各种基本数据类型和对象引用
data = [0, 0.0, 'a', False, ListNode(0)]
```

### 3.3  数字编码 *

#### 3.3.1  原码、反码和补码

在上一节的表格中我们发现，所有整数类型能够表示的负数都比正数多一个，例如 `byte` 的取值范围是[-128,127]。这个现象比较反直觉，它的内在原因涉及原码、反码、补码的相关知识。

首先需要指出，**数字是以“补码”的形式存储在计算机中的**。在分析这样做的原因之前，首先给出三者的定义。

- **原码**：我们将数字的二进制表示的最高位视为符号位，其中0表示正数，1表示负数，其余位表示数字的值。
- **反码**：正数的反码与其原码相同，负数的反码是对其原码除符号位外的所有位取反。
- **补码**：正数的补码与其原码相同，负数的补码是在其反码的基础上加1。

图 3-4 展示了原码、反码和补码之间的转换方法。

负数原码转补码，从右往左找到第一个1，包含1在内的往右都不变，左边全部取反（符号位不变）

![原码、反码与补码之间的相互转换](https://www.hello-algo.com/chapter_data_structure/number_encoding.assets/1s_2s_complement.png)

图 3-4  原码、反码与补码之间的相互转换

原码（sign-magnitude）虽然最直观，但存在一些局限性。一方面，**负数的原码不能直接用于运算**。例如在原码下计算1+(-2)，得到的结果是-3，这显然是不对的。

1+(-2)

->0000  0001+1000  0010

=1000 0011

->-3

为了解决此问题，计算机引入了反码（1's complement）。如果我们先将原码转换为反码，并在反码下计算1+(-2)，最后将结果从反码转换回原码，则可得到正确结果-1。

1+(-2)

->0000  0001(原码)+1000  0010(原码)

=0000  0001(反码)+1111  1101(反码)

=1111  1110(反码)

=1000  0001(原码)

->-1

另一方面，**数字零的原码有-0和+0两种表示方式**。这意味着数字零对应两个不同的二进制编码，这可能会带来歧义。比如在条件判断中，如果没有区分正零和负零，则可能会导致判断结果出错。而如果我们想处理正零和负零歧义，则需要引入额外的判断操作，这可能会降低计算机的运算效率。

+0->0000  0000

-0->1000  0000

与原码一样，反码也存在正负零歧义问题，因此计算机进一步引入了补码（2's complement）。我们先来观察一下负零的原码、反码、补码的转换过程：

-0->1000  0000(原码)

=1111  1111(反码)

=1  0000  0000(补码)

在负零的反码基础上加1会产生进位，但 `byte` 类型的长度只有 8 位，因此溢出到第 9 位的1会被舍弃。也就是说，**负零的补码为0000  0000，与正零的补码相同**。这意味着在补码表示中只存在一个零，正负零歧义从而得到解决。

还剩最后一个疑惑：`byte` 类型的取值范围是[-128,+127] ，多出来的一个负数-128是如何得到的呢？我们注意到，区间\[-127,+127]内的所有整数都有对应的原码、反码和补码，并且原码和补码之间可以互相转换。

然而，**补码1000  0000是一个例外，它并没有对应的原码**。根据转换方法，我们得到该补码的原码为0000  0000。这显然是矛盾的，因为该原码表示数字 ，它的补码应该是自身。计算机规定这个特殊的补码1000 0000代表-128。实际上，(-1)+(-127)在补码下的计算结果就是-128。

(-127)+(-1)

->1111  1111(原码)+1000  0001(原码)

=1000  0000(反码)+1111  1110(反码)

=1000  0001(补码)+1111  1111(补码)

=1000  0000(补码)

->-128

你可能已经发现了，上述所有计算都是加法运算。这暗示着一个重要事实：**计算机内部的硬件电路主要是基于加法运算设计的**。这是因为加法运算相对于其他运算（比如乘法、除法和减法）来说，硬件实现起来更简单，更容易进行并行化处理，运算速度更快。

请注意，这并不意味着计算机只能做加法。**通过将加法与一些基本逻辑运算结合，计算机能够实现各种其他的数学运算**。例如，计算减法a-b可以转换为a+(-b)计算加法 ；计算乘法和除法可以转换为计算多次加法或减法。

现在我们可以总结出计算机使用补码的原因：基于补码表示，计算机可以用同样的电路和操作来处理正数和负数的加法，不需要设计特殊的硬件电路来处理减法，并且无须特别处理正负零的歧义问题。这大大简化了硬件设计，提高了运算效率。

补码的设计非常精妙，因篇幅关系我们就先介绍到这里，建议有兴趣的读者进一步深入了解。

#### 3.3.2  浮点数编码

细心的你可能会发现：`int` 和 `float` 长度相同，都是 4 字节 ，但为什么 `float` 的取值范围远大于 `int` ？这非常反直觉，因为按理说 `float` 需要表示小数，取值范围应该变小才对。

实际上，**这是因为浮点数 `float` 采用了不同的表示方式**。记一个 32 比特长度的二进制数为：
$$
b_{31}b_{30}b_{29}...b_{2}b_{1}b_{0}
$$
据 IEEE 754 标准，32-bit 长度的 `float` 由以下三个部分构成。

- 符号位S：占 1 位 ，对应$b_{31}$。
- 指数位E：占 8 位 ，对应$b_{30}b_{29}...b_{23}$。
- 分数位N：占 23 位 ，对应$b_{22}b_{21}...b_{0}$ 。

二进制数 `float` 对应值的计算方法为：
$$
val=(-1)^{b_{31}}×2^{({{b_{30}b_{29}...b_{23})}_2-127}}×(1.b_{22}b_{21}...b_{0})_2
$$
转化到十进制下的计算公式为：
$$
val=(-1)^S×2^{E-127}×(1+N)
$$
其中各项的取值范围为：

![image-20250717200216151](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717200216151.png)

![IEEE 754 标准下的 float 的计算示例](https://www.hello-algo.com/chapter_data_structure/number_encoding.assets/ieee_754_float.png)

图 3-5  IEEE 754 标准下的 float 的计算示例

现在我们可以回答最初的问题：**`float` 的表示方式包含指数位，导致其取值范围远大于 `int`** 。根据以上计算，`float` 可表示的最大正数为$2^{254-127}×(2-2^{-23})≈3.4×10^{38}$，切换符号位便可得到最小负数。

**尽管浮点数 `float` 扩展了取值范围，但其副作用是牺牲了精度**。整数类型 `int` 将全部 32 比特用于表示数字，数字是均匀分布的；而由于指数位的存在，浮点数 `float` 的数值越大，相邻两个数字之间的差值就会趋向越大。

![image-20250717200740452](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717200740452.png)

#### Comment

![image-20250717203552149](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717203552149.png)

![image-20250717204002910](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717204002910.png)

- 原码：直观但减法复杂，零有冗余；
- 反码：实现减法转加法，但零仍冗余，需处理循环进位；
- 补码：彻底解决零的冗余和进位问题，实现了加减法运算的统一与高效，最终成为计算机中表示有符号整数的通用标准。

**进位循环处理**：反码加法时，若最高位产生进位，需将进位 “循环” 加到结果的最低位（称为 “循环进位”），增加了硬件运算的复杂度。例如 `3 + (-3)`：
`3` 反码 `00000011` + `-3` 反码 `11111100` = `11111111`（进位 1 被循环加到最低位后仍为 `11111111`，即 `-0`），逻辑不够简洁。

### 3.4  字符编码 *

在计算机中，所有数据都是以二进制数的形式存储的，字符 `char` 也不例外。为了表示字符，我们需要建立一套“字符集”，规定每个字符和二进制数之间的一一对应关系。有了字符集之后，计算机就可以通过查表完成二进制数到字符的转换。

#### 3.4.1  ASCII 字符集

ASCII 码是最早出现的字符集，其全称为 American Standard Code for Information Interchange（美国标准信息交换代码）。它使用 7 位二进制数（一个字节的低 7 位）表示一个字符，最多能够表示 128 个不同的字符。如图 3-6 所示，ASCII 码包括英文字母的大小写、数字 0 ~ 9、一些标点符号，以及一些控制字符（如换行符和制表符）。

![ASCII 码](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/ascii_table.png)

图 3-6  ASCII 码

然而，**ASCII 码仅能够表示英文**。随着计算机的全球化，诞生了一种能够表示更多语言的 EASCII 字符集。它在 ASCII 的 7 位基础上扩展到 8 位，能够表示 256 个不同的字符。

在世界范围内，陆续出现了一批适用于不同地区的 EASCII 字符集。这些字符集的前 128 个字符统一为 ASCII 码，后 128 个字符定义不同，以适应不同语言的需求。

#### 3.4.2  GBK 字符集

后来人们发现，**EASCII 码仍然无法满足许多语言的字符数量要求**。比如汉字有近十万个，光日常使用的就有几千个。中国国家标准总局于 1980 年发布了 GB2312 字符集，其收录了 6763 个汉字，基本满足了汉字的计算机处理需要。

然而，GB2312 无法处理部分罕见字和繁体字。GBK 字符集是在 GB2312 的基础上扩展得到的，它共收录了 21886 个汉字。在 GBK 的编码方案中，ASCII 字符使用一个字节表示，汉字使用两个字节表示。

#### 3.4.3  Unicode 字符集

随着计算机技术的蓬勃发展，字符集与编码标准百花齐放，而这带来了许多问题。一方面，这些字符集一般只定义了特定语言的字符，无法在多语言环境下正常工作。另一方面，同一种语言存在多种字符集标准，如果两台计算机使用的是不同的编码标准，则在信息传递时就会出现乱码。

那个时代的研究人员就在想：**如果推出一个足够完整的字符集，将世界范围内的所有语言和符号都收录其中，不就可以解决跨语言环境和乱码问题了吗**？在这种想法的驱动下，一个大而全的字符集 Unicode 应运而生。

Unicode 的中文名称为“统一码”，理论上能容纳 100 多万个字符。它致力于将全球范围内的字符纳入统一的字符集之中，提供一种通用的字符集来处理和显示各种语言文字，减少因为编码标准不同而产生的乱码问题。

自 1991 年发布以来，Unicode 不断扩充新的语言与字符。截至 2022 年 9 月，Unicode 已经包含 149186 个字符，包括各种语言的字符、符号甚至表情符号等。在庞大的 Unicode 字符集中，常用的字符占用 2 字节，有些生僻的字符占用 3 字节甚至 4 字节。

Unicode 是一种通用字符集，本质上是给每个字符分配一个编号（称为“码点”），**但它并没有规定在计算机中如何存储这些字符码点**。我们不禁会问：当多种长度的 Unicode 码点同时出现在一个文本中时，系统如何解析字符？例如给定一个长度为 2 字节的编码，系统如何确认它是一个 2 字节的字符还是两个 1 字节的字符？

对于以上问题，**一种直接的解决方案是将所有字符存储为等长的编码**。如图 3-7 所示，“Hello”中的每个字符占用 1 字节，“算法”中的每个字符占用 2 字节。我们可以通过高位填 0 将“Hello 算法”中的所有字符都编码为 2 字节长度。这样系统就可以每隔 2 字节解析一个字符，恢复这个短语的内容了。

![Unicode 编码示例](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/unicode_hello_algo.png)

图 3-7  Unicode 编码示例

然而 ASCII 码已经向我们证明，编码英文只需 1 字节。若采用上述方案，英文文本占用空间的大小将会是 ASCII 编码下的两倍，非常浪费内存空间。因此，我们需要一种更加高效的 Unicode 编码方法。

#### 3.4.4  UTF-8 编码

目前，UTF-8 已成为国际上使用最广泛的 Unicode 编码方法。**它是一种可变长度的编码**，使用 1 到 4 字节来表示一个字符，根据字符的复杂性而变。ASCII 字符只需 1 字节，拉丁字母和希腊字母需要 2 字节，常用的中文字符需要 3 字节，其他的一些生僻字符需要 4 字节。

UTF-8 的编码规则并不复杂，分为以下两种情况。

- 对于长度为 1 字节的字符，将最高位设置为0，其余 7 位设置为 Unicode 码点。值得注意的是，ASCII 字符在 Unicode 字符集中占据了前 128 个码点。也就是说，**UTF-8 编码可以向下兼容 ASCII 码**。这意味着我们可以使用 UTF-8 来解析年代久远的 ASCII 码文本。
- 对于长度为 字节的字符（其中n>1），将首个字节的高n位都设置为1，第n+1位设置为0；从第二个字节开始，将每个字节的高 2 位都设置为10；其余所有位用于填充字符的 Unicode 码点。

图 3-8 展示了“Hello算法”对应的 UTF-8 编码。观察发现，由于最高n位都设置为1，因此系统可以通过读取最高位1的个数来解析出字符的长度为n。

但为什么要将其余所有字节的高 2 位都设置为10呢？实际上，这个10能够起到校验符的作用。假设系统从一个错误的字节开始解析文本，字节头部的10能够帮助系统快速判断出异常。

之所以将10当作校验符，是因为在 UTF-8 编码规则下，不可能有字符的最高两位是10。这个结论可以用反证法来证明：假设一个字符的最高两位是10，说明该字符的长度为1，对应 ASCII 码。而 ASCII 码的最高位应该是0，与假设矛盾。

![UTF-8 编码示例](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/utf-8_hello_algo.png)

图 3-8  UTF-8 编码示例

除了 UTF-8 之外，常见的编码方式还包括以下两种。

- **UTF-16 编码**：使用 2 或 4 字节来表示一个字符。所有的 ASCII 字符和常用的非英文字符，都用 2 字节表示；少数字符需要用到 4 字节表示。对于 2 字节的字符，UTF-16 编码与 Unicode 码点相等。
- **UTF-32 编码**：每个字符都使用 4 字节。这意味着 UTF-32 比 UTF-8 和 UTF-16 更占用空间，特别是对于 ASCII 字符占比较高的文本。

从存储空间占用的角度看，使用 UTF-8 表示英文字符非常高效，因为它仅需 1 字节；使用 UTF-16 编码某些非英文字符（例如中文）会更加高效，因为它仅需 2 字节，而 UTF-8 可能需要 3 字节。

从兼容性的角度看，UTF-8 的通用性最佳，许多工具和库优先支持 UTF-8 。

#### 3.4.5  编程语言的字符编码

对于以往的大多数编程语言，程序运行中的字符串都采用 UTF-16 或 UTF-32 这类等长编码。在等长编码下，我们可以将字符串看作数组来处理，这种做法具有以下优点。

- **随机访问**：UTF-16 编码的字符串可以很容易地进行随机访问。UTF-8 是一种变长编码，要想找到第i个字符，我们需要从字符串的开始处遍历到第i个字符，这需要O(n)的时间。
- **字符计数**：与随机访问类似，计算 UTF-16 编码的字符串的长度也是O(1)的操作。但是，计算 UTF-8 编码的字符串的长度需要遍历整个字符串。
- **字符串操作**：在 UTF-16 编码的字符串上，很多字符串操作（如分割、连接、插入、删除等）更容易进行。在 UTF-8 编码的字符串上，进行这些操作通常需要额外的计算，以确保不会产生无效的 UTF-8 编码。

实际上，编程语言的字符编码方案设计是一个很有趣的话题，涉及许多因素。

- Java 的 `String` 类型使用 UTF-16 编码，每个字符占用 2 字节。这是因为 Java 语言设计之初，人们认为 16 位足以表示所有可能的字符。然而，这是一个不正确的判断。后来 Unicode 规范扩展到了超过 16 位，所以 Java 中的字符现在可能由一对 16 位的值（称为“代理对”）表示。
- JavaScript 和 TypeScript 的字符串使用 UTF-16 编码的原因与 Java 类似。当 1995 年 Netscape 公司首次推出 JavaScript 语言时，Unicode 还处于发展早期，那时候使用 16 位的编码就足以表示所有的 Unicode 字符了。
- C# 使用 UTF-16 编码，主要是因为 .NET 平台是由 Microsoft 设计的，而 Microsoft 的很多技术（包括 Windows 操作系统）都广泛使用 UTF-16 编码。

由于以上编程语言对字符数量的低估，它们不得不采取“代理对”的方式来表示超过 16 位长度的 Unicode 字符。这是一个不得已为之的无奈之举。一方面，包含代理对的字符串中，一个字符可能占用 2 字节或 4 字节，从而丧失了等长编码的优势。另一方面，处理代理对需要额外增加代码，这提高了编程的复杂性和调试难度。

出于以上原因，部分编程语言提出了一些不同的编码方案。

- Python 中的 `str` 使用 Unicode 编码，并采用一种灵活的字符串表示，存储的字符长度取决于字符串中最大的 Unicode 码点。若字符串中全部是 ASCII 字符，则每个字符占用 1 字节；如果有字符超出了 ASCII 范围，但全部在基本多语言平面（BMP）内，则每个字符占用 2 字节；如果有超出 BMP 的字符，则每个字符占用 4 字节。
- Go 语言的 `string` 类型在内部使用 UTF-8 编码。Go 语言还提供了 `rune` 类型，它用于表示单个 Unicode 码点。
- Rust 语言的 `str` 和 `String` 类型在内部使用 UTF-8 编码。Rust 也提供了 `char` 类型，用于表示单个 Unicode 码点。

需要注意的是，以上讨论的都是字符串在编程语言中的存储方式，**这和字符串如何在文件中存储或在网络中传输是不同的问题**。在文件存储或网络传输中，我们通常会将字符串编码为 UTF-8 格式，以达到最优的兼容性和空间效率。

#### Comment

Python 中的 `str` 字符串直接用 Unicode 表示（请注意区分：读写文件默认为 UTF-8 编码）。CPython 为 str 对象使用了一种灵活的存储策略，字符长度取决于字符串中最大的字符。观察以下测试：

```python
import sys

eng1 = "a"
eng2 = "ab"
eng3 = "abc"

chn1 = "哈"
chn2 = "哈啰"
chn2_eng1 = "哈啰a"

bmp1 = "𨊻"
bmp2 = "𨊻𨋾"
bmp2_eng1 = "𨊻𨋾a"

print("\n英文：") # 英文长度为 1
print(eng1 + ": ", sys.getsizeof(eng1))
print(eng2 + ": ", sys.getsizeof(eng2))
print(eng3 + ": ", sys.getsizeof(eng3))

print("\n中文:")
print(chn1 + ": ", sys.getsizeof(chn1))
print(chn2 + ": ", sys.getsizeof(chn2))
print(chn2_eng1 + ": ", sys.getsizeof(chn2_eng1))

print("\n补充平面:")
print(bmp1 + ": ", sys.getsizeof(bmp1))
print(bmp2 + ": ", sys.getsizeof(bmp2))
print(bmp2_eng1 + ": ", sys.getsizeof(bmp2_eng1))
```

可以得到以下结论：

1. 纯英文字符串的字符长度为 1 ；
2. 中文字符串下，中文和英文长度都为 2 ；
3. 补充平面字符下，英文字符长度为 4 ；

```python
英文：
a:  50
ab:  51
abc:  52

中文:
哈:  76
哈啰:  78
哈啰a:  80

超平面:
𨊻:  80
𨊻𨋾:  84
𨊻𨋾a:  88
```

![image-20250717214907640](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717214907640.png)

### 3.5  小结

####  重点回顾

- 数据结构可以从逻辑结构和物理结构两个角度进行分类。逻辑结构描述了数据元素之间的逻辑关系，而物理结构描述了数据在计算机内存中的存储方式。
- 常见的逻辑结构包括线性、树状和网状等。通常我们根据逻辑结构将数据结构分为线性（数组、链表、栈、队列）和非线性（树、图、堆）两种。哈希表的实现可能同时包含线性数据结构和非线性数据结构。
- 当程序运行时，数据被存储在计算机内存中。每个内存空间都拥有对应的内存地址，程序通过这些内存地址访问数据。
- 物理结构主要分为连续空间存储（数组）和分散空间存储（链表）。所有数据结构都是由数组、链表或两者的组合实现的。
- 计算机中的基本数据类型包括整数 `byte`、`short`、`int`、`long` ，浮点数 `float`、`double` ，字符 `char` 和布尔 `bool` 。它们的取值范围取决于占用空间大小和表示方式。
- 原码、反码和补码是在计算机中编码数字的三种方法，它们之间可以相互转换。整数的原码的最高位是符号位，其余位是数字的值。
- 整数在计算机中是以补码的形式存储的。在补码表示下，计算机可以对正数和负数的加法一视同仁，不需要为减法操作单独设计特殊的硬件电路，并且不存在正负零歧义的问题。
- 浮点数的编码由 1 位符号位、8 位指数位和 23 位分数位构成。由于存在指数位，因此浮点数的取值范围远大于整数，代价是牺牲了精度。
- ASCII 码是最早出现的英文字符集，长度为 1 字节，共收录 127 个字符。GBK 字符集是常用的中文字符集，共收录两万多个汉字。Unicode 致力于提供一个完整的字符集标准，收录世界上各种语言的字符，从而解决由于字符编码方法不一致而导致的乱码问题。
- UTF-8 是最受欢迎的 Unicode 编码方法，通用性非常好。它是一种变长的编码方法，具有很好的扩展性，有效提升了存储空间的使用效率。UTF-16 和 UTF-32 是等长的编码方法。在编码中文时，UTF-16 占用的空间比 UTF-8 更小。Java 和 C# 等编程语言默认使用 UTF-16 编码。

#### Q & A

**Q**：为什么哈希表同时包含线性数据结构和非线性数据结构？

哈希表底层是数组，而为了解决哈希冲突，我们可能会使用“链式地址”（后续“哈希冲突”章节会讲）：数组中每个桶指向一个链表，当链表长度超过一定阈值时，又可能被转化为树（通常为红黑树）。

从存储的角度来看，哈希表的底层是数组，其中每一个桶槽位可能包含一个值，也可能包含一个链表或一棵树。因此，哈希表可能同时包含线性数据结构（数组、链表）和非线性数据结构（树）。

**Q**：`char` 类型的长度是 1 字节吗？

`char` 类型的长度由编程语言采用的编码方法决定。例如，Java、JavaScript、TypeScript、C# 都采用 UTF-16 编码（保存 Unicode 码点），因此 `char` 类型的长度为 2 字节。

**Q**：基于数组实现的数据结构也称“静态数据结构” 是否有歧义？栈也可以进行出栈和入栈等操作，这些操作都是“动态”的。

栈确实可以实现动态的数据操作，但数据结构仍然是“静态”（长度不可变）的。尽管基于数组的数据结构可以动态地添加或删除元素，但它们的容量是固定的。如果数据量超出了预分配的大小，就需要创建一个新的更大的数组，并将旧数组的内容复制到新数组中。

**Q**：在构建栈（队列）的时候，未指定它的大小，为什么它们是“静态数据结构”呢？

在高级编程语言中，我们无须人工指定栈（队列）的初始容量，这个工作由类内部自动完成。例如，Java 的 `ArrayList` 的初始容量通常为 10。另外，扩容操作也是自动实现的。详见后续的“列表”章节。

## 第 4 章  数组与链表

### 4.1  数组

数组（array）是一种线性数据结构，其将相同类型的元素存储在连续的内存空间(虚拟内存)中。我们将元素在数组中的位置称为该元素的索引（index）。图 4-1 展示了数组的主要概念和存储方式。

![数组定义与存储方式](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_definition.png)

图 4-1  数组定义与存储方式

#### 4.1.1  数组常用操作

1. 初始化数组

   我们可以根据需求选用数组的两种初始化方式：无初始值、给定初始值。在未指定初始值的情况下，大多数编程语言会将数组元素初始化为 ：

   ```python
   # 初始化数组
   arr: list[int] = [0] * 5  # [ 0, 0, 0, 0, 0 ]
   nums: list[int] = [1, 3, 2, 5, 4]
   ```

2. 访问元素

   数组元素被存储在连续的内存空间中，这意味着计算数组元素的内存地址非常容易。给定数组内存地址（首元素内存地址）和某个元素的索引，我们可以使用图 4-2 所示的公式计算得到该元素的内存地址，从而直接访问该元素。

   ![数组元素的内存地址计算](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_memory_location_calculation.png)

   图 4-2  数组元素的内存地址计算

   观察图 4-2 ，我们发现数组首个元素的索引为0，这似乎有些反直觉，因为从1开始计数会更自然。但从地址计算公式的角度看，**索引本质上是内存地址的偏移量**。首个元素的地址偏移量是0，因此它的索引为0是合理的。

   在数组中访问元素非常高效，我们可以在O(1)时间内随机访问数组中的任意一个元素。

   ```python
   def random_access(nums: list[int]) -> int:
       """随机访问元素"""
       # 在区间 [0, len(nums)-1] 中随机抽取一个数字
       random_index = random.randint(0, len(nums) - 1)
       # 获取并返回随机元素
       random_num = nums[random_index]
       return random_num
   ```

3. 插入元素

   数组元素在内存中是“紧挨着的”，它们之间没有空间再存放任何数据。如图 4-3 所示，如果想在数组中间插入一个元素，则需要将该元素之后的所有元素都向后移动一位，之后再把元素赋值给该索引。

   ![数组插入元素示例](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_insert_element.png)

   图 4-3  数组插入元素示例

   值得注意的是，由于数组的长度是固定的，因此插入一个元素必定会导致数组尾部元素“丢失”。我们将这个问题的解决方案留在“列表”章节中讨论。

   ```python
   def insert(nums: list[int], num: int, index: int):
       """在数组的索引 index 处插入元素 num"""
       # 把索引 index 以及之后的所有元素向后移动一位
       for i in range(len(nums) - 1, index, -1):
           nums[i] = nums[i - 1]
       # 将 num 赋给 index 处的元素
       nums[index] = num
   ```

4. 删除元素

   同理，如图 4-4 所示，若想删除索引i处的元素，则需要把索引 之后的元素都向前移动一位。

   ![数组删除元素示例](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_remove_element.png)

   图 4-4  数组删除元素示例

   请注意，删除元素完成后，原先末尾的元素变得“无意义”了，所以我们无须特意去修改它。

   ```python
   def remove(nums: list[int], index: int):
       """删除索引 index 处的元素"""
       # 把索引 index 之后的所有元素向前移动一位
       for i in range(index, len(nums) - 1):
           nums[i] = nums[i + 1]
   ```

   总的来看，数组的插入与删除操作有以下缺点。

   - **时间复杂度高**：数组的插入和删除的平均时间复杂度均为O(n)，其中n为数组长度。
   - **丢失元素**：由于数组的长度不可变，因此在插入元素后，超出数组长度范围的元素会丢失。
   - **内存浪费**：我们可以初始化一个比较长的数组，只用前面一部分，这样在插入数据时，丢失的末尾元素都是“无意义”的，但这样做会造成部分内存空间浪费。

5. 遍历数组

   在大多数编程语言中，我们既可以通过索引遍历数组，也可以直接遍历获取数组中的每个元素：

   ```python
   def traverse(nums: list[int]):
       """遍历数组"""
       count = 0
       # 通过索引遍历数组
       for i in range(len(nums)):
           count += nums[i]
       # 直接遍历数组元素
       for num in nums:
           count += num
       # 同时遍历数据索引和元素
       for i, num in enumerate(nums):
           count += nums[i]
           count += num
   ```

6. 查找元素

   在数组中查找指定元素需要遍历数组，每轮判断元素值是否匹配，若匹配则输出对应索引。

   因为数组是线性数据结构，所以上述查找操作被称为“线性查找”。

   ```python
   def find(nums: list[int], target: int) -> int:
       """在数组中查找指定元素"""
       for i in range(len(nums)):
           if nums[i] == target:
               return i
       return -1
   ```

7. 扩容数组

   在复杂的系统环境中，程序难以保证数组之后的内存空间是可用的，从而无法安全地扩展数组容量。因此在大多数编程语言中，**数组的长度是不可变的**。

   如果我们希望扩容数组，则需重新建立一个更大的数组，然后把原数组元素依次复制到新数组。这是一个O(n)的操作，在数组很大的情况下非常耗时。代码如下所示：

   ```python
   def extend(nums: list[int], enlarge: int) -> list[int]:
       """扩展数组长度"""
       # 初始化一个扩展长度后的数组
       res = [0] * (len(nums) + enlarge)
       # 将原数组中的所有元素复制到新数组
       for i in range(len(nums)):
           res[i] = nums[i]
       # 返回扩展后的新数组
       return res
   ```

#### 4.1.2  数组的优点与局限性

数组存储在连续的内存空间内，且元素类型相同。这种做法包含丰富的先验信息，系统可以利用这些信息来优化数据结构的操作效率。

- **空间效率高**：数组为数据分配了连续的内存块，无须额外的结构开销。
- **支持随机访问**：数组允许在O(1)时间内访问任何元素。
- **缓存局部性**：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。

连续空间存储是一把双刃剑，其存在以下局限性。

- **插入与删除效率低**：当数组中元素较多时，插入与删除操作需要移动大量的元素。
- **长度不可变**：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。
- **空间浪费**：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。

#### 4.1.3  数组典型应用

数组是一种基础且常见的数据结构，既频繁应用在各类算法之中，也可用于实现各种复杂数据结构。

- **随机访问**：如果我们想随机抽取一些样本，那么可以用数组存储，并生成一个随机序列，根据索引实现随机抽样。
- **排序和搜索**：数组是排序和搜索算法最常用的数据结构。快速排序、归并排序、二分查找等都主要在数组上进行。
- **查找表**：当需要快速查找一个元素或其对应关系时，可以使用数组作为查找表。假如我们想实现字符到 ASCII 码的映射，则可以将字符的 ASCII 码值作为索引，对应的元素存放在数组中的对应位置。
- **机器学习**：神经网络中大量使用了向量、矩阵、张量之间的线性代数运算，这些数据都是以数组的形式构建的。数组是神经网络编程中最常使用的数据结构。
- **数据结构实现**：数组可以用于实现栈、队列、哈希表、堆、图等数据结构。例如，图的邻接矩阵表示实际上是一个二维数组。

#### Comment

![image-20250719174511179](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250719174511179.png)

### 4.2  链表

内存空间是所有程序的公共资源，在一个复杂的系统运行环境下，空闲的内存空间可能散落在内存各处。我们知道，存储数组的内存空间必须是连续的，而当数组非常大时，内存可能无法提供如此大的连续空间。此时链表的灵活性优势就体现出来了。

链表（linked list）是一种线性数据结构，其中的每个元素都是一个节点对象，各个节点通过“引用”相连接。引用记录了下一个节点的内存地址，通过它可以从当前节点访问到下一个节点。

链表的设计使得各个节点可以分散存储在内存各处，它们的内存地址无须连续。

![链表定义与存储方式](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_definition.png)

图 4-5  链表定义与存储方式

观察图 4-5 ，链表的组成单位是节点（node）对象。每个节点都包含两项数据：节点的“值”和指向下一节点的“引用”。

- 链表的首个节点被称为“头节点”，最后一个节点被称为“尾节点”。
- 尾节点指向的是“空”，它在 Java、C++ 和 Python 中分别被记为 `null`、`nullptr` 和 `None` 。
- 在 C、C++、Go 和 Rust 等支持指针的语言中，上述“引用”应被替换为“指针”。

如以下代码所示，链表节点 `ListNode` 除了包含值，还需额外保存一个引用（指针）。因此在相同数据量下，**链表比数组占用更多的内存空间**。

```python
class ListNode:
    """链表节点类"""
    def __init__(self, val: int):
        self.val: int = val               # 节点值
        self.next: ListNode | None = None # 指向下一节点的引用
```

#### 4.2.1  链表常用操作

1. 初始化链表

   建立链表分为两步，第一步是初始化各个节点对象，第二步是构建节点之间的引用关系。初始化完成后，我们就可以从链表的头节点出发，通过引用指向 `next` 依次访问所有节点。

   ```python
   # 初始化链表 1 -> 3 -> 2 -> 5 -> 4
   # 初始化各个节点
   n0 = ListNode(1)
   n1 = ListNode(3)
   n2 = ListNode(2)
   n3 = ListNode(5)
   n4 = ListNode(4)
   # 构建节点之间的引用
   n0.next = n1
   n1.next = n2
   n2.next = n3
   n3.next = n4
   ```

   数组整体是一个变量，比如数组 `nums` 包含元素 `nums[0]` 和 `nums[1]` 等，而链表是由多个独立的节点对象组成的。**我们通常将头节点当作链表的代称**，比如以上代码中的链表可记作链表 `n0` 。

2. 插入节点

   在链表中插入节点非常容易。如图 4-6 所示，假设我们想在相邻的两个节点 `n0` 和 `n1` 之间插入一个新节点 `P` ，**则只需改变两个节点引用（指针）即可**，时间复杂度为O(1)。

   相比之下，在数组中插入元素的时间复杂度为O(n)，在大数据量下的效率较低。

   ![链表插入节点示例](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_insert_node.png)

   图 4-6  链表插入节点示例

   ```python
   def insert(n0:ListNode,P:ListNode):
       P.next = n0.next
       n0.next = P
   ```

3. 删除节点

   如图 4-7 所示，在链表中删除节点也非常方便，**只需改变一个节点的引用（指针）即可**。

   请注意，尽管在删除操作完成后节点 `P` 仍然指向 `n1` ，但实际上遍历此链表已经无法访问到 `P` ，这意味着 `P` 已经不再属于该链表了。

   ![链表删除节点](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_remove_node.png)

   图 4-7  链表删除节点

   ```python
   def remove(n0: ListNode):
       """删除链表的节点 n0 之后的首个节点"""
       if not n0.next:
           return
       # n0 -> P -> n1
       P = n0.next
       n1 = P.next
       n0.next = n1
   ```

4. 访问节点

   **在链表中访问节点的效率较低**。如上一节所述，我们可以在O(1)时间下访问数组中的任意元素。链表则不然，程序需要从头节点出发，逐个向后遍历，直至找到目标节点。也就是说，访问链表的第i个节点需要循环i-1轮，时间复杂度为O(n) 。

   ```python
   def access(head: ListNode, index: int) -> ListNode | None:
       """访问链表中索引为 index 的节点"""
       for _ in range(index):
           if not head:
               return None
           head = head.next
       return head
   ```

5. 查找结点

   遍历链表，查找其中值为 `target` 的节点，输出该节点在链表中的索引。此过程也属于线性查找。代码如下所示：

   ```python
   def find(head: ListNode, target: int) -> int:
       """在链表中查找值为 target 的首个节点"""
       index = 0
       while head:
           if head.val == target:
               return index
           head = head.next
           index += 1
       return -1
   ```

#### 4.2.2  数组 vs. 链表

表 4-1 总结了数组和链表的各项特点并对比了操作效率。由于它们采用两种相反的存储策略，因此各种性质和操作效率也呈现对立的特点。

表 4-1  数组与链表的效率对比

|          | 数组                           | 链表           |
| :------- | :----------------------------- | -------------- |
| 存储方式 | 连续内存空间                   | 分散内存空间   |
| 容量扩展 | 长度不可变                     | 可灵活扩展     |
| 内存效率 | 元素占用内存少、但可能浪费空间 | 元素占用内存多 |
| 访问元素 | O(1)                           | O(n)           |
| 添加元素 | O(n)                           | O(1)           |
| 删除元素 | O(n)                           | O(1)           |

#### 4.2.3  常见链表类型

如图 4-8 所示，常见的链表类型包括三种。

- **单向链表**：即前面介绍的普通链表。单向链表的节点包含值和指向下一节点的引用两项数据。我们将首个节点称为头节点，将最后一个节点称为尾节点，尾节点指向空 `None` 。
- **环形链表**：如果我们令单向链表的尾节点指向头节点（首尾相接），则得到一个环形链表。在环形链表中，任意节点都可以视作头节点。
- **双向链表**：与单向链表相比，双向链表记录了两个方向的引用。双向链表的节点定义同时包含指向后继节点（下一个节点）和前驱节点（上一个节点）的引用（指针）。相较于单向链表，双向链表更具灵活性，可以朝两个方向遍历链表，但相应地也需要占用更多的内存空间。

```python
class ListNode:
    """双向链表节点类"""
    def __init__(self, val: int):
        self.val: int = val                # 节点值
        self.next: ListNode | None = None  # 指向后继节点的引用
        self.prev: ListNode | None = None  # 指向前驱节点的引用
```

![常见链表种类](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_common_types.png)

图 4-8  常见链表种类

#### 4.2.4  链表典型应用

单向链表通常用于实现栈、队列、哈希表和图等数据结构。

- **栈与队列**：当插入和删除操作都在链表的一端进行时，它表现的特性为先进后出，对应栈；当插入操作在链表的一端进行，删除操作在链表的另一端进行，它表现的特性为先进先出，对应队列。
- **哈希表**：链式地址是解决哈希冲突的主流方案之一，在该方案中，所有冲突的元素都会被放到一个链表中。
- **图**：邻接表是表示图的一种常用方式，其中图的每个顶点都与一个链表相关联，链表中的每个元素都代表与该顶点相连的其他顶点。

双向链表常用于需要快速查找前一个和后一个元素的场景。

- **高级数据结构**：比如在红黑树、B 树中，我们需要访问节点的父节点，这可以通过在节点中保存一个指向父节点的引用来实现，类似于双向链表。
- **浏览器历史**：在网页浏览器中，当用户点击前进或后退按钮时，浏览器需要知道用户访问过的前一个和后一个网页。双向链表的特性使得这种操作变得简单。
- **LRU 算法**：在缓存淘汰（LRU）算法中，我们需要快速找到最近最少使用的数据，以及支持快速添加和删除节点。这时候使用双向链表就非常合适。

环形链表常用于需要周期性操作的场景，比如操作系统的资源调度。

- **时间片轮转调度算法**：在操作系统中，时间片轮转调度算法是一种常见的 CPU 调度算法，它需要对一组进程进行循环。每个进程被赋予一个时间片，当时间片用完时，CPU 将切换到下一个进程。这种循环操作可以通过环形链表来实现。
- **数据缓冲区**：在某些数据缓冲区的实现中，也可能会使用环形链表。比如在音频、视频播放器中，数据流可能会被分成多个缓冲块并放入一个环形链表，以便实现无缝播放。

#### Comment

![image-20250719210234637](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250719210234637.png)

### 4.3  列表

列表（list）是一个抽象的数据结构概念，它表示元素的有序集合，支持元素访问、修改、添加、删除和遍历等操作，无须使用者考虑容量限制的问题。列表可以基于链表或数组实现。

- 链表天然可以看作一个列表，其支持元素增删查改操作，并且可以灵活动态扩容。
- 数组也支持元素增删查改，但由于其长度不可变，因此只能看作一个具有长度限制的列表。

当使用数组实现列表时，**长度不可变的性质会导致列表的实用性降低**。这是因为我们通常无法事先确定需要存储多少数据，从而难以选择合适的列表长度。若长度过小，则很可能无法满足使用需求；若长度过大，则会造成内存空间浪费。

为解决此问题，我们可以使用动态数组（dynamic array）来实现列表。它继承了数组的各项优点，并且可以在程序运行过程中进行动态扩容。

实际上，**许多编程语言中的标准库提供的列表是基于动态数组实现的**，例如 Python 中的 `list` 、Java 中的 `ArrayList` 、C++ 中的 `vector` 和 C# 中的 `List` 等。在接下来的讨论中，我们将把“列表”和“动态数组”视为等同的概念。

#### 4.3.1  列表常用操作

1. 初始化列表

   我们通常使用“无初始值”和“有初始值”这两种初始化方法：

   ```python
   # 初始化列表
   # 无初始值
   nums1: list[int] = []
   # 有初始值
   nums: list[int] = [1, 3, 2, 5, 4]
   ```

2. 访问元素

   列表本质上是数组，因此可以在O(1)时间内访问和更新元素，效率很高。

   ```python
   # 访问元素
   num: int = nums[1]  # 访问索引 1 处的元素
   
   # 更新元素
   nums[1] = 0    # 将索引 1 处的元素更新为 0
   ```

3. 插入和删除元素

   相较于数组，列表可以自由地添加与删除元素。在列表尾部添加元素的时间复杂度为O(1)，但插入和删除元素的效率仍与数组相同，时间复杂度为O(n)。

   ```python
   # 清空列表
   nums.clear()
   
   # 在尾部添加元素
   nums.append(1)
   nums.append(3)
   nums.append(2)
   nums.append(5)
   nums.append(4)
   
   # 在中间插入元素
   nums.insert(3, 6)  # 在索引 3 处插入数字 6
   
   # 删除元素
   nums.pop(3)        # 删除索引 3 处的元素
   ```

4. 遍历列表

   与数组一样，列表可以根据索引遍历，也可以直接遍历各元素。

   ```python
   # 通过索引遍历列表
   count = 0
   for i in range(len(nums)):
       count += nums[i]
   
   # 直接遍历列表元素
   for num in nums:
       count += num
   ```

5. 拼接列表

   给定一个新列表 `nums1` ，我们可以将其拼接到原列表的尾部。

   ```python
   # 拼接两个列表
   nums1: list[int] = [6, 8, 7, 10, 9]
   nums += nums1  # 将列表 nums1 拼接到 nums 之后
   ```

6. 排序列表

   完成列表排序后，我们便可以使用在数组类算法题中经常考查的“二分查找”和“双指针”算法。

   ```python
   # 排序列表
   nums.sort()  # 排序后，列表元素从小到大排列
   ```

#### 4.3.2  列表实现

许多编程语言内置了列表，例如 Java、C++、Python 等。它们的实现比较复杂，各个参数的设定也非常考究，例如初始容量、扩容倍数等。感兴趣的读者可以查阅源码进行学习。

为了加深对列表工作原理的理解，我们尝试实现一个简易版列表，包括以下三个重点设计。

- **初始容量**：选取一个合理的数组初始容量。在本示例中，我们选择 10 作为初始容量。
- **数量记录**：声明一个变量 `size` ，用于记录列表当前元素数量，并随着元素插入和删除实时更新。根据此变量，我们可以定位列表尾部，以及判断是否需要扩容。
- **扩容机制**：若插入元素时列表容量已满，则需要进行扩容。先根据扩容倍数创建一个更大的数组，再将当前数组的所有元素依次移动至新数组。在本示例中，我们规定每次将数组扩容至之前的 2 倍。

```python
class MyList:
    """列表类"""

    def __init__(self):
        """构造方法"""
        self._capacity: int = 10  # 列表容量
        self._arr: list[int] = [0] * self._capacity  # 数组（存储列表元素）
        self._size: int = 0  # 列表长度（当前元素数量）
        self._extend_ratio: int = 2  # 每次列表扩容的倍数

    def size(self) -> int:
        """获取列表长度（当前元素数量）"""
        return self._size

    def capacity(self) -> int:
        """获取列表容量"""
        return self._capacity

    def get(self, index: int) -> int:
        """访问元素"""
        # 索引如果越界，则抛出异常，下同
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        return self._arr[index]

    def set(self, num: int, index: int):
        """更新元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        self._arr[index] = num

    def add(self, num: int):
        """在尾部添加元素"""
        # 元素数量超出容量时，触发扩容机制
        if self.size() == self.capacity():
            self.extend_capacity()
        self._arr[self._size] = num
        self._size += 1

    def insert(self, num: int, index: int):
        """在中间插入元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        # 元素数量超出容量时，触发扩容机制
        if self._size == self.capacity():
            self.extend_capacity()
        # 将索引 index 以及之后的元素都向后移动一位
        for j in range(self._size - 1, index - 1, -1):
            self._arr[j + 1] = self._arr[j]
        self._arr[index] = num
        # 更新元素数量
        self._size += 1

    def remove(self, index: int) -> int:
        """删除元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        num = self._arr[index]
        # 将索引 index 之后的元素都向前移动一位
        for j in range(index, self._size - 1):
            self._arr[j] = self._arr[j + 1]
        # 更新元素数量
        self._size -= 1
        # 返回被删除的元素
        return num

    def extend_capacity(self):
        """列表扩容"""
        # 新建一个长度为原数组 _extend_ratio 倍的新数组，并将原数组复制到新数组
        self._arr = self._arr + [0] * self.capacity() * (self._extend_ratio - 1)
        # 更新列表容量
        self._capacity = len(self._arr)

    def to_array(self) -> list[int]:
        """返回有效长度的列表"""
        return self._arr[: self._size]
```

#### Comment

在 Python 中使用加号（`+`）运算符拼接两个列表时，**时间复杂度为 O (n + m)**，其中 `n` 和 `m` 分别是两个列表的长度。

原因解析：

使用 `+` 拼接列表时，Python 会创建一个**新的列表**，并将两个原始列表中的所有元素依次复制到新列表中。这个过程需要遍历第一个列表的 `n` 个元素和第二个列表的 `m` 个元素，因此总操作次数与两个列表的总长度成正比，即时间复杂度为 O (n + m)。

![image-20250724143704223](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250724143704223.png)

### 4.4  内存与缓存 *

在本章的前两节中，我们探讨了数组和链表这两种基础且重要的数据结构，它们分别代表了“连续存储”和“分散存储”两种物理结构。

实际上，**物理结构在很大程度上决定了程序对内存和缓存的使用效率**，进而影响算法程序的整体性能。

#### 4.4.1  计算机存储设备

计算机中包括三种类型的存储设备：硬盘（hard disk）、内存（random-access memory, RAM）、缓存（cache memory）。表 4-2 展示了它们在计算机系统中的不同角色和性能特点。

表 4-2  计算机的存储设备

|                | 硬盘                                     | 内存                                   | 缓存                                              |
| :------------- | :--------------------------------------- | :------------------------------------- | ------------------------------------------------- |
| 用途           | 长期存储数据，包括操作系统、程序、文件等 | 临时存储当前运行的程序和正在处理的数据 | 存储经常访问的数据和指令，减少 CPU 访问内存的次数 |
| 易失性         | 断电后数据不会丢失                       | 断电后数据会丢失                       | 断电后数据会丢失                                  |
| 容量           | 较大，TB 级别                            | 较小，GB 级别                          | 非常小，MB 级别                                   |
| 速度           | 较慢，几百到几千 MB/s                    | 较快，几十 GB/s                        | 非常快，几十到几百 GB/s                           |
| 价格（人民币） | 较便宜，几毛到几元 / GB                  | 较贵，几十到几百元 / GB                | 非常贵，随 CPU 打包计价                           |

我们可以将计算机存储系统想象为图 4-9 所示的金字塔结构。越靠近金字塔顶端的存储设备的速度越快、容量越小、成本越高。这种多层级的设计并非偶然，而是计算机科学家和工程师们经过深思熟虑的结果。

- **硬盘难以被内存取代**。首先，内存中的数据在断电后会丢失，因此它不适合长期存储数据；其次，内存的成本是硬盘的几十倍，这使得它难以在消费者市场普及。
- **缓存的大容量和高速度难以兼得**。随着 L1、L2、L3 缓存的容量逐步增大，其物理尺寸会变大，与 CPU 核心之间的物理距离会变远，从而导致数据传输时间增加，元素访问延迟变高。在当前技术下，多层级的缓存结构是容量、速度和成本之间的最佳平衡点。

![计算机存储系统](https://www.hello-algo.com/chapter_array_and_linkedlist/ram_and_cache.assets/storage_pyramid.png)

图 4-9  计算机存储系统

> 计算机的存储层次结构体现了速度、容量和成本三者之间的精妙平衡。实际上，这种权衡普遍存在于所有工业领域，它要求我们在不同的优势和限制之间找到最佳平衡点。

总的来说，**硬盘用于长期存储大量数据，内存用于临时存储程序运行中正在处理的数据，而缓存则用于存储经常访问的数据和指令**，以提高程序运行效率。三者共同协作，确保计算机系统高效运行。

如图 4-10 所示，在程序运行时，数据会从硬盘中被读取到内存中，供 CPU 计算使用。缓存可以看作 CPU 的一部分，**它通过智能地从内存加载数据**，给 CPU 提供高速的数据读取，从而显著提升程序的执行效率，减少对较慢的内存的依赖。

![硬盘、内存和缓存之间的数据流通](https://www.hello-algo.com/chapter_array_and_linkedlist/ram_and_cache.assets/computer_storage_devices.png)

图 4-10  硬盘、内存和缓存之间的数据流通

#### 4.4.2  数据结构的内存效率

在内存空间利用方面，数组和链表各自具有优势和局限性。

一方面，**内存是有限的，且同一块内存不能被多个程序共享**，因此我们希望数据结构能够尽可能高效地利用空间。数组的元素紧密排列，不需要额外的空间来存储链表节点间的引用（指针），因此空间效率更高。然而，数组需要一次性分配足够的连续内存空间，这可能导致内存浪费，数组扩容也需要额外的时间和空间成本。相比之下，链表以“节点”为单位进行动态内存分配和回收，提供了更大的灵活性。

另一方面，在程序运行时，**随着反复申请与释放内存，空闲内存的碎片化程度会越来越高**，从而导致内存的利用效率降低。数组由于其连续的存储方式，相对不容易导致内存碎片化。相反，链表的元素是分散存储的，在频繁的插入与删除操作中，更容易导致内存碎片化。

#### 4.4.3  数据结构的缓存效率

缓存虽然在空间容量上远小于内存，但它比内存快得多，在程序执行速度上起着至关重要的作用。由于缓存的容量有限，只能存储一小部分频繁访问的数据，因此当 CPU 尝试访问的数据不在缓存中时，就会发生缓存未命中（cache miss），此时 CPU 不得不从速度较慢的内存中加载所需数据。

显然，**“缓存未命中”越少，CPU 读写数据的效率就越高**，程序性能也就越好。我们将 CPU 从缓存中成功获取数据的比例称为缓存命中率（cache hit rate），这个指标通常用来衡量缓存效率。

为了尽可能达到更高的效率，缓存会采取以下数据加载机制。

- **缓存行**：缓存不是单个字节地存储与加载数据，而是以缓存行为单位。相比于单个字节的传输，缓存行的传输形式更加高效。
- **预取机制**：处理器会尝试预测数据访问模式（例如顺序访问、固定步长跳跃访问等），并根据特定模式将数据加载至缓存之中，从而提升命中率。
- **空间局部性**：如果一个数据被访问，那么它附近的数据可能近期也会被访问。因此，缓存在加载某一数据时，也会加载其附近的数据，以提高命中率。
- **时间局部性**：如果一个数据被访问，那么它在不久的将来很可能再次被访问。缓存利用这一原理，通过保留最近访问过的数据来提高命中率。

实际上，**数组和链表对缓存的利用效率是不同的**，主要体现在以下几个方面。

- **占用空间**：链表元素比数组元素占用空间更多，导致缓存中容纳的有效数据量更少。
- **缓存行**：链表数据分散在内存各处，而缓存是“按行加载”的，因此加载到无效数据的比例更高。
- **预取机制**：数组比链表的数据访问模式更具“可预测性”，即系统更容易猜出即将被加载的数据。
- **空间局部性**：数组被存储在集中的内存空间中，因此被加载数据附近的数据更有可能即将被访问。

总体而言，**数组具有更高的缓存命中率，因此它在操作效率上通常优于链表**。这使得在解决算法问题时，基于数组实现的数据结构往往更受欢迎。

需要注意的是，**高缓存效率并不意味着数组在所有情况下都优于链表**。实际应用中选择哪种数据结构，应根据具体需求来决定。例如，数组和链表都可以实现“栈”数据结构（下一章会详细介绍），但它们适用于不同场景。

- 在做算法题时，我们会倾向于选择基于数组实现的栈，因为它提供了更高的操作效率和随机访问的能力，代价仅是需要预先为数组分配一定的内存空间。
- 如果数据量非常大、动态性很高、栈的预期大小难以估计，那么基于链表实现的栈更加合适。链表能够将大量数据分散存储于内存的不同部分，并且避免了数组扩容产生的额外开销。

### 4.5  小结

#### 1.重点回顾

- 数组和链表是两种基本的数据结构，分别代表数据在计算机内存中的两种存储方式：连续空间存储和分散空间存储。两者的特点呈现出互补的特性。
- 数组支持随机访问、占用内存较少；但插入和删除元素效率低，且初始化后长度不可变。
- 链表通过更改引用（指针）实现高效的节点插入与删除，且可以灵活调整长度；但节点访问效率低、占用内存较多。常见的链表类型包括单向链表、环形链表、双向链表。
- 列表是一种支持增删查改的元素有序集合，通常基于动态数组实现。它保留了数组的优势，同时可以灵活调整长度。
- 列表的出现大幅提高了数组的实用性，但可能导致部分内存空间浪费。
- 程序运行时，数据主要存储在内存中。数组可提供更高的内存空间效率，而链表则在内存使用上更加灵活。
- 缓存通过缓存行、预取机制以及空间局部性和时间局部性等数据加载机制，为 CPU 提供快速数据访问，显著提升程序的执行效率。
- 由于数组具有更高的缓存命中率，因此它通常比链表更高效。在选择数据结构时，应根据具体需求和场景做出恰当选择。

#### 2.Q&A

**Q**：数组存储在栈上和存储在堆上，对时间效率和空间效率是否有影响？

存储在栈上和堆上的数组都被存储在连续内存空间内，数据操作效率基本一致。然而，栈和堆具有各自的特点，从而导致以下不同点。

1. 分配和释放效率：栈是一块较小的内存，分配由编译器自动完成；而堆内存相对更大，可以在代码中动态分配，更容易碎片化。因此，堆上的分配和释放操作通常比栈上的慢。
2. 大小限制：栈内存相对较小，堆的大小一般受限于可用内存。因此堆更加适合存储大型数组。
3. 灵活性：栈上的数组的大小需要在编译时确定，而堆上的数组的大小可以在运行时动态确定。

**Q**：为什么数组要求相同类型的元素，而在链表中却没有强调相同类型呢？

链表由节点组成，节点之间通过引用（指针）连接，各个节点可以存储不同类型的数据，例如 `int`、`double`、`string`、`object` 等。

相对地，数组元素则必须是相同类型的，这样才能通过计算偏移量来获取对应元素位置。例如，数组同时包含 `int` 和 `long` 两种类型，单个元素分别占用 4 字节和 8 字节 ，此时就不能用以下公式计算偏移量了，因为数组中包含了两种“元素长度”。

```
# 元素内存地址 = 数组内存地址（首元素内存地址） + 元素长度 * 元素索引
```

**Q**：删除节点 `P` 后，是否需要把 `P.next` 设为 `None` 呢？

不修改 `P.next` 也可以。从该链表的角度看，从头节点遍历到尾节点已经不会遇到 `P` 了。这意味着节点 `P` 已经从链表中删除了，此时节点 `P` 指向哪里都不会对该链表产生影响。

从数据结构与算法（做题）的角度看，不断开没有关系，只要保证程序的逻辑是正确的就行。从标准库的角度看，断开更加安全、逻辑更加清晰。如果不断开，假设被删除节点未被正常回收，那么它会影响后继节点的内存回收。

**Q**：在链表中插入和删除操作的时间复杂度是O(1)。但是增删之前都需要O(n)的时间查找元素，那为什么时间复杂度不是O(n)呢？

如果是先查找元素、再删除元素，时间复杂度确实是O(n)。然而，链表的O(1)增删的优势可以在其他应用上得到体现。例如，双向队列适合使用链表实现，我们维护一个指针变量始终指向头节点、尾节点，每次插入与删除操作都是O(1)。

**Q**：图“链表定义与存储方式”中，浅蓝色的存储节点指针是占用一块内存地址吗？还是和节点值各占一半呢？

该示意图只是定性表示，定量表示需要根据具体情况进行分析。

- 不同类型的节点值占用的空间是不同的，比如 `int`、`long`、`double` 和实例对象等。
- 指针变量占用的内存空间大小根据所使用的操作系统及编译环境而定，大多为 8 字节或 4 字节。

**Q**：在列表末尾添加元素是否时时刻刻都为O(1)？

如果添加元素时超出列表长度，则需要先扩容列表再添加。系统会申请一块新的内存，并将原列表的所有元素搬运过去，这时候时间复杂度就会是O(n)。

**Q**：“列表的出现极大地提高了数组的实用性，但可能导致部分内存空间浪费”，这里的空间浪费是指额外增加的变量如容量、长度、扩容倍数所占的内存吗？

这里的空间浪费主要有两方面含义：一方面，列表都会设定一个初始长度，我们不一定需要用这么多；另一方面，为了防止频繁扩容，扩容一般会乘以一个系数，比如×1.5。这样一来，也会出现很多空位，我们通常不能完全填满它们。

**Q**：在 Python 中初始化 `n = [1, 2, 3]` 后，这 3 个元素的地址是相连的，但是初始化 `m = [2, 1, 3]` 会发现它们每个元素的 id 并不是连续的，而是分别跟 `n` 中的相同。这些元素的地址不连续，那么 `m` 还是数组吗？

假如把列表元素换成链表节点 `n = [n1, n2, n3, n4, n5]` ，通常情况下这 5 个节点对象也分散存储在内存各处。然而，给定一个列表索引，我们仍然可以在 时间内获取节点内存地址，从而访问到对应的节点。这是因为数组中存储的是节点的引用，而非节点本身。

与许多语言不同，Python 中的数字也被包装为对象，列表中存储的不是数字本身，而是对数字的引用。因此，我们会发现两个数组中的相同数字拥有同一个 id ，并且这些数字的内存地址无须连续。

**Q**：操作 `res = [[0]] * n` 生成了一个二维列表，其中每一个 `[0]` 都是独立的吗？

不是独立的。此二维列表中，所有的 `[0]` 实际上是同一个对象的引用。如果我们修改其中一个元素，会发现所有的对应元素都会随之改变。

如果希望二维列表中的每个 `[0]` 都是独立的，可以使用 `res = [[0] for _ in range(n)]` 来实现。这种方式的原理是初始化了n个独立的 `[0]` 列表对象。

**Q**：操作 `res = [0] * n` 生成了一个列表，其中每一个整数 0 都是独立的吗？

在该列表中，所有整数 0 都是同一个对象的引用。这是因为 Python 对小整数（通常是 -5 到 256）采用了缓存池机制，以便最大化对象复用，从而提升性能。

虽然它们指向同一个对象，但我们仍然可以独立修改列表中的每个元素，这是因为 Python 的整数是“不可变对象”。当我们修改某个元素时，实际上是切换为另一个对象的引用，而不是改变原有对象本身。

然而，当列表元素是“可变对象”时（例如列表、字典或类实例等），修改某个元素会直接改变该对象本身，所有引用该对象的元素都会产生相同变化。

> Python 的缓存池机制（也称为 “对象池” 或 “小整数缓存”）是一种**内存优化策略**，通过复用频繁使用的简单对象（如小整数、短字符串），减少内存开销和对象创建 / 销毁的效率损耗。
>
> 原理：对于一些使用频率极高的简单对象（如 `-5~256` 的整数、长度较短的字符串），Python 会在启动时提前创建这些对象并放入 “缓存池” 中。当程序再次需要使用这些对象时，不会重新创建新对象，而是直接复用缓存池中的已有对象（即多个变量指向同一个内存地址）。

## 第 5 章  栈与队列

### 5.1  栈

栈（stack）是一种遵循先入后出逻辑的线性数据结构。

我们可以将栈类比为桌面上的一摞盘子，如果想取出底部的盘子，则需要先将上面的盘子依次移走。我们将盘子替换为各种类型的元素（如整数、字符、对象等），就得到了栈这种数据结构。

如图 5-1 所示，我们把堆叠元素的顶部称为“栈顶”，底部称为“栈底”。将把元素添加到栈顶的操作叫作“入栈”，删除栈顶元素的操作叫作“出栈”。

![栈的先入后出规则](https://www.hello-algo.com/chapter_stack_and_queue/stack.assets/stack_operations.png)

图 5-1  栈的先入后出规则

#### 5.1.1  栈的常用操作

栈的常用操作如表 5-1 所示，具体的方法名需要根据所使用的编程语言来确定。在此，我们以常见的 `push()`、`pop()`、`peek()` 命名为例。

表 5-1  栈的操作效率

| 方法     | 描述                   | 时间复杂度 |
| :------- | :--------------------- | :--------- |
| `push()` | 元素入栈（添加至栈顶） | $O(1)$     |
| `pop()`  | 栈顶元素出栈           | $O(1)$     |
| `peek()` | 访问栈顶元素           | $O(1)$     |

通常情况下，我们可以直接使用编程语言内置的栈类。然而，某些语言可能没有专门提供栈类，这时我们可以将该语言的“数组”或“链表”当作栈来使用，并在程序逻辑上忽略与栈无关的操作。

```python
# 初始化栈
# Python 没有内置的栈类，可以把 list 当作栈来使用
stack: list[int] = []

# 元素入栈
stack.append(1)
stack.append(3)
stack.append(2)
stack.append(5)
stack.append(4)

# 访问栈顶元素
peek: int = stack[-1]

# 元素出栈
pop: int = stack.pop()

# 获取栈的长度
size: int = len(stack)

# 判断是否为空
is_empty: bool = len(stack) == 0
```

#### 5.1.2  栈的实现

为了深入了解栈的运行机制，我们来尝试自己实现一个栈类。

栈遵循先入后出的原则，因此我们只能在栈顶添加或删除元素。然而，数组和链表都可以在任意位置添加和删除元素，**因此栈可以视为一种受限制的数组或链表**。换句话说，我们可以“屏蔽”数组或链表的部分无关操作，使其对外表现的逻辑符合栈的特性。

1. 基于链表的实现

   使用链表实现栈时，我们可以将链表的头节点视为栈顶，尾节点视为栈底。

   如图 5-2 所示，对于入栈操作，我们只需将元素插入链表头部，这种节点插入方法被称为“头插法”。而对于出栈操作，只需将头节点从链表中删除即可。

   ![基于链表实现栈的入栈出栈操作](https://www.hello-algo.com/chapter_stack_and_queue/stack.assets/linkedlist_stack_step1.png)

   图 5-2  基于链表实现栈的入栈出栈操作

   以下是基于链表实现栈的示例代码：

   ```python
   class LinkedListStack:
       """基于链表实现的栈"""
   
       def __init__(self):
           """构造方法"""
           self._peek: ListNode | None = None
           self._size: int = 0
   
       def size(self) -> int:
           """获取栈的长度"""
           return self._size
   
       def is_empty(self) -> bool:
           """判断栈是否为空"""
           return self._size == 0
   
       def push(self, val: int):
           """入栈"""
           node = ListNode(val)
           node.next = self._peek
           self._peek = node
           self._size += 1
   
       def pop(self) -> int:
           """出栈"""
           num = self.peek()
           self._peek = self._peek.next
           self._size -= 1
           return num
   
       def peek(self) -> int:
           """访问栈顶元素"""
           if self.is_empty():
               raise IndexError("栈为空")
           return self._peek.val
   
       def to_list(self) -> list[int]:
           """转化为列表用于打印"""
           arr = []
           node = self._peek
           while node:
               arr.append(node.val)
               node = node.next
           arr.reverse()
           return arr
   ```

2.  基于数组的实现

    使用数组实现栈时，我们可以将数组的尾部作为栈顶。如图 5-3 所示，入栈与出栈操作分别对应在数组尾部添加元素与删除元素，时间复杂度都为O(1)。

    ![基于数组实现栈的入栈出栈操作](https://www.hello-algo.com/chapter_stack_and_queue/stack.assets/array_stack_step1.png)

    图 5-3  基于数组实现栈的入栈出栈操作

    由于入栈的元素可能会源源不断地增加，因此我们可以使用动态数组，这样就无须自行处理数组扩容问题。以下为示例代码：

    ```python
    class ArrayStack:
        """基于数组实现的栈"""
    
        def __init__(self):
            """构造方法"""
            self._stack: list[int] = []
    
        def size(self) -> int:
            """获取栈的长度"""
            return len(self._stack)
    
        def is_empty(self) -> bool:
            """判断栈是否为空"""
            return self.size() == 0
    
        def push(self, item: int):
            """入栈"""
            self._stack.append(item)
    
        def pop(self) -> int:
            """出栈"""
            if self.is_empty():
                raise IndexError("栈为空")
            return self._stack.pop()
    
        def peek(self) -> int:
            """访问栈顶元素"""
            if self.is_empty():
                raise IndexError("栈为空")
            return self._stack[-1]
    
        def to_list(self) -> list[int]:
            """返回列表用于打印"""
            return self._stack
    ```


#### 5.1.3  两种实现对比

**支持操作**

两种实现都支持栈定义中的各项操作。数组实现额外支持随机访问，但这已超出了栈的定义范畴，因此一般不会用到。

**时间效率**

在基于数组的实现中，入栈和出栈操作都在预先分配好的连续内存中进行，具有很好的缓存本地性，因此效率较高。然而，如果入栈时超出数组容量，会触发扩容机制，导致该次入栈操作的时间复杂度变为$O(n)$。

在基于链表的实现中，链表的扩容非常灵活，不存在上述数组扩容时效率降低的问题。但是，入栈操作需要初始化节点对象并修改指针，因此效率相对较低。不过，如果入栈元素本身就是节点对象，那么可以省去初始化步骤，从而提高效率。

综上所述，当入栈与出栈操作的元素是基本数据类型时，例如 `int` 或 `double` ，我们可以得出以下结论。

- 基于数组实现的栈在触发扩容时效率会降低，但由于扩容是低频操作，因此平均效率更高。
- 基于链表实现的栈可以提供更加稳定的效率表现。

**空间效率**

在初始化列表时，系统会为列表分配“初始容量”，该容量可能超出实际需求；并且，扩容机制通常是按照特定倍率（例如 2 倍）进行扩容的，扩容后的容量也可能超出实际需求。因此，**基于数组实现的栈可能造成一定的空间浪费**。

然而，由于链表节点需要额外存储指针，**因此链表节点占用的空间相对较大**。

综上，我们不能简单地确定哪种实现更加节省内存，需要针对具体情况进行分析。

#### 5.1.4  栈的典型应用

- **浏览器中的后退与前进、软件中的撤销与反撤销**。每当我们打开新的网页，浏览器就会对上一个网页执行入栈，这样我们就可以通过后退操作回到上一个网页。后退操作实际上是在执行出栈。如果要同时支持后退和前进，那么需要两个栈来配合实现。
- **程序内存管理**。每次调用函数时，系统都会在栈顶添加一个栈帧，用于记录函数的上下文信息。在递归函数中，向下递推阶段会不断执行入栈操作，而向上回溯阶段则会不断执行出栈操作。

### 5.2  队列

队列（queue）是一种遵循先入先出规则的线性数据结构。顾名思义，队列模拟了排队现象，即新来的人不断加入队列尾部，而位于队列头部的人逐个离开。

如图 5-4 所示，我们将队列头部称为“队首”，尾部称为“队尾”，将把元素加入队尾的操作称为“入队”，删除队首元素的操作称为“出队”。

![队列的先入先出规则](https://www.hello-algo.com/chapter_stack_and_queue/queue.assets/queue_operations.png)

图 5-4  队列的先入先出规则

#### 5.2.1  队列常用操作

队列的常见操作如表 5-2 所示。需要注意的是，不同编程语言的方法名称可能会有所不同。我们在此采用与栈相同的方法命名。

表 5-2  队列操作效率

| 方法名   | 描述                         | 时间复杂度 |
| :------- | :--------------------------- | :--------- |
| `push()` | 元素入队，即将元素添加至队尾 | $O(1)$     |
| `pop()`  | 队首元素出队                 | $O(1)$     |
| `peek()` | 访问队首元素                 | $O(1)$     |

我们可以直接使用编程语言中现成的队列类：

```python
from collections import deque

# 初始化队列
# 在 Python 中，我们一般将双向队列类 deque 当作队列使用
# 虽然 queue.Queue() 是纯正的队列类，但不太好用，因此不推荐
que: deque[int] = deque()

# 元素入队
que.append(1)
que.append(3)
que.append(2)
que.append(5)
que.append(4)

# 访问队首元素
front: int = que[0]

# 元素出队
pop: int = que.popleft()

# 获取队列的长度
size: int = len(que)

# 判断队列是否为空
is_empty: bool = len(que) == 0
```

#### 5.2.2  队列实现

为了实现队列，我们需要一种数据结构，可以在一端添加元素，并在另一端删除元素，链表和数组都符合要求。

1. 基于链表的实现

   如图 5-5 所示，我们可以将链表的“头节点”和“尾节点”分别视为“队首”和“队尾”，规定队尾仅可添加节点，队首仅可删除节点。

   ![基于链表实现队列的入队出队操作](https://www.hello-algo.com/chapter_stack_and_queue/queue.assets/linkedlist_queue_step1.png)

   图 5-5  基于链表实现队列的入队出队操作

   以下是用链表实现队列的代码：

   ```python
   class LinkedListQueue:
       """基于链表实现的队列"""
   
       def __init__(self):
           """构造方法"""
           self._front: ListNode | None = None  # 头节点 front
           self._rear: ListNode | None = None  # 尾节点 rear
           self._size: int = 0
   
       def size(self) -> int:
           """获取队列的长度"""
           return self._size
   
       def is_empty(self) -> bool:
           """判断队列是否为空"""
           return self._size == 0
   
       def push(self, num: int):
           """入队"""
           # 在尾节点后添加 num
           node = ListNode(num)
           # 如果队列为空，则令头、尾节点都指向该节点
           if self._front is None:
               self._front = node
               self._rear = node
           # 如果队列不为空，则将该节点添加到尾节点后
           else:
               self._rear.next = node
               self._rear = node
           self._size += 1
   
       def pop(self) -> int:
           """出队"""
           num = self.peek()
           # 删除头节点
           self._front = self._front.next
           self._size -= 1
           return num
   
       def peek(self) -> int:
           """访问队首元素"""
           if self.is_empty():
               raise IndexError("队列为空")
           return self._front.val
   
       def to_list(self) -> list[int]:
           """转化为列表用于打印"""
           queue = []
           temp = self._front
           while temp:
               queue.append(temp.val)
               temp = temp.next
           return queue
   ```

2.  基于数组的实现

    在数组中删除首元素的时间复杂度为$O(n)$，这会导致出队操作效率较低。然而，我们可以采用以下巧妙方法来避免这个问题。

    我们可以使用一个变量 `front` 指向队首元素的索引，并维护一个变量 `size` 用于记录队列长度。定义 `rear = front + size` ，这个公式计算出的 `rear` 指向队尾元素之后的下一个位置。

    基于此设计，**数组中包含元素的有效区间为 `[front, rear - 1]`**，各种操作的实现方法如图 5-6 所示。

    - 入队操作：将输入元素赋值给 `rear` 索引处，并将 `size` 增加 1 。
    - 出队操作：只需将 `front` 增加 1 ，并将 `size` 减少 1 。

    可以看到，入队和出队操作都只需进行一次操作，时间复杂度均为$O(1)$。

    ![基于数组实现队列的入队出队操作](https://www.hello-algo.com/chapter_stack_and_queue/queue.assets/array_queue_step1.png)

    图 5-6  基于数组实现队列的入队出队操作

    你可能会发现一个问题：在不断进行入队和出队的过程中，`front` 和 `rear` 都在向右移动，**当它们到达数组尾部时就无法继续移动了**。为了解决此问题，我们可以将数组视为首尾相接的“环形数组”。

    对于环形数组，我们需要让 `front` 或 `rear` 在越过数组尾部时，直接回到数组头部继续遍历。这种周期性规律可以通过“取余操作”来实现，代码如下所示：

    ```python
    class ArrayQueue:
        """基于环形数组实现的队列"""
    
        def __init__(self, size: int):
            """构造方法"""
            self._nums: list[int] = [0] * size  # 用于存储队列元素的数组
            self._front: int = 0  # 队首指针，指向队首元素
            self._size: int = 0  # 队列长度
    
        def capacity(self) -> int:
            """获取队列的容量"""
            return len(self._nums)
    
        def size(self) -> int:
            """获取队列的长度"""
            return self._size
    
        def is_empty(self) -> bool:
            """判断队列是否为空"""
            return self._size == 0
    
        def push(self, num: int):
            """入队"""
            if self._size == self.capacity():
                raise IndexError("队列已满")
            # 计算队尾指针，指向队尾索引 + 1
            # 通过取余操作实现 rear 越过数组尾部后回到头部
            rear: int = (self._front + self._size) % self.capacity()
            # 将 num 添加至队尾
            self._nums[rear] = num
            self._size += 1
    
        def pop(self) -> int:
            """出队"""
            num: int = self.peek()
            # 队首指针向后移动一位，若越过尾部，则返回到数组头部
            self._front = (self._front + 1) % self.capacity()
            self._size -= 1
            return num
    
        def peek(self) -> int:
            """访问队首元素"""
            if self.is_empty():
                raise IndexError("队列为空")
            return self._nums[self._front]
    
        def to_list(self) -> list[int]:
            """返回列表用于打印"""
            res = [0] * self.size()
            j: int = self._front
            for i in range(self.size()):
                res[i] = self._nums[(j % self.capacity())]
                j += 1
            return res
    ```

    以上实现的队列仍然具有局限性：其长度不可变。然而，这个问题不难解决，我们可以将数组替换为动态数组，从而引入扩容机制。有兴趣的读者可以尝试自行实现。

    两种实现的对比结论与栈一致，在此不再赘述。

#### 5.2.3  队列典型应用

- **淘宝订单**。购物者下单后，订单将加入队列中，系统随后会根据顺序处理队列中的订单。在双十一期间，短时间内会产生海量订单，高并发成为工程师们需要重点攻克的问题。
- **各类待办事项**。任何需要实现“先来后到”功能的场景，例如打印机的任务队列、餐厅的出餐队列等，队列在这些场景中可以有效地维护处理顺序。

#### Comment

![image-20250803153604695](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250803153604695.png)

循环队列长度=(rear-front+maxsize)%maxsize

循环队列（记得手写例子判断一下条件对不对）

1. 头指针指向当前队头，尾指针指向队尾后一个位置，需要牺牲一个存储单元来判断队满

   队空：Q.rear==Q.front

   队满：(Q.rear+1)%Maxsize==Q.front

   队列元素个数：(rear-front+maxsize)%maxsize

2. 设置一个变量size，入队时+1，出队时-1，无需牺牲一个存储单元

   队空：size=0

   队满：size=Maxsize

   队列元素个数：size

3. 增加一个标志位tag，只有入队(tag=1)才能导致队满，出队(tag=0)才能导致队空，无需牺牲一个存储单元

   队空：front==rear&&tag==0

   队满：front==rear&&tag==1

   队列元素个数：(rear-front+maxsize)%maxsize

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754206898626.png)

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754206927462.png)

[如何理解 Python 列表的可变性](https://blog.csdn.net/weixin_41971448/article/details/149864762?spm=1001.2014.3001.5501)

### 5.3  双向队列

在队列中，我们仅能删除头部元素或在尾部添加元素。如图 5-7 所示，双向队列（double-ended queue）提供了更高的灵活性，允许在头部和尾部执行元素的添加或删除操作。

![双向队列的操作](https://www.hello-algo.com/chapter_stack_and_queue/deque.assets/deque_operations.png)

图 5-7  双向队列的操作

#### 5.3.1  双向队列常用操作

双向队列的常用操作如表 5-3 所示，具体的方法名称需要根据所使用的编程语言来确定。

表 5-3  双向队列操作效率

| 方法名         | 描述             | 时间复杂度 |
| :------------- | :--------------- | :--------- |
| `push_first()` | 将元素添加至队首 | $O(1)$     |
| `push_last()`  | 将元素添加至队尾 | $O(1)$     |
| `pop_first()`  | 删除队首元素     | $O(1)$     |
| `pop_last()`   | 删除队尾元素     | $O(1)$     |
| `peek_first()` | 访问队首元素     | $O(1)$     |
| `peek_last()`  | 访问队尾元素     | $O(1)$     |

```python
from collections import deque

# 初始化双向队列
deq: deque[int] = deque()

# 元素入队
deq.append(2)      # 添加至队尾
deq.append(5)
deq.append(4)
deq.appendleft(3)  # 添加至队首
deq.appendleft(1)

# 访问元素
front: int = deq[0]  # 队首元素
rear: int = deq[-1]  # 队尾元素

# 元素出队
pop_front: int = deq.popleft()  # 队首元素出队
pop_rear: int = deq.pop()       # 队尾元素出队

# 获取双向队列的长度
size: int = len(deq)

# 判断双向队列是否为空
is_empty: bool = len(deq) == 0
```

#### 5.3.2  双向队列实现 *

双向队列的实现与队列类似，可以选择链表或数组作为底层数据结构。

1. 基于双向链表的实现

   回顾上一节内容，我们使用普通单向链表来实现队列，因为它可以方便地删除头节点（对应出队操作）和在尾节点后添加新节点（对应入队操作）。

   对于双向队列而言，头部和尾部都可以执行入队和出队操作。换句话说，双向队列需要实现另一个对称方向的操作。为此，我们采用“双向链表”作为双向队列的底层数据结构。

   如图 5-8 所示，我们将双向链表的头节点和尾节点视为双向队列的队首和队尾，同时实现在两端添加和删除节点的功能。

   ![基于链表实现双向队列的入队出队操作](https://www.hello-algo.com/chapter_stack_and_queue/deque.assets/linkedlist_deque_step1.png)

   图 5-8  基于链表实现双向队列的入队出队操作

   实现代码如下所示：

   ```python
   class ListNode:
       """双向链表节点"""
   
       def __init__(self, val: int):
           """构造方法"""
           self.val: int = val
           self.next: ListNode | None = None  # 后继节点引用
           self.prev: ListNode | None = None  # 前驱节点引用
   
   class LinkedListDeque:
       """基于双向链表实现的双向队列"""
   
       def __init__(self):
           """构造方法"""
           self._front: ListNode | None = None  # 头节点 front
           self._rear: ListNode | None = None  # 尾节点 rear
           self._size: int = 0  # 双向队列的长度
   
       def size(self) -> int:
           """获取双向队列的长度"""
           return self._size
   
       def is_empty(self) -> bool:
           """判断双向队列是否为空"""
           return self._size == 0
   
       def push(self, num: int, is_front: bool):
           """入队操作"""
           node = ListNode(num)
           # 若链表为空，则令 front 和 rear 都指向 node
           if self.is_empty():
               self._front = self._rear = node
           # 队首入队操作
           elif is_front:
               # 将 node 添加至链表头部
               self._front.prev = node
               node.next = self._front
               self._front = node  # 更新头节点
           # 队尾入队操作
           else:
               # 将 node 添加至链表尾部
               self._rear.next = node
               node.prev = self._rear
               self._rear = node  # 更新尾节点
           self._size += 1  # 更新队列长度
   
       def push_first(self, num: int):
           """队首入队"""
           self.push(num, True)
   
       def push_last(self, num: int):
           """队尾入队"""
           self.push(num, False)
   
       def pop(self, is_front: bool) -> int:
           """出队操作"""
           if self.is_empty():
               raise IndexError("双向队列为空")
           # 队首出队操作
           if is_front:
               val: int = self._front.val  # 暂存头节点值
               # 删除头节点
               fnext: ListNode | None = self._front.next
               # self.front 也可以不指向非空元素，因为已经无法访问到它，在逻辑上它已经不在链表中了。但是可能会导致一些少见的内存回收 Bug
               if fnext is not None:
                   fnext.prev = None
                   self._front.next = None
               self._front = fnext  # 更新头节点
           # 队尾出队操作
           else:
               val: int = self._rear.val  # 暂存尾节点值
               # 删除尾节点
               rprev: ListNode | None = self._rear.prev
               if rprev is not None:
                   rprev.next = None
                   self._rear.prev = None
               self._rear = rprev  # 更新尾节点
           self._size -= 1  # 更新队列长度
           return val
   
       def pop_first(self) -> int:
           """队首出队"""
           return self.pop(True)
   
       def pop_last(self) -> int:
           """队尾出队"""
           return self.pop(False)
   
       def peek_first(self) -> int:
           """访问队首元素"""
           if self.is_empty():
               raise IndexError("双向队列为空")
           return self._front.val
   
       def peek_last(self) -> int:
           """访问队尾元素"""
           if self.is_empty():
               raise IndexError("双向队列为空")
           return self._rear.val
   
       def to_array(self) -> list[int]:
           """返回数组用于打印"""
           node = self._front
           res = [0] * self.size()
           for i in range(self.size()):
               res[i] = node.val
               node = node.next
           return res
   ```

2.  基于数组的实现

    如图 5-9 所示，与基于数组实现队列类似，我们也可以使用环形数组来实现双向队列。

    ![基于数组实现双向队列的入队出队操作](https://www.hello-algo.com/chapter_stack_and_queue/deque.assets/array_deque_step1.png)

    图 5-9  基于数组实现双向队列的入队出队操作

    在队列的实现基础上，仅需增加“队首入队”和“队尾出队”的方法：

    ```python
    class ArrayDeque:
        """基于环形数组实现的双向队列"""
    
        def __init__(self, capacity: int):
            """构造方法"""
            self._nums: list[int] = [0] * capacity
            self._front: int = 0
            self._size: int = 0
    
        def capacity(self) -> int:
            """获取双向队列的容量"""
            return len(self._nums)
    
        def size(self) -> int:
            """获取双向队列的长度"""
            return self._size
    
        def is_empty(self) -> bool:
            """判断双向队列是否为空"""
            return self._size == 0
    
        def index(self, i: int) -> int:
            """计算环形数组索引"""
            # 通过取余操作实现数组首尾相连
            # 当 i 越过数组尾部后，回到头部
            # 当 i 越过数组头部后，回到尾部
            # i + self.capacity() 的目的是避免 i 为负数时取余运算出现不符合预期的结果，确保取余后得到的索引始终是非负的有效索引。
            return (i + self.capacity()) % self.capacity()
    
        def push_first(self, num: int):
            """队首入队"""
            if self._size == self.capacity():
                print("双向队列已满")
                return
            # 队首指针向左移动一位
            # 通过取余操作实现 front 越过数组头部后回到尾部
            self._front = self.index(self._front - 1)
            # 将 num 添加至队首
            self._nums[self._front] = num
            self._size += 1
    
        def push_last(self, num: int):
            """队尾入队"""
            if self._size == self.capacity():
                print("双向队列已满")
                return
            # 计算队尾指针，指向队尾索引 + 1
            rear = self.index(self._front + self._size)
            # 将 num 添加至队尾
            self._nums[rear] = num
            self._size += 1
    
        def pop_first(self) -> int:
            """队首出队"""
            num = self.peek_first()
            # 队首指针向后移动一位
            self._front = self.index(self._front + 1)
            self._size -= 1
            return num
    
        def pop_last(self) -> int:
            """队尾出队"""
            num = self.peek_last()
            self._size -= 1
            return num
    
        def peek_first(self) -> int:
            """访问队首元素"""
            if self.is_empty():
                raise IndexError("双向队列为空")
            return self._nums[self._front]
    
        def peek_last(self) -> int:
            """访问队尾元素"""
            if self.is_empty():
                raise IndexError("双向队列为空")
            # 计算尾元素索引
            last = self.index(self._front + self._size - 1)
            return self._nums[last]
    
        def to_array(self) -> list[int]:
            """返回数组用于打印"""
            # 仅转换有效长度范围内的列表元素
            res = []
            for i in range(self._size):
                res.append(self._nums[self.index(self._front + i)])
            return res
    ```

#### 5.3.3  双向队列应用

双向队列兼具栈与队列的逻辑，**因此它可以实现这两者的所有应用场景，同时提供更高的自由度**。

我们知道，软件的“撤销”功能通常使用栈来实现：系统将每次更改操作 `push` 到栈中，然后通过 `pop` 实现撤销。然而，考虑到系统资源的限制，软件通常会限制撤销的步数（例如仅允许保存50步）。当栈的长度超过50时，软件需要在栈底（队首）执行删除操作。**但栈无法实现该功能，此时就需要使用双向队列来替代栈**。请注意，“撤销”的核心逻辑仍然遵循栈的先入后出原则，只是双向队列能够更加灵活地实现一些额外逻辑。

### 5.4  小结

1. 重点回顾

   - 栈是一种遵循先入后出原则的数据结构，可通过数组或链表来实现。
   - 在时间效率方面，栈的数组实现具有较高的平均效率，但在扩容过程中，单次入栈操作的时间复杂度会劣化至$O(n)$。相比之下，栈的链表实现具有更为稳定的效率表现。
   - 在空间效率方面，栈的数组实现可能导致一定程度的空间浪费。但需要注意的是，链表节点所占用的内存空间比数组元素更大。
   - 队列是一种遵循先入先出原则的数据结构，同样可以通过数组或链表来实现。在时间效率和空间效率的对比上，队列的结论与前述栈的结论相似。
   - 双向队列是一种具有更高自由度的队列，它允许在两端进行元素的添加和删除操作。

2.  Q & A

    **Q**：浏览器的前进后退是否是双向链表实现？

    浏览器的前进后退功能本质上是“栈”的体现。当用户访问一个新页面时，该页面会被添加到栈顶；当用户点击后退按钮时，该页面会从栈顶弹出。使用双向队列可以方便地实现一些额外操作，这个在“双向队列”章节有提到。

    **Q**：在出栈后，是否需要释放出栈节点的内存？

    如果后续仍需要使用弹出节点，则不需要释放内存。若之后不需要用到，`Java` 和 `Python` 等语言拥有自动垃圾回收机制，因此不需要手动释放内存；在 `C` 和 `C++` 中需要手动释放内存。

    **Q**：双向队列像是两个栈拼接在了一起，它的用途是什么？

    双向队列就像是栈和队列的组合或两个栈拼在了一起。它表现的是栈 + 队列的逻辑，因此可以实现栈与队列的所有应用，并且更加灵活。

    **Q**：撤销（undo）和反撤销（redo）具体是如何实现的？

    使用两个栈，栈 `A` 用于撤销，栈 `B` 用于反撤销。

    1. 每当用户执行一个操作，将这个操作压入栈 `A` ，并清空栈 `B` 。
    2. 当用户执行“撤销”时，从栈 `A` 中弹出最近的操作，并将其压入栈 `B` 。
    3. 当用户执行“反撤销”时，从栈 `B` 中弹出最近的操作，并将其压入栈 `A` 。

## 第 6 章  哈希表

### 6.1  哈希表

哈希表（hash table），又称散列表，它通过建立键 `key` 与值 `value` 之间的映射，实现高效的元素查询。具体而言，我们向哈希表中输入一个键 `key` ，则可以在$O(1)$时间内获取对应的值 `value` 。

如图 6-1 所示，给定n个学生，每个学生都有“姓名”和“学号”两项数据。假如我们希望实现“输入一个学号，返回对应的姓名”的查询功能，则可以采用图 6-1 所示的哈希表来实现。

![哈希表的抽象表示](https://www.hello-algo.com/chapter_hashing/hash_map.assets/hash_table_lookup.png)

图 6-1  哈希表的抽象表示

除哈希表外，数组和链表也可以实现查询功能，它们的效率对比如表 6-1 所示。

- **添加元素**：仅需将元素添加至数组（链表）的尾部即可，使用$O(1)$时间。
- **查询元素**：由于数组（链表）是乱序的，因此需要遍历其中的所有元素，使用$O(n)$时间。
- **删除元素**：需要先查询到元素，再从数组（链表）中删除，使用$O(n)$时间。

|          | 数组   | 链表   | 哈希表 |
| :------- | :----- | :----- | ------ |
| 查找元素 | $O(n)$ | $O(n)$ | $O(1)$ |
| 添加元素 | $O(1)$ | $O(1)$ | $O(1)$ |
| 删除元素 | $O(n)$ | $O(n)$ | $O(1)$ |

观察发现，**在哈希表中进行增删查改的时间复杂度都是**$O(1)$，非常高效。

#### 6.1.1  哈希表常用操作

哈希表的常见操作包括：初始化、查询操作、添加键值对和删除键值对等，示例代码如下：

```python
# 初始化哈希表
hmap: dict = {}

# 添加操作
# 在哈希表中添加键值对 (key, value)
hmap[12836] = "小哈"
hmap[15937] = "小啰"
hmap[16750] = "小算"
hmap[13276] = "小法"
hmap[10583] = "小鸭"

# 查询操作
# 向哈希表中输入键 key ，得到值 value
name: str = hmap[15937]

# 删除操作
# 在哈希表中删除键值对 (key, value)
hmap.pop(10583)
```

哈希表有三种常用的遍历方式：遍历键值对、遍历键和遍历值。示例代码如下：

```python
# 遍历哈希表
# 遍历键值对 key->value
for key, value in hmap.items():
    print(key, "->", value)
# 单独遍历键 key
for key in hmap.keys():
    print(key)
# 单独遍历值 value
for value in hmap.values():
    print(value)
```

#### 6.1.2  哈希表简单实现

我们先考虑最简单的情况，**仅用一个数组来实现哈希表**。在哈希表中，我们将数组中的每个空位称为桶（bucket），每个桶可存储一个键值对。因此，查询操作就是找到 `key` 对应的桶，并在桶中获取 `value` 。

那么，如何基于 `key` 定位对应的桶呢？这是通过哈希函数（hash function）实现的。哈希函数的作用是将一个较大的输入空间映射到一个较小的输出空间。在哈希表中，输入空间是所有 `key` ，输出空间是所有桶（数组索引）。换句话说，输入一个 `key` ，**我们可以通过哈希函数得到该 `key` 对应的键值对在数组中的存储位置**。

输入一个 `key` ，哈希函数的计算过程分为以下两步。

1. 通过某种哈希算法 `hash()` 计算得到哈希值。
2. 将哈希值对桶数量（数组长度）`capacity` 取模，从而获取该 `key` 对应的数组索引 `index` 。

```python
index = hash(key) % capacity
```

随后，我们就可以利用 `index` 在哈希表中访问对应的桶，从而获取 `value` 。

设数组长度 `capacity = 100`、哈希算法 `hash(key) = key` ，易得哈希函数为 `key % 100` 。图 6-2 以 `key` 学号和 `value` 姓名为例，展示了哈希函数的工作原理。

![哈希函数工作原理](https://www.hello-algo.com/chapter_hashing/hash_map.assets/hash_function.png)

图 6-2  哈希函数工作原理

以下代码实现了一个简单哈希表。其中，我们将 `key` 和 `value` 封装成一个类 `Pair` ，以表示键值对。

```python
class Pair:
    """键值对"""

    def __init__(self, key: int, val: str):
        self.key = key
        self.val = val

class ArrayHashMap:
    """基于数组实现的哈希表"""

    def __init__(self):
        """构造方法"""
        # 初始化数组，包含 100 个桶
        self.buckets: list[Pair | None] = [None] * 100

    def hash_func(self, key: int) -> int:
        """哈希函数"""
        index = key % 100
        return index

    def get(self, key: int) -> str:
        """查询操作"""
        index: int = self.hash_func(key)
        pair: Pair = self.buckets[index]
        if pair is None:
            return None
        return pair.val

    def put(self, key: int, val: str):
        """添加操作"""
        pair = Pair(key, val)
        index: int = self.hash_func(key)
        self.buckets[index] = pair

    def remove(self, key: int):
        """删除操作"""
        index: int = self.hash_func(key)
        # 置为 None ，代表删除
        self.buckets[index] = None

    def entry_set(self) -> list[Pair]:
        """获取所有键值对"""
        result: list[Pair] = []
        for pair in self.buckets:
            if pair is not None:
                result.append(pair)
        return result

    def key_set(self) -> list[int]:
        """获取所有键"""
        result = []
        for pair in self.buckets:
            if pair is not None:
                result.append(pair.key)
        return result

    def value_set(self) -> list[str]:
        """获取所有值"""
        result = []
        for pair in self.buckets:
            if pair is not None:
                result.append(pair.val)
        return result

    def print(self):
        """打印哈希表"""
        for pair in self.buckets:
            if pair is not None:
                print(pair.key, "->", pair.val)
```

#### 6.1.3  哈希冲突与扩容

从本质上看，哈希函数的作用是将所有 `key` 构成的输入空间映射到数组所有索引构成的输出空间，而输入空间往往远大于输出空间。因此，**理论上一定存在“多个输入对应相同输出”的情况**。

对于上述示例中的哈希函数，当输入的 `key` 后两位相同时，哈希函数的输出结果也相同。例如，查询学号为 12836 和 20336 的两个学生时，我们得到：

```python
12836 % 100 = 36
20336 % 100 = 36
```

如图 6-3 所示，两个学号指向了同一个姓名，这显然是不对的。我们将这种多个输入对应同一输出的情况称为哈希冲突（hash collision）。

![哈希冲突示例](https://www.hello-algo.com/chapter_hashing/hash_map.assets/hash_collision.png)

图 6-3  哈希冲突示例

容易想到，哈希表容量n越大，多个 `key` 被分配到同一个桶中的概率就越低，冲突就越少。因此，**我们可以通过扩容哈希表来减少哈希冲突**。

如图 6-4 所示，扩容前键值对 `(136, A)` 和 `(236, D)` 发生冲突，扩容后冲突消失。

![哈希表扩容](https://www.hello-algo.com/chapter_hashing/hash_map.assets/hash_table_reshash.png)

图 6-4  哈希表扩容

类似于数组扩容，哈希表扩容需将所有键值对从原哈希表迁移至新哈希表，非常耗时；并且由于哈希表容量 `capacity` 改变，我们需要通过哈希函数来重新计算所有键值对的存储位置，这进一步增加了扩容过程的计算开销。为此，编程语言通常会预留足够大的哈希表容量，防止频繁扩容。

负载因子（load factor）是哈希表的一个重要概念，其定义为哈希表的元素数量除以桶数量，用于衡量哈希冲突的严重程度，**也常作为哈希表扩容的触发条件**。例如在 Java 中，当负载因子超过0.75时，系统会将哈希表扩容至原先的2倍。

#### Comment

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754296963099.png)

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754297150698.png)

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754297305366.png)

### 6.2  哈希冲突

上一节提到，**通常情况下哈希函数的输入空间远大于输出空间**，因此理论上哈希冲突是不可避免的。比如，输入空间为全体整数，输出空间为数组容量大小，则必然有多个整数映射至同一桶索引。

哈希冲突会导致查询结果错误，严重影响哈希表的可用性。为了解决该问题，每当遇到哈希冲突时，我们就进行哈希表扩容，直至冲突消失为止。此方法简单粗暴且有效，但效率太低，因为哈希表扩容需要进行大量的数据搬运与哈希值计算。为了提升效率，我们可以采用以下策略。

1. 改良哈希表数据结构，**使得哈希表可以在出现哈希冲突时正常工作**。
2. 仅在必要时，即当哈希冲突比较严重时，才执行扩容操作。

哈希表的结构改良方法主要包括“链式地址”和“开放寻址”。

#### 6.2.1  链式地址

在原始哈希表中，每个桶仅能存储一个键值对。链式地址（separate chaining）将单个元素转换为链表，将键值对作为链表节点，将所有发生冲突的键值对都存储在同一链表中。图 6-5 展示了一个链式地址哈希表的例子。

![链式地址哈希表](https://www.hello-algo.com/chapter_hashing/hash_collision.assets/hash_table_chaining.png)

图 6-5  链式地址哈希表

基于链式地址实现的哈希表的操作方法发生了以下变化。

- **查询元素**：输入 `key` ，经过哈希函数得到桶索引，即可访问链表头节点，然后遍历链表并对比 `key` 以查找目标键值对。
- **添加元素**：首先通过哈希函数访问链表头节点，然后将节点（键值对）添加到链表中。
- **删除元素**：根据哈希函数的结果访问链表头部，接着遍历链表以查找目标节点并将其删除。

链式地址存在以下局限性。

- **占用空间增大**：链表包含节点指针，它相比数组更加耗费内存空间。
- **查询效率降低**：因为需要线性遍历链表来查找对应元素。

以下代码给出了链式地址哈希表的简单实现，需要注意两点。

- 使用列表（动态数组）代替链表，从而简化代码。在这种设定下，哈希表（数组）包含多个桶，每个桶都是一个列表。
- 以下实现包含哈希表扩容方法。当负载因子超过$2/3$时，我们将哈希表扩容至原先的2倍。

```python
class HashMapChaining:
    """链式地址哈希表"""

    def __init__(self):
        """构造方法"""
        self.size = 0  # 键值对数量
        self.capacity = 4  # 哈希表容量
        self.load_thres = 2.0 / 3.0  # 触发扩容的负载因子阈值
        self.extend_ratio = 2  # 扩容倍数
        self.buckets = [[] for _ in range(self.capacity)]  # 桶数组

    def hash_func(self, key: int) -> int:
        """哈希函数"""
        return key % self.capacity

    def load_factor(self) -> float:
        """负载因子"""
        return self.size / self.capacity

    def get(self, key: int) -> str | None:
        """查询操作"""
        index = self.hash_func(key)
        bucket = self.buckets[index]
        # 遍历桶，若找到 key ，则返回对应 val
        for pair in bucket:
            if pair.key == key:
                return pair.val
        # 若未找到 key ，则返回 None
        return None

    def put(self, key: int, val: str):
        """添加操作"""
        # 当负载因子超过阈值时，执行扩容
        if self.load_factor() > self.load_thres:
            self.extend()
        index = self.hash_func(key)
        bucket = self.buckets[index]
        # 遍历桶，若遇到指定 key ，则更新对应 val 并返回
        for pair in bucket:
            if pair.key == key:
                pair.val = val
                return
        # 若无该 key ，则将键值对添加至尾部
        pair = Pair(key, val)
        bucket.append(pair)
        self.size += 1

    def remove(self, key: int):
        """删除操作"""
        index = self.hash_func(key)
        bucket = self.buckets[index]
        # 遍历桶，从中删除键值对
        for pair in bucket:
            if pair.key == key:
                bucket.remove(pair)
                self.size -= 1
                break

    def extend(self):
        """扩容哈希表"""
        # 暂存原哈希表
        buckets = self.buckets
        # 初始化扩容后的新哈希表
        self.capacity *= self.extend_ratio
        self.buckets = [[] for _ in range(self.capacity)]
        self.size = 0
        # 将键值对从原哈希表搬运至新哈希表
        for bucket in buckets:
            for pair in bucket:
                self.put(pair.key, pair.val)

    def print(self):
        """打印哈希表"""
        for bucket in self.buckets:
            res = []
            for pair in bucket:
                res.append(str(pair.key) + " -> " + pair.val)
            print(res)
```

值得注意的是，当链表很长时，查询效率$O(n)$很差。**此时可以将链表转换为“AVL 树”或“红黑树”**，从而将查询操作的时间复杂度优化至$O(log n)$。

#### 6.2.2  开放寻址

开放寻址（open addressing）不引入额外的数据结构，而是通过“多次探测”来处理哈希冲突，探测方式主要包括线性探测、平方探测和多次哈希等。

下面以线性探测为例，介绍开放寻址哈希表的工作机制。

1. 线性探测

   线性探测采用固定步长的线性搜索来进行探测，其操作方法与普通哈希表有所不同。

   - **插入元素**：通过哈希函数计算桶索引，若发现桶内已有元素，则从冲突位置向后线性遍历（步长通常为1），直至找到空桶，将元素插入其中。
   - **查找元素**：若发现哈希冲突，则使用相同步长向后进行线性遍历，直到找到对应元素，返回 `value` 即可；如果遇到空桶，说明目标元素不在哈希表中，返回 `None` 。

   图 6-6 展示了开放寻址（线性探测）哈希表的键值对分布。根据此哈希函数，最后两位相同的 `key` 都会被映射到相同的桶。而通过线性探测，它们被依次存储在该桶以及之下的桶中。

   ![开放寻址（线性探测）哈希表的键值对分布](https://www.hello-algo.com/chapter_hashing/hash_collision.assets/hash_table_linear_probing.png)

   图 6-6  开放寻址（线性探测）哈希表的键值对分布

   然而，**线性探测容易产生“聚集现象”**。具体来说，数组中连续被占用的位置越长，这些连续位置发生哈希冲突的可能性越大，从而进一步促使该位置的聚堆生长，形成恶性循环，最终导致增删查改操作效率劣化。

   值得注意的是，**我们不能在开放寻址哈希表中直接删除元素**。这是因为删除元素会在数组内产生一个空桶 `None` ，而当查询元素时，线性探测到该空桶就会返回，因此在该空桶之下的元素都无法再被访问到，程序可能误判这些元素不存在，如图 6-7 所示。

   ![在开放寻址中删除元素导致的查询问题](https://www.hello-algo.com/chapter_hashing/hash_collision.assets/hash_table_open_addressing_deletion.png)

   图 6-7  在开放寻址中删除元素导致的查询问题

   为了解决该问题，我们可以采用懒删除（lazy deletion）机制：它不直接从哈希表中移除元素，**而是利用一个常量 `TOMBSTONE` 来标记这个桶**。在该机制下，`None` 和 `TOMBSTONE` 都代表空桶，都可以放置键值对。但不同的是，线性探测到 `TOMBSTONE` 时应该继续遍历，因为其之下可能还存在键值对。

   然而，**懒删除可能会加速哈希表的性能退化**。这是因为每次删除操作都会产生一个删除标记，随着 `TOMBSTONE` 的增加，搜索时间也会增加，因为线性探测可能需要跳过多个 `TOMBSTONE` 才能找到目标元素。

   为此，考虑在线性探测中记录遇到的首个 `TOMBSTONE` 的索引，并将搜索到的目标元素与该 `TOMBSTONE` 交换位置。这样做的好处是当每次查询或添加元素时，元素会被移动至距离理想位置（探测起始点）更近的桶，从而优化查询效率。

   以下代码实现了一个包含懒删除的开放寻址（线性探测）哈希表。为了更加充分地使用哈希表的空间，我们将哈希表看作一个“环形数组”，当越过数组尾部时，回到头部继续遍历。

   ```python
   class HashMapOpenAddressing:
       """开放寻址哈希表"""
   
       def __init__(self):
           """构造方法"""
           self.size = 0  # 键值对数量
           self.capacity = 4  # 哈希表容量
           self.load_thres = 2.0 / 3.0  # 触发扩容的负载因子阈值
           self.extend_ratio = 2  # 扩容倍数
           self.buckets: list[Pair | None] = [None] * self.capacity  # 桶数组
           self.TOMBSTONE = Pair(-1, "-1")  # 删除标记
   
       def hash_func(self, key: int) -> int:
           """哈希函数"""
           return key % self.capacity
   
       def load_factor(self) -> float:
           """负载因子"""
           return self.size / self.capacity
   
       def find_bucket(self, key: int) -> int:
           """搜索 key 对应的桶索引"""
           index = self.hash_func(key)
           first_tombstone = -1
           # 线性探测，当遇到空桶时跳出
           while self.buckets[index] is not None:
               # 若遇到 key ，返回对应的桶索引
               if self.buckets[index].key == key:
                   # 若之前遇到了删除标记，则将键值对移动至该索引处
                   if first_tombstone != -1:
                       self.buckets[first_tombstone] = self.buckets[index]
                       self.buckets[index] = self.TOMBSTONE
                       return first_tombstone  # 返回移动后的桶索引
                   return index  # 返回桶索引
               # 记录遇到的首个删除标记
               if first_tombstone == -1 and self.buckets[index] is self.TOMBSTONE:
                   first_tombstone = index
               # 计算桶索引，越过尾部则返回头部
               index = (index + 1) % self.capacity
           # 若 key 不存在，则返回添加点的索引
           return index if first_tombstone == -1 else first_tombstone
   
       def get(self, key: int) -> str:
           """查询操作"""
           # 搜索 key 对应的桶索引
           index = self.find_bucket(key)
           # 若找到键值对，则返回对应 val
           if self.buckets[index] not in [None, self.TOMBSTONE]:
               return self.buckets[index].val
           # 若键值对不存在，则返回 None
           return None
   
       def put(self, key: int, val: str):
           """添加操作"""
           # 当负载因子超过阈值时，执行扩容
           if self.load_factor() > self.load_thres:
               self.extend()
           # 搜索 key 对应的桶索引
           index = self.find_bucket(key)
           # 若找到键值对，则覆盖 val 并返回
           if self.buckets[index] not in [None, self.TOMBSTONE]:
               self.buckets[index].val = val
               return
           # 若键值对不存在，则添加该键值对
           self.buckets[index] = Pair(key, val)
           self.size += 1
   
       def remove(self, key: int):
           """删除操作"""
           # 搜索 key 对应的桶索引
           index = self.find_bucket(key)
           # 若找到键值对，则用删除标记覆盖它
           if self.buckets[index] not in [None, self.TOMBSTONE]:
               self.buckets[index] = self.TOMBSTONE
               self.size -= 1
   
       def extend(self):
           """扩容哈希表"""
           # 暂存原哈希表
           buckets_tmp = self.buckets
           # 初始化扩容后的新哈希表
           self.capacity *= self.extend_ratio
           self.buckets = [None] * self.capacity
           self.size = 0
           # 将键值对从原哈希表搬运至新哈希表
           for pair in buckets_tmp:
               if pair not in [None, self.TOMBSTONE]:
                   self.put(pair.key, pair.val)
   
       def print(self):
           """打印哈希表"""
           for pair in self.buckets:
               if pair is None:
                   print("None")
               elif pair is self.TOMBSTONE:
                   print("TOMBSTONE")
               else:
                   print(pair.key, "->", pair.val)
   ```

2.  平方探测

    平方探测与线性探测类似，都是开放寻址的常见策略之一。当发生冲突时，平方探测不是简单地跳过一个固定的步数，而是跳过“探测次数的平方”的步数，即1，4，9，...步。

    平方探测主要具有以下优势。

    - 平方探测通过跳过探测次数平方的距离，试图缓解线性探测的聚集效应。
    - 平方探测会跳过更大的距离来寻找空位置，有助于数据分布得更加均匀。

    然而，平方探测并不是完美的。

    - 仍然存在聚集现象，即某些位置比其他位置更容易被占用。
    - 由于平方的增长，平方探测可能不会探测整个哈希表，这意味着即使哈希表中有空桶，平方探测也可能无法访问到它。

3.  多次哈希

    顾名思义，多次哈希方法使用多个哈希函数$f_1(x)$ 、$f_2(x)$、$f_3(x)$进行探测。

    - **插入元素**：若哈希函数$f_1(x)$出现冲突，则尝试$f_2(x)$，以此类推，直到找到空位后插入元素。
    - **查找元素**：在相同的哈希函数顺序下进行查找，直到找到目标元素时返回；若遇到空位或已尝试所有哈希函数，说明哈希表中不存在该元素，则返回 `None` 。

    与线性探测相比，多次哈希方法不易产生聚集，但多个哈希函数会带来额外的计算量。

> 请注意，开放寻址（线性探测、平方探测和多次哈希）哈希表都存在“不能直接删除元素”的问题。

#### 6.2.3  编程语言的选择

各种编程语言采取了不同的哈希表实现策略，下面举几个例子。

- Python 采用开放寻址。字典 `dict` 使用伪随机数进行探测。
- Java 采用链式地址。自 JDK 1.8 以来，当 `HashMap` 内数组长度达到 64 且链表长度达到 8 时，链表会转换为红黑树以提升查找性能。
- Go 采用链式地址。Go 规定每个桶最多存储 8 个键值对，超出容量则连接一个溢出桶；当溢出桶过多时，会执行一次特殊的等量扩容操作，以确保性能。

#### Comment

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754304145575.png)

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754304212524.png)

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1754304280555.png)

### 6.3  哈希算法

前两节介绍了哈希表的工作原理和哈希冲突的处理方法。然而无论是开放寻址还是链式地址，**它们只能保证哈希表可以在发生冲突时正常工作，而无法减少哈希冲突的发生**。

如果哈希冲突过于频繁，哈希表的性能则会急剧劣化。如图 6-8 所示，对于链式地址哈希表，理想情况下键值对均匀分布在各个桶中，达到最佳查询效率；最差情况下所有键值对都存储到同一个桶中，时间复杂度退化至$O(n)$。

![哈希冲突的最佳情况与最差情况](https://www.hello-algo.com/chapter_hashing/hash_algorithm.assets/hash_collision_best_worst_condition.png)

图 6-8  哈希冲突的最佳情况与最差情况

**键值对的分布情况由哈希函数决定**。回忆哈希函数的计算步骤，先计算哈希值，再对数组长度取模：

```python
index = hash(key) % capacity
```

观察以上公式，当哈希表容量 `capacity` 固定时，**哈希算法 `hash()` 决定了输出值**，进而决定了键值对在哈希表中的分布情况。

这意味着，为了降低哈希冲突的发生概率，我们应当将注意力集中在哈希算法 `hash()` 的设计上。

#### 6.3.1  哈希算法的目标

为了实现“既快又稳”的哈希表数据结构，哈希算法应具备以下特点。

- **确定性**：对于相同的输入，哈希算法应始终产生相同的输出。这样才能确保哈希表是可靠的。
- **效率高**：计算哈希值的过程应该足够快。计算开销越小，哈希表的实用性越高。
- **均匀分布**：哈希算法应使得键值对均匀分布在哈希表中。分布越均匀，哈希冲突的概率就越低。

实际上，哈希算法除了可以用于实现哈希表，还广泛应用于其他领域中。

- **密码存储**：为了保护用户密码的安全，系统通常不会直接存储用户的明文密码，而是存储密码的哈希值。当用户输入密码时，系统会对输入的密码计算哈希值，然后与存储的哈希值进行比较。如果两者匹配，那么密码就被视为正确。
- **数据完整性检查**：数据发送方可以计算数据的哈希值并将其一同发送；接收方可以重新计算接收到的数据的哈希值，并与接收到的哈希值进行比较。如果两者匹配，那么数据就被视为完整。

对于密码学的相关应用，为了防止从哈希值推导出原始密码等逆向工程，哈希算法需要具备更高等级的安全特性。

- **单向性**：无法通过哈希值反推出关于输入数据的任何信息。
- **抗碰撞性**：应当极难找到两个不同的输入，使得它们的哈希值相同。
- **雪崩效应**：输入的微小变化应当导致输出的显著且不可预测的变化。

请注意，**“均匀分布”与“抗碰撞性”是两个独立的概念**，满足均匀分布不一定满足抗碰撞性。例如，在随机输入 `key` 下，哈希函数 `key % 100` 可以产生均匀分布的输出。然而该哈希算法过于简单，所有后两位相等的 `key` 的输出都相同，因此我们可以很容易地从哈希值反推出可用的 `key` ，从而破解密码。

#### 6.3.2  哈希算法的设计

哈希算法的设计是一个需要考虑许多因素的复杂问题。然而对于某些要求不高的场景，我们也能设计一些简单的哈希算法。

- **加法哈希**：对输入的每个字符的 ASCII 码进行相加，将得到的总和作为哈希值。
- **乘法哈希**：利用乘法的不相关性，每轮乘以一个常数，将各个字符的 ASCII 码累积到哈希值中。
- **异或哈希**：将输入数据的每个元素通过异或操作累积到一个哈希值中。
- **旋转哈希**：将每个字符的 ASCII 码累积到一个哈希值中，每次累积之前都会对哈希值进行旋转操作(**旋转操作（Rotation）** 是一种对二进制数进行循环移位的位运算，通常分为**左旋转**和**右旋转**两种，核心是让二进制数的 bits 循环移动，溢出的位会重新补到另一端（而非像普通移位那样补 0）)。

```python
def add_hash(key: str) -> int:
    """加法哈希"""
    hash = 0
    modulus = 1000000007
    for c in key:
        hash += ord(c)
    return hash % modulus

def mul_hash(key: str) -> int:
    """乘法哈希"""
    hash = 0
    modulus = 1000000007
    for c in key:
        # 这个31有说法的，不是随便一个常数
        hash = 31 * hash + ord(c)
    return hash % modulus

def xor_hash(key: str) -> int:
    """异或哈希"""
    hash = 0
    modulus = 1000000007
    for c in key:
        hash ^= ord(c)
    return hash % modulus

def rot_hash(key: str) -> int:
    """旋转哈希"""
    hash = 0
    modulus = 1000000007
    for c in key:
        hash = (hash << 4) ^ (hash >> 28) ^ ord(c)
    return hash % modulus
```

观察发现，每种哈希算法的最后一步都是对大质数1000000007取模，以确保哈希值在合适的范围内。值得思考的是，为什么要强调对质数取模，或者说对合数取模的弊端是什么？这是一个有趣的问题。

先给出结论：**使用大质数作为模数，可以最大化地保证哈希值的均匀分布**。因为质数不与其他数字存在公约数，可以减少因取模操作而产生的周期性模式，从而避免哈希冲突。

举个例子，假设我们选择合数9作为模数，它可以被3整除，那么所有可以被3整除的 `key` 都会被映射到 0、3、6 这三个哈希值。

modulus = 9
key = {0,3,6,9,12,15,18,21,24,27,30,33,...}
hash = {0,3,6,0,3,6,0,3,6,0,3,6,...}

如果输入 `key` 恰好满足这种等差数列的数据分布，那么哈希值就会出现聚堆，从而加重哈希冲突。现在，假设将 `modulus` 替换为质数13，由于 `key` 和 `modulus` 之间不存在公约数，因此输出的哈希值的均匀性会明显提升。

modulus = 13
key = {0,3,6,9,12,15,18,21,24,27,30,33,...}
hash = {0,3,6,9,12,2,5,8,11,1,4,7,...}

值得说明的是，如果能够保证 `key` 是随机均匀分布的，那么选择质数或者合数作为模数都可以，它们都能输出均匀分布的哈希值。而当 `key` 的分布存在某种周期性时，对合数取模更容易出现聚集现象。

总而言之，我们通常选取质数作为模数，并且这个质数最好足够大，以尽可能消除周期性模式，提升哈希算法的稳健性。

#### 6.3.3  常见哈希算法

不难发现，以上介绍的简单哈希算法都比较“脆弱”，远远没有达到哈希算法的设计目标。例如，由于加法和异或满足交换律，因此加法哈希和异或哈希无法区分内容相同但顺序不同的字符串，这可能会加剧哈希冲突，并引起一些安全问题。

在实际中，我们通常会用一些标准哈希算法，例如 MD5、SHA-1、SHA-2 和 SHA-3 等。它们可以将任意长度的输入数据映射到恒定长度的哈希值。

近一个世纪以来，哈希算法处在不断升级与优化的过程中。一部分研究人员努力提升哈希算法的性能，另一部分研究人员和黑客则致力于寻找哈希算法的安全性问题。表 6-2 展示了在实际应用中常见的哈希算法。

- MD5 和 SHA-1 已多次被成功攻击，因此它们被各类安全应用弃用。
- SHA-2 系列中的 SHA-256 是最安全的哈希算法之一，仍未出现成功的攻击案例，因此常用在各类安全应用与协议中。
- SHA-3 相较 SHA-2 的实现开销更低、计算效率更高，但目前使用覆盖度不如 SHA-2 系列。

表 6-2  常见的哈希算法

|          | MD5                            | SHA-1            | SHA-2                        | SHA-3               |
| :------- | :----------------------------- | :--------------- | :--------------------------- | ------------------- |
| 推出时间 | 1992                           | 1995             | 2002                         | 2008                |
| 输出长度 | 128 bit                        | 160 bit          | 256/512 bit                  | 224/256/384/512 bit |
| 哈希冲突 | 较多                           | 较多             | 很少                         | 很少                |
| 安全等级 | 低，已被成功攻击               | 低，已被成功攻击 | 高                           | 高                  |
| 应用     | 已被弃用，仍用于数据完整性检查 | 已被弃用         | 加密货币交易验证、数字签名等 | 可用于替代 SHA-2    |

#### 6.3.4  数据结构的哈希值

我们知道，哈希表的 `key` 可以是整数、小数或字符串等数据类型。编程语言通常会为这些数据类型提供内置的哈希算法，用于计算哈希表中的桶索引。以 Python 为例，我们可以调用 `hash()` 函数来计算各种数据类型的哈希值。

- 整数和布尔量的哈希值就是其本身。
- 浮点数和字符串的哈希值计算较为复杂，有兴趣的读者请自行学习。
- 元组的哈希值是对其中每一个元素进行哈希，然后将这些哈希值组合起来，得到单一的哈希值。
- 对象的哈希值基于其内存地址生成。通过重写对象的哈希方法，可实现基于内容生成哈希值。

> 请注意，不同编程语言的内置哈希值计算函数的定义和方法不同。

```python
num = 3
hash_num = hash(num)
# 整数 3 的哈希值为 3

bol = True
hash_bol = hash(bol)
# 布尔量 True 的哈希值为 1

dec = 3.14159
hash_dec = hash(dec)
# 小数 3.14159 的哈希值为 326484311674566659

str = "Hello 算法"
hash_str = hash(str)
# 字符串“Hello 算法”的哈希值为 4617003410720528961

tup = (12836, "小哈")
hash_tup = hash(tup)
# 元组 (12836, '小哈') 的哈希值为 1029005403108185979

obj = ListNode(0)
hash_obj = hash(obj)
# 节点对象 <ListNode object at 0x1058fd810> 的哈希值为 274267521
```

在许多编程语言中，**只有不可变对象才可作为哈希表的 `key`** 。假如我们将列表（动态数组）作为 `key` ，当列表的内容发生变化时，它的哈希值也随之改变，我们就无法在哈希表中查询到原先的 `value` 了。

虽然自定义对象（比如链表节点）的成员变量是可变的，但它是可哈希的。**这是因为对象的哈希值通常是基于内存地址生成的**，即使对象的内容发生了变化，但它的内存地址不变，哈希值仍然是不变的。

细心的你可能发现在不同控制台中运行程序时，输出的哈希值是不同的。**这是因为 Python 解释器在每次启动时，都会为字符串哈希函数加入一个随机的盐（salt）值**。这种做法可以有效防止 HashDoS 攻击，提升哈希算法的安全性。

#### Comment

![image-20250807182657334](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250807182657334.png)

### 6.4  小结

1. 重点回顾

   - 输入 `key` ，哈希表能够在O(1)时间内查询到 `value` ，效率非常高。
   - 常见的哈希表操作包括查询、添加键值对、删除键值对和遍历哈希表等。
   - 哈希函数将 `key` 映射为数组索引，从而访问对应桶并获取 `value` 。
   - 两个不同的 `key` 可能在经过哈希函数后得到相同的数组索引，导致查询结果出错，这种现象被称为哈希冲突。
   - 哈希表容量越大，哈希冲突的概率就越低。因此可以通过扩容哈希表来缓解哈希冲突。与数组扩容类似，哈希表扩容操作的开销很大。
   - 负载因子定义为哈希表中元素数量除以桶数量，反映了哈希冲突的严重程度，常用作触发哈希表扩容的条件。
   - 链式地址通过将单个元素转化为链表，将所有冲突元素存储在同一个链表中。然而，链表过长会降低查询效率，可以通过进一步将链表转换为红黑树来提高效率。
   - 开放寻址通过多次探测来处理哈希冲突。线性探测使用固定步长，缺点是不能删除元素，且容易产生聚集。多次哈希使用多个哈希函数进行探测，相较线性探测更不易产生聚集，但多个哈希函数增加了计算量。
   - 不同编程语言采取了不同的哈希表实现。例如，Java 的 `HashMap` 使用链式地址，而 Python 的 `Dict` 采用开放寻址。
   - 在哈希表中，我们希望哈希算法具有确定性、高效率和均匀分布的特点。在密码学中，哈希算法还应该具备抗碰撞性和雪崩效应。
   - 哈希算法通常采用大质数作为模数，以最大化地保证哈希值均匀分布，减少哈希冲突。
   - 常见的哈希算法包括 MD5、SHA-1、SHA-2 和 SHA-3 等。MD5 常用于校验文件完整性，SHA-2 常用于安全应用与协议。
   - 编程语言通常会为数据类型提供内置哈希算法，用于计算哈希表中的桶索引。通常情况下，只有不可变对象是可哈希的。

2.  Q & A

    **Q**：哈希表的时间复杂度在什么情况下是$O(n)$？

    当哈希冲突比较严重时，哈希表的时间复杂度会退化至$O(n)$。当哈希函数设计得比较好、容量设置比较合理、冲突比较平均时，时间复杂度是$O(1)$。我们使用编程语言内置的哈希表时，通常认为时间复杂度是$O(1)$。

    **Q**：为什么不使用哈希函数$f(x)=x$呢？这样就不会有冲突了。

    在$f(x)=x$哈希函数下，每个元素对应唯一的桶索引，这与数组等价。然而，输入空间通常远大于输出空间（数组长度），因此哈希函数的最后一步往往是对数组长度取模。换句话说，哈希表的目标是将一个较大的状态空间映射到一个较小的空间，并提供$O(1)$的查询效率。

    **Q**：哈希表底层实现是数组、链表、二叉树，但为什么效率可以比它们更高呢？

    首先，哈希表的时间效率变高，但空间效率变低了。哈希表有相当一部分内存未使用。

    其次，只是在特定使用场景下时间效率变高了。如果一个功能能够在相同的时间复杂度下使用数组或链表实现，那么通常比哈希表更快。这是因为哈希函数计算需要开销，时间复杂度的常数项更大。

    最后，哈希表的时间复杂度可能发生劣化。例如在链式地址中，我们采取在链表或红黑树中执行查找操作，仍然有退化至$O(n)$时间的风险。

    **Q**：多次哈希有不能直接删除元素的缺陷吗？标记为已删除的空间还能再次使用吗？

    多次哈希是开放寻址的一种，开放寻址法都有不能直接删除元素的缺陷，需要通过标记删除。标记为已删除的空间可以再次使用。当将新元素插入哈希表，并且通过哈希函数找到标记为已删除的位置时，该位置可以被新元素使用。这样做既能保持哈希表的探测序列不变，又能保证哈希表的空间使用率。

    **Q**：为什么在线性探测中，查找元素的时候会出现哈希冲突呢？

    查找的时候通过哈希函数找到对应的桶和键值对，发现 `key` 不匹配，这就代表有哈希冲突。因此，线性探测法会根据预先设定的步长依次向下查找，直至找到正确的键值对或无法找到跳出为止。

    **Q**：为什么哈希表扩容能够缓解哈希冲突？

    哈希函数的最后一步往往是对数组长度n取模（取余），让输出值落在数组索引范围内；在扩容后，数组长度n发生变化，而 `key` 对应的索引也可能发生变化。原先落在同一个桶的多个 `key` ，在扩容后可能会被分配到多个桶中，从而实现哈希冲突的缓解。

## 第 7 章  树

### 7.1  二叉树

二叉树（binary tree）是一种非线性数据结构，代表“祖先”与“后代”之间的派生关系，体现了“一分为二”的分治逻辑。与链表类似，二叉树的基本单元是节点，每个节点包含值、左子节点引用和右子节点引用。

```python
class TreeNode:
    """二叉树节点类"""
    def __init__(self, val: int):
        self.val: int = val                # 节点值
        self.left: TreeNode | None = None  # 左子节点引用
        self.right: TreeNode | None = None # 右子节点引用
```

每个节点都有两个引用（指针），分别指向左子节点（left-child node）和右子节点（right-child node），该节点被称为这两个子节点的父节点（parent node）。当给定一个二叉树的节点时，我们将该节点的左子节点及其以下节点形成的树称为该节点的左子树（left subtree），同理可得右子树（right subtree）。

**在二叉树中，除叶节点外，其他所有节点都包含子节点和非空子树**。如图 7-1 所示，如果将“节点 2”视为父节点，则其左子节点和右子节点分别是“节点 4”和“节点 5”，左子树是“节点 4 及其以下节点形成的树”，右子树是“节点 5 及其以下节点形成的树”。

![父节点、子节点、子树](https://www.hello-algo.com/chapter_tree/binary_tree.assets/binary_tree_definition.png)

图 7-1  父节点、子节点、子树

#### 7.1.1  二叉树常见术语

二叉树的常用术语如图 7-2 所示。

- 根节点（root node）：位于二叉树顶层的节点，没有父节点。
- 叶节点（leaf node）：没有子节点的节点，其两个指针均指向 `None` 。
- 边（edge）：连接两个节点的线段，即节点引用（指针）。
- 节点所在的层（level）：从顶至底递增，根节点所在层为 1 。
- 节点的度（degree）：节点的子节点的数量。在二叉树中，度的取值范围是 0、1、2 。
- 二叉树的高度（height）：从根节点到最远叶节点所经过的边的数量。
- 节点的深度（depth）：从根节点到该节点所经过的边的数量。
- 节点的高度（height）：从距离该节点最远的叶节点到该节点所经过的边的数量。

![二叉树的常用术语](https://www.hello-algo.com/chapter_tree/binary_tree.assets/binary_tree_terminology.png)

图 7-2  二叉树的常用术语

> 请注意，我们通常将“高度”和“深度”定义为“经过的边的数量”，但有些题目或教材可能会将其定义为“经过的节点的数量”。在这种情况下，高度和深度都需要加 1 。

#### 7.1.2  二叉树基本操作

1. 初始化二叉树

   与链表类似，首先初始化节点，然后构建引用（指针）。

   ```python
   # 初始化二叉树
   # 初始化节点
   n1 = TreeNode(val=1)
   n2 = TreeNode(val=2)
   n3 = TreeNode(val=3)
   n4 = TreeNode(val=4)
   n5 = TreeNode(val=5)
   # 构建节点之间的引用（指针）
   n1.left = n2
   n1.right = n3
   n2.left = n4
   n2.right = n5
   ```

2.  插入与删除节点

    与链表类似，在二叉树中插入与删除节点可以通过修改指针来实现。图 7-3 给出了一个示例。

    ![在二叉树中插入与删除节点](https://www.hello-algo.com/chapter_tree/binary_tree.assets/binary_tree_add_remove.png)

    图 7-3  在二叉树中插入与删除节点

    ```python
    # 插入与删除节点
    p = TreeNode(0)
    # 在 n1 -> n2 中间插入节点 P
    n1.left = p
    p.left = n2
    # 删除节点 P
    n1.left = n2
    ```

    > 需要注意的是，插入节点可能会改变二叉树的原有逻辑结构，而删除节点通常意味着删除该节点及其所有子树。因此，在二叉树中，插入与删除通常是由一套操作配合完成的，以实现有实际意义的操作。

#### 7.1.3  常见二叉树类型

1. 完美二叉树

   如图 7-4 所示，完美二叉树（perfect binary tree）所有层的节点都被完全填满。在完美二叉树中，叶节点的度为0，其余所有节点的度都为2；若树的高度为h，则节点总数为$2^{h+1}-1$，呈现标准的指数级关系，反映了自然界中常见的细胞分裂现象。

   > 请注意，在中文社区中，完美二叉树常被称为满二叉树。

   ![完美二叉树](https://www.hello-algo.com/chapter_tree/binary_tree.assets/perfect_binary_tree.png)

   图 7-4  完美二叉树

2.  完全二叉树

    如图 7-5 所示，完全二叉树（complete binary tree）仅允许最底层的节点不完全填满，且最底层的节点必须从左至右依次连续填充。请注意，完美二叉树也是一棵完全二叉树。

    ![完全二叉树](https://www.hello-algo.com/chapter_tree/binary_tree.assets/complete_binary_tree.png)

    图 7-5  完全二叉树

3.  完满二叉树

    如图 7-6 所示，完满二叉树（full binary tree）除了叶节点之外，其余所有节点都有两个子节点。

    ![完满二叉树](https://www.hello-algo.com/chapter_tree/binary_tree.assets/full_binary_tree.png)

    图 7-6  完满二叉树

4.  平衡二叉树

    如图 7-7 所示，平衡二叉树（balanced binary tree）中任意节点的左子树和右子树的高度之差的绝对值不超过 1 。

    ![平衡二叉树](https://www.hello-algo.com/chapter_tree/binary_tree.assets/balanced_binary_tree.png)

    图 7-7  平衡二叉树

#### 7.1.4  二叉树的退化

图 7-8 展示了二叉树的理想结构与退化结构。当二叉树的每层节点都被填满时，达到“完美二叉树”；而当所有节点都偏向一侧时，二叉树退化为“链表”。

- 完美二叉树是理想情况，可以充分发挥二叉树“分治”的优势。
- 链表则是另一个极端，各项操作都变为线性操作，时间复杂度退化至$O(n)$。

![二叉树的最佳结构与最差结构](https://www.hello-algo.com/chapter_tree/binary_tree.assets/binary_tree_best_worst_cases.png)

图 7-8  二叉树的最佳结构与最差结构

如表 7-1 所示，在最佳结构和最差结构下，二叉树的叶节点数量、节点总数、高度等达到极大值或极小值。

表 7-1  二叉树的最佳结构与最差结构

|                         | 完美二叉树        | 链表 |
| :---------------------- | :---------------- | ---- |
| 第i层的节点数量         | $2^{i-1}$         | 1    |
| 高度为h的树的叶节点数量 | $2^h$             | 1    |
| 高度为h的树的节点总数   | $2^{h+1}-1$       | h+1  |
| 节点总数为n的树的高度   | $log_2 {(n+1)}-1$ | n-1  |

### 7.2  二叉树遍历

从物理结构的角度来看，树是一种基于链表的数据结构，因此其遍历方式是通过指针逐个访问节点。然而，树是一种非线性数据结构，这使得遍历树比遍历链表更加复杂，需要借助搜索算法来实现。

二叉树常见的遍历方式包括层序遍历、前序遍历、中序遍历和后序遍历等。

#### 7.2.1  层序遍历

如图 7-9 所示，层序遍历（level-order traversal）从顶部到底部逐层遍历二叉树，并在每一层按照从左到右的顺序访问节点。

层序遍历本质上属于广度优先遍历（breadth-first traversal），也称广度优先搜索（breadth-first search, BFS），它体现了一种“一圈一圈向外扩展”的逐层遍历方式。

![二叉树的层序遍历](https://www.hello-algo.com/chapter_tree/binary_tree_traversal.assets/binary_tree_bfs.png)

图 7-9  二叉树的层序遍历

1. 代码实现

   广度优先遍历通常借助“队列”来实现。队列遵循“先进先出”的规则，而广度优先遍历则遵循“逐层推进”的规则，两者背后的思想是一致的。实现代码如下：

   ```python
   def level_order(root: TreeNode | None) -> list[int]:
       """层序遍历"""
       # 初始化队列，加入根节点
       queue: deque[TreeNode] = deque()
       queue.append(root)
       # 初始化一个列表，用于保存遍历序列
       res = []
       while queue:
           node: TreeNode = queue.popleft()  # 队列出队
           res.append(node.val)  # 保存节点值
           if node.left is not None:
               queue.append(node.left)  # 左子节点入队
           if node.right is not None:
               queue.append(node.right)  # 右子节点入队
       return res
   ```

2.  复杂度分析

    - **时间复杂度为**$O(n)$：所有节点被访问一次，使用$O(n)$时间，其中n为节点数量。
    - **空间复杂度为**$O(n)$：在最差情况下，即满二叉树时，遍历到最底层之前，队列中最多同时存在 $(n+1)/2$个节点，占用$O(n)$空间。

#### 7.2.2  前序、中序、后序遍历

相应地，前序、中序和后序遍历都属于深度优先遍历（depth-first traversal），也称深度优先搜索（depth-first search, DFS），它体现了一种“先走到尽头，再回溯继续”的遍历方式。

图 7-10 展示了对二叉树进行深度优先遍历的工作原理。**深度优先遍历就像是绕着整棵二叉树的外围“走”一圈**，在每个节点都会遇到三个位置，分别对应前序遍历、中序遍历和后序遍历。

![二叉搜索树的前序、中序、后序遍历](https://www.hello-algo.com/chapter_tree/binary_tree_traversal.assets/binary_tree_dfs.png)

图 7-10  二叉搜索树的前序、中序、后序遍历

1. 代码实现

   深度优先搜索通常基于递归实现：

   ```python
   def pre_order(root: TreeNode | None):
       """前序遍历"""
       if root is None:
           return
       # 访问优先级：根节点 -> 左子树 -> 右子树
       res.append(root.val)
       pre_order(root=root.left)
       pre_order(root=root.right)
   
   def in_order(root: TreeNode | None):
       """中序遍历"""
       if root is None:
           return
       # 访问优先级：左子树 -> 根节点 -> 右子树
       in_order(root=root.left)
       res.append(root.val)
       in_order(root=root.right)
   
   def post_order(root: TreeNode | None):
       """后序遍历"""
       if root is None:
           return
       # 访问优先级：左子树 -> 右子树 -> 根节点
       post_order(root=root.left)
       post_order(root=root.right)
       res.append(root.val)
   ```

   > 深度优先搜索也可以基于迭代实现，有兴趣的读者可以自行研究。

   ```python
   class TreeNode:
       """二叉树节点类"""
   
       def __init__(self, val=0, left=None, right=None):
           self.val = val
           self.left = left
           self.right = right
   
   
   def preorder_traversal(root: TreeNode):
       """前序遍历：根 -> 左 -> 右（非递归）"""
       if not root:
           return []
   
       result = []
       stack = [root]  # 栈初始化，先放入根节点
   
       while stack:
           node = stack.pop()  # 弹出栈顶节点
           result.append(node.val)  # 访问根节点
   
           # 注意：栈是后进先出，所以先放右子树，再放左子树
           if node.right:
               stack.append(node.right)
           if node.left:
               stack.append(node.left)
   
       return result
   
   
   def inorder_traversal(root: TreeNode):
       """中序遍历：左 -> 根 -> 右（非递归）"""
       if not root:
           return []
   
       result = []
       stack = []
       current = root
   
       while current or stack:
           # 先遍历左子树，将所有左节点入栈
           while current:
               stack.append(current)
               current = current.left
   
           # 弹出栈顶节点（最左节点）
           current = stack.pop()
           result.append(current.val)  # 访问根节点
   
           # 转向右子树
           current = current.right
   
       return result
   
   
   def postorder_traversal(root: TreeNode):
       """后序遍历：左 -> 右 -> 根（非递归）"""
       if not root:
           return []
   
       result = []
       stack = [root]
       visited = set()  # 记录已访问的节点
   
       while stack:
           node = stack[-1]  # 查看栈顶节点（不弹出）
   
           # 如果节点的左右子树都已访问，或者是叶子节点，则访问该节点
           if (not node.left and not node.right) or node in visited:
               stack.pop()
               result.append(node.val)
           else:
               # 标记当前节点为已访问（表示其左右子树即将被处理）
               visited.add(node)
               # 先放右子树，再放左子树（栈是后进先出）
               if node.right:
                   stack.append(node.right)
               if node.left:
                   stack.append(node.left)
   
       return result
   ```

   图 7-11 展示了前序遍历二叉树的递归过程，其可分为“递”和“归”两个逆向的部分。

   1. “递”表示开启新方法，程序在此过程中访问下一个节点。
   2. “归”表示函数返回，代表当前节点已经访问完毕。

   ![preorder_step11](https://www.hello-algo.com/chapter_tree/binary_tree_traversal.assets/preorder_step11.png)

   图 7-11  前序遍历的递归过程

2. 复杂度分析

   - **时间复杂度为**$O(n)$：所有节点被访问一次，使用$O(n)$时间。
   - **空间复杂度为**$O(n)$：在最差情况下，即树退化为链表时，递归深度达到n，系统占用$O(n)$栈帧空间。

### 7.3  二叉树数组表示

在链表表示下，二叉树的存储单元为节点 `TreeNode` ，节点之间通过指针相连接。上一节介绍了链表表示下的二叉树的各项基本操作。

那么，我们能否用数组来表示二叉树呢？答案是肯定的。

#### 7.3.1  表示完美二叉树

先分析一个简单案例。给定一棵完美二叉树，我们将所有节点按照层序遍历的顺序存储在一个数组中，则每个节点都对应唯一的数组索引。

根据层序遍历的特性，我们可以推导出父节点索引与子节点索引之间的“映射公式”：**若某节点的索引为i，则该节点的左子节点索引为2i+1，右子节点索引为2i+2** 。图 7-12 展示了各个节点索引之间的映射关系。

![完美二叉树的数组表示](https://www.hello-algo.com/chapter_tree/array_representation_of_tree.assets/array_representation_binary_tree.png)

图 7-12  完美二叉树的数组表示

**映射公式的角色相当于链表中的节点引用（指针）**。给定数组中的任意一个节点，我们都可以通过映射公式来访问它的左（右）子节点。

#### 7.3.2  表示任意二叉树

完美二叉树是一个特例，在二叉树的中间层通常存在许多 `None` 。由于层序遍历序列并不包含这些 `None` ，因此我们无法仅凭该序列来推测 `None` 的数量和分布位置。**这意味着存在多种二叉树结构都符合该层序遍历序列**。

如图 7-13 所示，给定一棵非完美二叉树，上述数组表示方法已经失效。

![层序遍历序列对应多种二叉树可能性](https://www.hello-algo.com/chapter_tree/array_representation_of_tree.assets/array_representation_without_empty.png)

图 7-13  层序遍历序列对应多种二叉树可能性

为了解决此问题，**我们可以考虑在层序遍历序列中显式地写出所有 `None`** 。如图 7-14 所示，这样处理后，层序遍历序列就可以唯一表示二叉树了。示例代码如下：

```python
# 二叉树的数组表示
# 使用 None 来表示空位
tree = [1, 2, 3, 4, None, 6, 7, 8, 9, None, None, 12, None, None, 15]
```

![任意类型二叉树的数组表示](https://www.hello-algo.com/chapter_tree/array_representation_of_tree.assets/array_representation_with_empty.png)

图 7-14  任意类型二叉树的数组表示

值得说明的是，**完全二叉树非常适合使用数组来表示**。回顾完全二叉树的定义，`None` 只出现在最底层且靠右的位置，**因此所有 `None` 一定出现在层序遍历序列的末尾**。

这意味着使用数组表示完全二叉树时，可以省略存储所有 `None` ，非常方便。图 7-15 给出了一个例子。

![完全二叉树的数组表示](https://www.hello-algo.com/chapter_tree/array_representation_of_tree.assets/array_representation_complete_binary_tree.png)

图 7-15  完全二叉树的数组表示

以下代码实现了一棵基于数组表示的二叉树，包括以下几种操作。

- 给定某节点，获取它的值、左（右）子节点、父节点。
- 获取前序遍历、中序遍历、后序遍历、层序遍历序列。

```python
class ArrayBinaryTree:
    """数组表示下的二叉树类"""

    def __init__(self, arr: list[int | None]):
        """构造方法"""
        self._tree = list(arr)

    def size(self):
        """列表容量"""
        return len(self._tree)

    def val(self, i: int) -> int | None:
        """获取索引为 i 节点的值"""
        # 若索引越界，则返回 None ，代表空位
        if i < 0 or i >= self.size():
            return None
        return self._tree[i]

    def left(self, i: int) -> int | None:
        """获取索引为 i 节点的左子节点的索引"""
        return 2 * i + 1

    def right(self, i: int) -> int | None:
        """获取索引为 i 节点的右子节点的索引"""
        return 2 * i + 2

    def parent(self, i: int) -> int | None:
        """获取索引为 i 节点的父节点的索引"""
        return (i - 1) // 2

    def level_order(self) -> list[int]:
        """层序遍历"""
        self.res = []
        # 直接遍历数组
        for i in range(self.size()):
            if self.val(i) is not None:
                self.res.append(self.val(i))
        return self.res

    def dfs(self, i: int, order: str):
        """深度优先遍历"""
        if self.val(i) is None:
            return
        # 前序遍历
        if order == "pre":
            self.res.append(self.val(i))
        self.dfs(self.left(i), order)
        # 中序遍历
        if order == "in":
            self.res.append(self.val(i))
        self.dfs(self.right(i), order)
        # 后序遍历
        if order == "post":
            self.res.append(self.val(i))

    def pre_order(self) -> list[int]:
        """前序遍历"""
        self.res = []
        self.dfs(0, order="pre")
        return self.res

    def in_order(self) -> list[int]:
        """中序遍历"""
        self.res = []
        self.dfs(0, order="in")
        return self.res

    def post_order(self) -> list[int]:
        """后序遍历"""
        self.res = []
        self.dfs(0, order="post")
        return self.res
```

#### 7.3.3  优点与局限性

二叉树的数组表示主要有以下优点。

- 数组存储在连续的内存空间中，对缓存友好，访问与遍历速度较快。
- 不需要存储指针，比较节省空间。
- 允许随机访问节点。

然而，数组表示也存在一些局限性。

- 数组存储需要连续内存空间，因此不适合存储数据量过大的树。
- 增删节点需要通过数组插入与删除操作实现，效率较低。
- 当二叉树中存在大量 `None` 时，数组中包含的节点数据比重较低，空间利用率较低。

### 7.4  二叉搜索树

如图 7-16 所示，二叉搜索树（binary search tree）满足以下条件。

1. 对于根节点，左子树中所有节点的值<根节点的值<右子树中所有节点的值。
2. 任意节点的左、右子树也是二叉搜索树，即同样满足条件 `1.` 。

![二叉搜索树](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/binary_search_tree.png)

图 7-16  二叉搜索树

#### 7.4.1  二叉搜索树的操作

我们将二叉搜索树封装为一个类 `BinarySearchTree` ，并声明一个成员变量 `root` ，指向树的根节点。

1. 查找节点

   给定目标节点值 `num` ，可以根据二叉搜索树的性质来查找。如图 7-17 所示，我们声明一个节点 `cur` ，从二叉树的根节点 `root` 出发，循环比较节点值 `cur.val` 和 `num` 之间的大小关系。

   - 若 `cur.val < num` ，说明目标节点在 `cur` 的右子树中，因此执行 `cur = cur.right` 。
   - 若 `cur.val > num` ，说明目标节点在 `cur` 的左子树中，因此执行 `cur = cur.left` 。
   - 若 `cur.val = num` ，说明找到目标节点，跳出循环并返回该节点。

   ![bst_search_step4](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_search_step4.png)

   图 7-17  二叉搜索树查找节点示例

   二叉搜索树的查找操作与二分查找算法的工作原理一致，都是每轮排除一半情况。循环次数最多为二叉树的高度，当二叉树平衡时，使用$O(log n)$时间。示例代码如下：

   ```python
   def search(self, num: int) -> TreeNode | None:
       """查找节点"""
       cur = self._root
       # 循环查找，越过叶节点后跳出
       while cur is not None:
           # 目标节点在 cur 的右子树中
           if cur.val < num:
               cur = cur.right
           # 目标节点在 cur 的左子树中
           elif cur.val > num:
               cur = cur.left
           # 找到目标节点，跳出循环
           else:
               break
       return cur
   ```

2.  插入节点

    给定一个待插入元素 `num` ，为了保持二叉搜索树“左子树 < 根节点 < 右子树”的性质，插入操作流程如图 7-18 所示。

    1. **查找插入位置**：与查找操作相似，从根节点出发，根据当前节点值和 `num` 的大小关系循环向下搜索，直到越过叶节点（遍历至 `None` ）时跳出循环。
    2. **在该位置插入节点**：初始化节点 `num` ，将该节点置于 `None` 的位置。

    ![在二叉搜索树中插入节点](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_insert.png)

    图 7-18  在二叉搜索树中插入节点

    在代码实现中，需要注意以下两点。

    - 二叉搜索树不允许存在重复节点，否则将违反其定义。因此，若待插入节点在树中已存在，则不执行插入，直接返回。
    - 为了实现插入节点，我们需要借助节点 `pre` 保存上一轮循环的节点。这样在遍历至 `None` 时，我们可以获取到其父节点，从而完成节点插入操作。

    ```python
    def insert(self, num: int):
        """插入节点"""
        # 若树为空，则初始化根节点
        if self._root is None:
            self._root = TreeNode(num)
            return
        # 循环查找，越过叶节点后跳出
        cur, pre = self._root, None
        while cur is not None:
            # 找到重复节点，直接返回
            if cur.val == num:
                return
            pre = cur
            # 插入位置在 cur 的右子树中
            if cur.val < num:
                cur = cur.right
            # 插入位置在 cur 的左子树中
            else:
                cur = cur.left
        # 插入节点
        node = TreeNode(num)
        if pre.val < num:
            pre.right = node
        else:
            pre.left = node
    ```

    与查找节点相同，插入节点使用$O(log n)$时间。

3.  删除节点

    先在二叉树中查找到目标节点，再将其删除。与插入节点类似，我们需要保证在删除操作完成后，二叉搜索树的“左子树 < 根节点 < 右子树”的性质仍然满足。因此，我们根据目标节点的子节点数量，分 0、1 和 2 三种情况，执行对应的删除节点操作。

    如图 7-19 所示，当待删除节点的度为0时，表示该节点是叶节点，可以直接删除。

    ![在二叉搜索树中删除节点（度为 0 ）](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_remove_case1.png)

    图 7-19  在二叉搜索树中删除节点（度为 0 ）

    如图 7-20 所示，当待删除节点的度为1时，将待删除节点替换为其子节点即可。

    ![在二叉搜索树中删除节点（度为 1 ）](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_remove_case2.png)

    图 7-20  在二叉搜索树中删除节点（度为 1 ）

    当待删除节点的度为2时，我们无法直接删除它，而需要使用一个节点替换该节点。由于要保持二叉搜索树“左子树<根节点<右子树”的性质，**因此这个节点可以是右子树的最小节点或左子树的最大节点**。

    假设我们选择右子树的最小节点（中序遍历的下一个节点），则删除操作流程如图 7-21 所示。

    1. 找到待删除节点在“中序遍历序列”中的下一个节点，记为 `tmp` 。
    2. 用 `tmp` 的值覆盖待删除节点的值，并在树中递归删除节点 `tmp` 。

    ![bst_remove_case3_step4](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_remove_case3_step4.png)

    图 7-21  在二叉搜索树中删除节点（度为 2 ）

    删除节点操作同样使用$O(log n)$时间，其中查找待删除节点需要$O(log n)$时间，获取中序遍历后继节点需要$O(log n)$时间。示例代码如下：

    ```python
    def remove(self, num: int):
        """删除节点"""
        # 若树为空，直接提前返回
        if self._root is None:
            return
        # 循环查找，越过叶节点后跳出
        cur, pre = self._root, None
        while cur is not None:
            # 找到待删除节点，跳出循环
            if cur.val == num:
                break
            pre = cur
            # 待删除节点在 cur 的右子树中
            if cur.val < num:
                cur = cur.right
            # 待删除节点在 cur 的左子树中
            else:
                cur = cur.left
        # 若无待删除节点，则直接返回
        if cur is None:
            return
    
        # 子节点数量 = 0 or 1
        if cur.left is None or cur.right is None:
            # 当子节点数量 = 0 / 1 时， child = null / 该子节点
            child = cur.left or cur.right
            # 删除节点 cur
            if cur != self._root:
                if pre.left == cur:
                    pre.left = child
                else:
                    pre.right = child
            else:
                # 若删除节点为根节点，则重新指定根节点
                self._root = child
        # 子节点数量 = 2
        else:
            # 获取中序遍历中 cur 的下一个节点
            tmp: TreeNode = cur.right
            while tmp.left is not None:
                tmp = tmp.left
            # 递归删除节点 tmp
            self.remove(tmp.val)
            # 用 tmp 覆盖 cur
            cur.val = tmp.val
    ```

4.  中序遍历有序

    如图 7-22 所示，二叉树的中序遍历遵循“左 根 右”的遍历顺序，而二叉搜索树满足“左子节点<根节点<右子节点”的大小关系。

    这意味着在二叉搜索树中进行中序遍历时，总是会优先遍历下一个最小节点，从而得出一个重要性质：**二叉搜索树的中序遍历序列是升序的**。

    利用中序遍历升序的性质，我们在二叉搜索树中获取有序数据仅需$O(n)$时间，无须进行额外的排序操作，非常高效。

    ![二叉搜索树的中序遍历序列](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_inorder_traversal.png)

    图 7-22  二叉搜索树的中序遍历序列

#### 7.4.2  二叉搜索树的效率

给定一组数据，我们考虑使用数组或二叉搜索树存储。观察表 7-2 ，二叉搜索树的各项操作的时间复杂度都是对数阶，具有稳定且高效的性能。只有在高频添加、低频查找删除数据的场景下，数组比二叉搜索树的效率更高。

表 7-2  数组与搜索树的效率对比

|          | 无序数组 | 二叉搜索树 |
| :------- | :------- | ---------- |
| 查找元素 | $O(n)$   | $O(log n)$ |
| 插入元素 | $O(1)$   | $O(log n)$ |
| 删除元素 | $O(n)$   | $O(log n)$ |

在理想情况下，二叉搜索树是“平衡”的，这样就可以在$log n $轮循环内查找任意节点。

然而，如果我们在二叉搜索树中不断地插入和删除节点，可能导致二叉树退化为图 7-23 所示的链表，这时各种操作的时间复杂度也会退化为$O(n)$。

![二叉搜索树退化](https://www.hello-algo.com/chapter_tree/binary_search_tree.assets/bst_degradation.png)

图 7-23  二叉搜索树退化

#### 7.4.3  二叉搜索树常见应用

- 用作系统中的多级索引，实现高效的查找、插入、删除操作。
- 作为某些搜索算法的底层数据结构。
- 用于存储数据流，以保持其有序状态。

#### Comment

二叉搜索树插入节点都是在叶子节点上插入

![img](file:///C:\Users\zdz1411\AppData\Local\Temp\QQ_1755008423160.png)

![image-20250815171552671](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250815171552671.png)

### 7.5  AVL 树 *

在“二叉搜索树”章节中我们提到，在多次插入和删除操作后，二叉搜索树可能退化为链表。在这种情况下，所有操作的时间复杂度将从$O(logn)$劣化为$O(n)$。

如图 7-24 所示，经过两次删除节点操作，这棵二叉搜索树便会退化为链表。

![AVL 树在删除节点后发生退化](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_degradation_from_removing_node.png)

图 7-24  AVL 树在删除节点后发生退化

再例如，在图 7-25 所示的完美二叉树中插入两个节点后，树将严重向左倾斜，查找操作的时间复杂度也随之劣化。

![AVL 树在插入节点后发生退化](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_degradation_from_inserting_node.png)

图 7-25  AVL 树在插入节点后发生退化

1962 年 G. M. Adelson-Velsky 和 E. M. Landis 在论文“An algorithm for the organization of information”中提出了 AVL 树。论文中详细描述了一系列操作，确保在持续添加和删除节点后，AVL 树不会退化，从而使得各种操作的时间复杂度保持在$O(log n)$级别。换句话说，在需要频繁进行增删查改操作的场景中，AVL 树能始终保持高效的数据操作性能，具有很好的应用价值。

#### 7.5.1  AVL 树常见术语

AVL 树既是二叉搜索树，也是平衡二叉树，同时满足这两类二叉树的所有性质，因此是一种平衡二叉搜索树（balanced binary search tree）。

1. 节点高度

   由于 AVL 树的相关操作需要获取节点高度，因此我们需要为节点类添加 `height` 变量：

   ```python
   class TreeNode:
       """AVL 树节点类"""
       def __init__(self, val: int):
           self.val: int = val                 # 节点值
           self.height: int = 0                # 节点高度
           self.left: TreeNode | None = None   # 左子节点引用
           self.right: TreeNode | None = None  # 右子节点引用
   ```

   “节点高度”是指从该节点到它的最远叶节点的距离，即所经过的“边”的数量。需要特别注意的是，叶节点的高度为0，而空节点的高度为-1。我们将创建两个工具函数，分别用于获取和更新节点的高度：

   ```python
   def height(self, node: TreeNode | None) -> int:
       """获取节点高度"""
       # 空节点高度为 -1 ，叶节点高度为 0
       if node is not None:
           return node.height
       return -1
   
   def update_height(self, node: TreeNode | None):
       """更新节点高度"""
       # 节点高度等于最高子树高度 + 1
       node.height = max([self.height(node.left), self.height(node.right)]) + 1
   ```

2.  节点平衡因子

    节点的平衡因子（balance factor）定义为节点左子树的高度减去右子树的高度，同时规定空节点的平衡因子为0。我们同样将获取节点平衡因子的功能封装成函数，方便后续使用：

    ```python
    def balance_factor(self, node: TreeNode | None) -> int:
        """获取平衡因子"""
        # 空节点平衡因子为 0
        if node is None:
            return 0
        # 节点平衡因子 = 左子树高度 - 右子树高度
        return self.height(node.left) - self.height(node.right)
    ```

    > 设平衡因子为$f$，则一棵 AVL 树的任意节点的平衡因子皆满足$-1<=f<=1$。

#### 7.5.2  AVL 树旋转

AVL 树的特点在于“旋转”操作，它能够在不影响二叉树的中序遍历序列的前提下，使失衡节点重新恢复平衡。换句话说，**旋转操作既能保持“二叉搜索树”的性质，也能使树重新变为“平衡二叉树”**。

我们将平衡因子绝对值>1的节点称为“失衡节点”。根据节点失衡情况的不同，旋转操作分为四种：右旋、左旋、先右旋后左旋、先左旋后右旋。下面详细介绍这些旋转操作。

1. 右旋

   如图 7-26 所示，节点下方为平衡因子。从底至顶看，二叉树中首个失衡节点是“节点 3”。我们关注以该失衡节点为根节点的子树，将该节点记为 `node` ，其左子节点记为 `child` ，执行“右旋”操作。完成右旋后，子树恢复平衡，并且仍然保持二叉搜索树的性质。

   ![右旋操作步骤](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_right_rotate_step1.png)

   ![avltree_right_rotate_step4](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_right_rotate_step4.png)

   图 7-26  右旋操作步骤

   如图 7-27 所示，当节点 `child` 有右子节点（记为 `grand_child` ）时，需要在右旋中添加一步：将 `grand_child` 作为 `node` 的左子节点。

   ![有 grand_child 的右旋操作](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_right_rotate_with_grandchild.png)

   图 7-27  有 grand_child 的右旋操作

   “向右旋转”是一种形象化的说法，实际上需要通过修改节点指针来实现，代码如下所示：

   ```python
   def right_rotate(self, node: TreeNode | None) -> TreeNode | None:
       """右旋操作"""
       child = node.left
       grand_child = child.right
       # 以 child 为原点，将 node 向右旋转
       child.right = node
       node.left = grand_child
       # 更新节点高度,在右旋操作中，只需更新 node（原根节点）和 child（新根节点）的高度，是因为只有这两个节点的子树结构发生了变化，其他节点的子树未受影响，高度自然也不会改变。
       self.update_height(node)
       self.update_height(child)
       # 返回旋转后子树的根节点
       return child
   ```

2. 左旋

   相应地，如果考虑上述失衡二叉树的“镜像”，则需要执行图 7-28 所示的“左旋”操作。

   ![左旋操作](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_left_rotate.png)

   图 7-28  左旋操作

   同理，如图 7-29 所示，当节点 `child` 有左子节点（记为 `grand_child` ）时，需要在左旋中添加一步：将 `grand_child` 作为 `node` 的右子节点。

   ![有 grand_child 的左旋操作](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_left_rotate_with_grandchild.png)

   图 7-29  有 grand_child 的左旋操作

   可以观察到，**右旋和左旋操作在逻辑上是镜像对称的，它们分别解决的两种失衡情况也是对称的**。基于对称性，我们只需将右旋的实现代码中的所有的 `left` 替换为 `right` ，将所有的 `right` 替换为 `left` ，即可得到左旋的实现代码：

   ```python
   def left_rotate(self, node: TreeNode | None) -> TreeNode | None:
       """左旋操作"""
       child = node.right
       grand_child = child.left
       # 以 child 为原点，将 node 向左旋转
       child.left = node
       node.right = grand_child
       # 更新节点高度
       self.update_height(node)
       self.update_height(child)
       # 返回旋转后子树的根节点
       return child
   ```

3. 先左旋后右旋

   对于图 7-30 中的失衡节点 3 ，仅使用左旋或右旋都无法使子树恢复平衡。此时需要先对 `child` 执行“左旋”，再对 `node` 执行“右旋”。

   ![先左旋后右旋](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_left_right_rotate.png)

   图 7-30  先左旋后右旋

4. 先右旋后左旋

   如图 7-31 所示，对于上述失衡二叉树的镜像情况，需要先对 `child` 执行“右旋”，再对 `node` 执行“左旋”。

   ![先右旋后左旋](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_right_left_rotate.png)

   图 7-31  先右旋后左旋

5. 旋转的选择

   图 7-32 展示的四种失衡情况与上述案例逐个对应，分别需要采用右旋、先左旋后右旋、先右旋后左旋、左旋的操作。

   ![AVL 树的四种旋转情况](https://www.hello-algo.com/chapter_tree/avl_tree.assets/avltree_rotation_cases.png)

   图 7-32  AVL 树的四种旋转情况

   如下表所示，我们通过判断失衡节点的平衡因子以及较高一侧子节点的平衡因子的正负号，来确定失衡节点属于图 7-32 中的哪种情况。

   表 7-3  四种旋转情况的选择条件

   | 失衡节点的平衡因子 | 子节点的平衡因子 | 应采用的旋转方法 |
| :----------------- | :--------------- | :--------------- |
   | >1（左偏树）       | >=0              | 右旋             |
   | >1（左偏树）       | <0               | 先左旋后右旋     |
   | <-1（右偏树）      | <=0              | 左旋             |
   | <-1（右偏树）      | >0               | 先右旋后左旋     |
   
   为了便于使用，我们将旋转操作封装成一个函数。**有了这个函数，我们就能对各种失衡情况进行旋转，使失衡节点重新恢复平衡**。代码如下所示：

   ```python
   def rotate(self, node: TreeNode | None) -> TreeNode | None:
       """执行旋转操作，使该子树重新恢复平衡"""
       # 获取节点 node 的平衡因子
       balance_factor = self.balance_factor(node)
       # 左偏树
       if balance_factor > 1:
           if self.balance_factor(node.left) >= 0:
               # 右旋
               return self.right_rotate(node)
           else:
               # 先左旋后右旋
               node.left = self.left_rotate(node.left)
               return self.right_rotate(node)
       # 右偏树
       elif balance_factor < -1:
           if self.balance_factor(node.right) <= 0:
               # 左旋
               return self.left_rotate(node)
           else:
               # 先右旋后左旋
               node.right = self.right_rotate(node.right)
               return self.left_rotate(node)
       # 平衡树，无须旋转，直接返回
       return node
   ```

#### 7.5.3  AVL 树常用操作

1. 插入节点

   AVL 树的节点插入操作与二叉搜索树在主体上类似。唯一的区别在于，在 AVL 树中插入节点后，从该节点到根节点的路径上可能会出现一系列失衡节点。因此，**我们需要从这个节点开始，自底向上执行旋转操作，使所有失衡节点恢复平衡**。代码如下所示：

   ```python
   def insert(self, val):
       """插入节点"""
       self._root = self.insert_helper(self._root, val)
   
   def insert_helper(self, node: TreeNode | None, val: int) -> TreeNode:
       """递归插入节点（辅助方法）"""
       if node is None:
           return TreeNode(val)
       # 1. 查找插入位置并插入节点
       if val < node.val:
           node.left = self.insert_helper(node.left, val)
       elif val > node.val:
           node.right = self.insert_helper(node.right, val)
       else:
           # 重复节点不插入，直接返回
           return node
       # 更新节点高度
       self.update_height(node)
       # 2. 执行旋转操作，使该子树重新恢复平衡
       return self.rotate(node)
   ```

2.  删除节点

    类似地，在二叉搜索树的删除节点方法的基础上，需要从底至顶执行旋转操作，使所有失衡节点恢复平衡。代码如下所示：

    ```python
    def remove(self, val: int):
        """删除节点"""
        self._root = self.remove_helper(self._root, val)
    
    def remove_helper(self, node: TreeNode | None, val: int) -> TreeNode | None:
        """递归删除节点（辅助方法）"""
        if node is None:
            return None
        # 1. 查找节点并删除
        if val < node.val:
            node.left = self.remove_helper(node.left, val)
        elif val > node.val:
            node.right = self.remove_helper(node.right, val)
        else:
            if node.left is None or node.right is None:
                child = node.left or node.right
                # 子节点数量 = 0 ，直接删除 node 并返回
                if child is None:
                    return None
                # 子节点数量 = 1 ，直接删除 node
                else:
                    node = child
            else:
                # 子节点数量 = 2 ，则将中序遍历的下个节点删除，并用该节点替换当前节点
                temp = node.right
                while temp.left is not None:
                    temp = temp.left
                node.right = self.remove_helper(node.right, temp.val)
                node.val = temp.val
        # 更新节点高度
        self.update_height(node)
        # 2. 执行旋转操作，使该子树重新恢复平衡
        return self.rotate(node)
    ```

3.  查找节点

    AVL 树的节点查找操作与二叉搜索树一致，在此不再赘述。

#### 7.5.4  AVL 树典型应用

- 组织和存储大型数据，适用于高频查找、低频增删的场景。
- 用于构建数据库中的索引系统。
- 红黑树也是一种常见的平衡二叉搜索树。相较于 AVL 树，红黑树的平衡条件更宽松，插入与删除节点所需的旋转操作更少，节点增删操作的平均效率更高。

### 7.6  小结

#### 1.  重点回顾

- 二叉树是一种非线性数据结构，体现“一分为二”的分治逻辑。每个二叉树节点包含一个值以及两个指针，分别指向其左子节点和右子节点。
- 对于二叉树中的某个节点，其左（右）子节点及其以下形成的树被称为该节点的左（右）子树。
- 二叉树的相关术语包括根节点、叶节点、层、度、边、高度和深度等。
- 二叉树的初始化、节点插入和节点删除操作与链表操作方法类似。
- 常见的二叉树类型有完美二叉树、完全二叉树、完满二叉树和平衡二叉树。完美二叉树是最理想的状态，而链表是退化后的最差状态。
- 二叉树可以用数组表示，方法是将节点值和空位按层序遍历顺序排列，并根据父节点与子节点之间的索引映射关系来实现指针。
- 二叉树的层序遍历是一种广度优先搜索方法，它体现了“一圈一圈向外扩展”的逐层遍历方式，通常通过队列来实现。
- 前序、中序、后序遍历皆属于深度优先搜索，它们体现了“先走到尽头，再回溯继续”的遍历方式，通常使用递归来实现。
- 二叉搜索树是一种高效的元素查找数据结构，其查找、插入和删除操作的时间复杂度均为$O(log n)$。当二叉搜索树退化为链表时，各项时间复杂度会劣化至$O(n)$。
- AVL 树，也称平衡二叉搜索树，它通过旋转操作确保在不断插入和删除节点后树仍然保持平衡。
- AVL 树的旋转操作包括右旋、左旋、先右旋再左旋、先左旋再右旋。在插入或删除节点后，AVL 树会从底向顶执行旋转操作，使树重新恢复平衡。

#### 2.  Q & A

**Q**：对于只有一个节点的二叉树，树的高度和根节点的深度都是 吗？

是的，因为高度和深度通常定义为“经过的边的数量”。

**Q**：二叉树中的插入与删除一般由一套操作配合完成，这里的“一套操作”指什么呢？可以理解为资源的子节点的资源释放吗？

拿二叉搜索树来举例，删除节点操作要分三种情况处理，其中每种情况都需要进行多个步骤的节点操作。

**Q**：为什么 DFS 遍历二叉树有前、中、后三种顺序，分别有什么用呢？

与顺序和逆序遍历数组类似，前序、中序、后序遍历是三种二叉树遍历方法，我们可以使用它们得到一个特定顺序的遍历结果。例如在二叉搜索树中，由于节点大小满足 `左子节点值 < 根节点值 < 右子节点值` ，因此我们只要按照“左 根 右”的优先级遍历树，就可以获得有序的节点序列。

**Q**：右旋操作是处理失衡节点 `node`、`child`、`grand_child` 之间的关系，那 `node` 的父节点和 `node` 原来的连接不需要维护吗？右旋操作后岂不是断掉了？

我们需要从递归的视角来看这个问题。右旋操作 `right_rotate(root)` 传入的是子树的根节点，最终 `return child` 返回旋转之后的子树的根节点。子树的根节点和其父节点的连接是在该函数返回后完成的，不属于右旋操作的维护范围。

**Q**：在 C++ 中，函数被划分到 `private` 和 `public` 中，这方面有什么考量吗？为什么要将 `height()` 函数和 `updateHeight()` 函数分别放在 `public` 和 `private` 中呢？

主要看方法的使用范围，如果方法只在类内部使用，那么就设计为 `private` 。例如，用户单独调用 `updateHeight()` 是没有意义的，它只是插入、删除操作中的一步。而 `height()` 是访问节点高度，类似于 `vector.size()` ，因此设置成 `public` 以便使用。

**Q**：如何从一组输入数据构建一棵二叉搜索树？根节点的选择是不是很重要？

是的，构建树的方法已在二叉搜索树代码中的 `build_tree()` 方法中给出。至于根节点的选择，我们通常会将输入数据排序，然后将中点元素作为根节点，再递归地构建左右子树。这样做可以最大程度保证树的平衡性。

**Q**：在 Java 中，字符串对比是否一定要用 `equals()` 方法？

在 Java 中，对于基本数据类型，`==` 用于对比两个变量的值是否相等。对于引用类型，两种符号的工作原理是不同的。

- `==` ：用来比较两个变量是否指向同一个对象，即它们在内存中的位置是否相同。
- `equals()`：用来对比两个对象的值是否相等。

因此，如果要对比值，我们应该使用 `equals()` 。然而，通过 `String a = "hi"; String b = "hi";` 初始化的字符串都存储在字符串常量池中，它们指向同一个对象，因此也可以用 `a == b` 来比较两个字符串的内容。

**Q**：广度优先遍历到最底层之前，队列中的节点数量是$2^h$吗？

是的，例如高度h=2的满二叉树，其节点总数n=7，则底层节点数量$4=2^h=(n+1)/2$。

## 第 8 章  堆

### 8.1  堆

堆（heap）是一种满足特定条件的完全二叉树，主要可分为两种类型，如图 8-1 所示。

- 小顶堆（min heap）：任意节点的值<=其子节点的值。
- 大顶堆（max heap）：任意节点的值>=其子节点的值。

![小顶堆与大顶堆](https://www.hello-algo.com/chapter_heap/heap.assets/min_heap_and_max_heap.png)

图 8-1  小顶堆与大顶堆

堆作为完全二叉树的一个特例，具有以下特性。

- 最底层节点靠左填充，其他层的节点都被填满。
- 我们将二叉树的根节点称为“堆顶”，将底层最靠右的节点称为“堆底”。
- 对于大顶堆（小顶堆），堆顶元素（根节点）的值是最大（最小）的。

#### 8.1.1  堆的常用操作

需要指出的是，许多编程语言提供的是优先队列（priority queue），这是一种抽象的数据结构，定义为具有优先级排序的队列。

实际上，**堆通常用于实现优先队列，大顶堆相当于元素按从大到小的顺序出队的优先队列**。从使用角度来看，我们可以将“优先队列”和“堆”看作等价的数据结构。因此，本书对两者不做特别区分，统一称作“堆”。

堆的常用操作见表 8-1 ，方法名需要根据编程语言来确定。

表 8-1  堆的操作效率

| 方法名      | 描述                                             | 时间复杂度 |
| :---------- | :----------------------------------------------- | :--------- |
| `push()`    | 元素入堆                                         | $O(log n)$ |
| `pop()`     | 堆顶元素出堆                                     | $O(log n)$ |
| `peek()`    | 访问堆顶元素（对于大 / 小顶堆分别为最大 / 小值） | $O(1)$     |
| `size()`    | 获取堆的元素数量                                 | $O(1)$     |
| `isEmpty()` | 判断堆是否为空                                   | $O(1)$     |

在实际应用中，我们可以直接使用编程语言提供的堆类（或优先队列类）。

类似于排序算法中的“从小到大排列”和“从大到小排列”，我们可以通过设置一个 `flag` 或修改 `Comparator` 实现“小顶堆”与“大顶堆”之间的转换。代码如下所示：

```python
# 初始化小顶堆
min_heap, flag = [], 1
# 初始化大顶堆
max_heap, flag = [], -1

# Python 的 heapq 模块默认实现小顶堆
# 考虑将“元素取负”后再入堆，这样就可以将大小关系颠倒，从而实现大顶堆
# 在本示例中，flag = 1 时对应小顶堆，flag = -1 时对应大顶堆

# 元素入堆
heapq.heappush(max_heap, flag * 1)
heapq.heappush(max_heap, flag * 3)
heapq.heappush(max_heap, flag * 2)
heapq.heappush(max_heap, flag * 5)
heapq.heappush(max_heap, flag * 4)

# 获取堆顶元素
peek: int = flag * max_heap[0] # 5

# 堆顶元素出堆
# 出堆元素会形成一个从大到小的序列
val = flag * heapq.heappop(max_heap) # 5
val = flag * heapq.heappop(max_heap) # 4
val = flag * heapq.heappop(max_heap) # 3
val = flag * heapq.heappop(max_heap) # 2
val = flag * heapq.heappop(max_heap) # 1

# 获取堆大小
size: int = len(max_heap)

# 判断堆是否为空
is_empty: bool = not max_heap

# 输入列表并建堆
min_heap: list[int] = [1, 3, 2, 5, 4]
heapq.heapify(min_heap)
```

#### 8.1.2  堆的实现

下文实现的是大顶堆。若要将其转换为小顶堆，只需将所有大小逻辑判断进行逆转（例如，将>=替换为<=）。感兴趣的读者可以自行实现。

1. 堆的存储与表示

   “二叉树”章节讲过，完全二叉树非常适合用数组来表示。由于堆正是一种完全二叉树，**因此我们将采用数组来存储堆**。

   当使用数组表示二叉树时，元素代表节点值，索引代表节点在二叉树中的位置。**节点指针通过索引映射公式来实现**。

   如图 8-2 所示，给定索引$i$，其左子节点的索引为$2i+1$，右子节点的索引为$2i+2$，父节点的索引为$(i-1)/2$（向下整除）。当索引越界时，表示空节点或节点不存在。

   ![堆的表示与存储](https://www.hello-algo.com/chapter_heap/heap.assets/representation_of_heap.png)

   图 8-2  堆的表示与存储

   我们可以将索引映射公式封装成函数，方便后续使用：

   ```python
   def left(self, i: int) -> int:
       """获取左子节点的索引"""
       return 2 * i + 1
   
   def right(self, i: int) -> int:
       """获取右子节点的索引"""
       return 2 * i + 2
   
   def parent(self, i: int) -> int:
       """获取父节点的索引"""
       return (i - 1) // 2  # 向下整除
   ```

2.  访问堆顶元素

    堆顶元素即为二叉树的根节点，也就是列表的首个元素：

    ```python
    def peek(self) -> int:
        """访问堆顶元素"""
        return self.max_heap[0]
    ```

3.  元素入堆

    给定元素 `val` ，我们首先将其添加到堆底。添加之后，由于 `val` 可能大于堆中其他元素，堆的成立条件可能已被破坏，**因此需要修复从插入节点到根节点的路径上的各个节点**，这个操作被称为堆化（heapify）。

    考虑从入堆节点开始，**从底至顶执行堆化**。如图 8-3 所示，我们比较插入节点与其父节点的值，如果插入节点更大，则将它们交换。然后继续执行此操作，从底至顶修复堆中的各个节点，直至越过根节点或遇到无须交换的节点时结束。

    ![heap_push_step8](https://www.hello-algo.com/chapter_heap/heap.assets/heap_push_step8.png)

    图 8-3  元素入堆步骤

    设节点总数为n，则树的高度为$O(log n)$。由此可知，堆化操作的循环轮数最多为$O(log n)$，**元素入堆操作的时间复杂度为**$O(log n)$。代码如下所示：

    ```python
    def push(self, val: int):
        """元素入堆"""
        # 添加节点
        self.max_heap.append(val)
        # 从底至顶堆化
        # self.size() - 1代表新插入元素在堆中的索引位置
        self.sift_up(self.size() - 1)
    
    def sift_up(self, i: int):
        """从节点 i 开始，从底至顶堆化"""
        while True:
            # 获取节点 i 的父节点
            p = self.parent(i)
            # 当“越过根节点”或“节点无须修复”时，结束堆化
            if p < 0 or self.max_heap[i] <= self.max_heap[p]:
                break
            # 交换两节点
            self.swap(i, p)
            # 循环向上堆化
            i = p
    ```

4.  堆顶元素出堆

    堆顶元素是二叉树的根节点，即列表首元素。如果我们直接从列表中删除首元素，那么二叉树中所有节点的索引都会发生变化，这将使得后续使用堆化进行修复变得困难。为了尽量减少元素索引的变动，我们采用以下操作步骤。

    1. 交换堆顶元素与堆底元素（交换根节点与最右叶节点）。
    2. 交换完成后，将堆底从列表中删除（注意，由于已经交换，因此实际上删除的是原来的堆顶元素）。
    3. 从根节点开始，**从顶至底执行堆化**。

    如图 8-4 所示，**“从顶至底堆化”的操作方向与“从底至顶堆化”相反**，我们将根节点的值与其两个子节点的值进行比较，将最大的子节点与根节点交换。然后循环执行此操作，直到越过叶节点或遇到无须交换的节点时结束。

    ![heap_pop_step9](https://www.hello-algo.com/chapter_heap/heap.assets/heap_pop_step9.png)

    图 8-4  堆顶元素出堆步骤

    与元素入堆操作相似，堆顶元素出堆操作的时间复杂度也为$O(log n)$。代码如下所示：

    ```python
    def pop(self) -> int:
        """元素出堆"""
        # 判空处理
        if self.is_empty():
            raise IndexError("堆为空")
        # 交换根节点与最右叶节点（交换首元素与尾元素）
        self.swap(0, self.size() - 1)
        # 删除节点
        # 不是递归调用，self.pop()才是递归调用，此处调用的是 Python 列表（list）自带的 pop() 方法。
        val = self.max_heap.pop()
        # 从顶至底堆化
        self.sift_down(0)
        # 返回堆顶元素
        return val
    
    def sift_down(self, i: int):
        """从节点 i 开始，从顶至底堆化"""
        while True:
            # 判断节点 i, l, r 中值最大的节点，记为 ma
            l, r, ma = self.left(i), self.right(i), i
            if l < self.size() and self.max_heap[l] > self.max_heap[ma]:
                ma = l
            if r < self.size() and self.max_heap[r] > self.max_heap[ma]:
                ma = r
            # 若节点 i 最大或索引 l, r 越界，则无须继续堆化，跳出
            if ma == i:
                break
            # 交换两节点
            self.swap(i, ma)
            # 循环向下堆化
            i = ma
    ```

#### 8.1.3  堆的常见应用

- **优先队列**：堆通常作为实现优先队列的首选数据结构，其入队和出队操作的时间复杂度均为$O(log n)$，而建堆操作为$O(n)$，这些操作都非常高效。
- **堆排序**：给定一组数据，我们可以用它们建立一个堆，然后不断地执行元素出堆操作，从而得到有序数据。然而，我们通常会使用一种更优雅的方式实现堆排序，详见“堆排序”章节。
- **获取最大的k个元素**：这是一个经典的算法问题，同时也是一种典型应用，例如选择热度前 10 的新闻作为微博热搜，选取销量前 10 的商品等。

### 8.2  建堆操作

在某些情况下，我们希望使用一个列表的所有元素来构建一个堆，这个过程被称为“建堆操作”。

#### 8.2.1  借助入堆操作实现

我们首先创建一个空堆，然后遍历列表，依次对每个元素执行“入堆操作”，即先将元素添加至堆的尾部，再对该元素执行“从底至顶”堆化。

每当一个元素入堆，堆的长度就加一。由于节点是从顶到底依次被添加进二叉树的，因此堆是“自上而下”构建的。

设元素数量为n，每个元素的入堆操作使用$O(log n)$时间，因此该建堆方法的时间复杂度为$O(nlog n)$。

#### 8.2.2  通过遍历堆化实现

实际上，我们可以实现一种更为高效的建堆方法，共分为两步。

1. 将列表所有元素原封不动地添加到堆中，此时堆的性质尚未得到满足。
2. 倒序遍历堆（层序遍历的倒序），依次对每个非叶节点执行“从顶至底堆化”。

**每当堆化一个节点后，以该节点为根节点的子树就形成一个合法的子堆**。而由于是倒序遍历，因此堆是“自下而上”构建的。

之所以选择倒序遍历，是因为这样能够保证当前节点之下的子树已经是合法的子堆，这样堆化当前节点才是有效的。

值得说明的是，**由于叶节点没有子节点，因此它们天然就是合法的子堆，无须堆化**。如以下代码所示，最后一个非叶节点是最后一个节点的父节点，我们从它开始倒序遍历并执行堆化：

```python
def __init__(self, nums: list[int]):
    """构造方法，根据输入列表建堆"""
    # 将列表元素原封不动添加进堆
    self.max_heap = nums
    # 堆化除叶节点以外的其他所有节点
    for i in range(self.parent(self.size() - 1), -1, -1):
        self.sift_down(i)
```

#### 8.2.3  复杂度分析

下面，我们来尝试推算第二种建堆方法的时间复杂度。

- 假设完全二叉树的节点数量为n，则叶节点数量为$(n+1)/2$，其中/为向下整除。因此需要堆化的节点数量为$(n-1)/2$。
- 在从顶至底堆化的过程中，每个节点最多堆化到叶节点，因此最大迭代次数为二叉树高度$logn$。

将上述两者相乘，可得到建堆过程的时间复杂度为$O(nlog n)$。**但这个估算结果并不准确，因为我们没有考虑到二叉树底层节点数量远多于顶层节点的性质**。

接下来我们来进行更为准确的计算。为了降低计算难度，假设给定一个节点数量为n、高度为h的“完美二叉树”，该假设不会影响计算结果的正确性。

![完美二叉树的各层节点数量](https://www.hello-algo.com/chapter_heap/build_heap.assets/heapify_operations_count.png)

图 8-5  完美二叉树的各层节点数量

如图 8-5 所示，节点“从顶至底堆化”的最大迭代次数等于该节点到叶节点的距离，而该距离正是“节点高度”。因此，我们可以对各层的“节点数量*节点高度”求和，**得到所有节点的堆化迭代次数的总和**。
$$
T(h)=2^0h+2^1(h-1)+2^2(h-2)+...+2^{(h-1)}*1
$$
化简上式需要借助中学的数列知识，先将$T(h)$乘以2，得到：
$$
T(h)=2^0h+2^1(h-1)+2^2(h-2)+...+2^{(h-1)}*1
$$

$$
2T(h)=2^1h+2^2(h-1)+2^3(h-2)+...+2^h*1
$$

使用错位相减法，用下式$2T(h)$减去上式$T(h)$ ，可得：
$$
2T(h)-T(h)=T(h)=-2^0h+2^1+2^2+...+2^{(h-1)}+2^h
$$
观察上式，发现$T(h)$是一个等比数列，可直接使用求和公式，得到时间复杂度为：
$$
T(h)=2*(1-2^h)/(1-2)-h=2^{(k+1)}-h-2=O(2^h)
$$
进一步，高度为$h$的完美二叉树的节点数量为$n=2^{(h+1)}$，易得复杂度为$O(2^h)=O(n)$。以上推算表明，**输入列表并建堆的时间复杂度为$O(n)$，非常高效**。

### 8.3  Top-k 问题

> 给定一个长度为n的无序数组 `nums` ，请返回数组中最大的k个元素。

对于该问题，我们先介绍两种思路比较直接的解法，再介绍效率更高的堆解法。

#### 8.3.1  方法一：遍历选择

我们可以进行图 8-6 所示的 轮遍历，分别在每轮中提取第1、2、...、k大的元素，时间复杂度为$O(nk)$。

此方法只适用于k<<n的情况，因为当k与n比较接近时，其时间复杂度趋向于$O(n^2)$，非常耗时。

![遍历寻找最大的 k 个元素](https://www.hello-algo.com/chapter_heap/top_k.assets/top_k_traversal.png)

图 8-6  遍历寻找最大的 k 个元素

> 当k=n时，我们可以得到完整的有序序列，此时等价于“选择排序”算法。

#### 8.3.2  方法二：排序

如图 8-7 所示，我们可以先对数组 `nums` 进行排序，再返回最右边的k个元素，时间复杂度为$O(nlog n)$。

显然，该方法“超额”完成任务了，因为我们只需找出最大的k个元素即可，而不需要排序其他元素。

![排序寻找最大的 k 个元素](https://www.hello-algo.com/chapter_heap/top_k.assets/top_k_sorting.png)

图 8-7  排序寻找最大的 k 个元素

#### 8.3.3  方法三：堆

我们可以基于堆更加高效地解决 Top-k 问题，流程如图 8-8 所示。

1. 初始化一个小顶堆，其堆顶元素最小。
2. 先将数组的前k个元素依次入堆。
3. 从第k+1个元素开始，若当前元素大于堆顶元素，则将堆顶元素出堆，并将当前元素入堆。
4. 遍历完成后，堆中保存的就是最大的k个元素。

![top_k_heap_step8](https://www.hello-algo.com/chapter_heap/top_k.assets/top_k_heap_step8.png)

图 8-8  基于堆寻找最大的 k 个元素

示例代码如下：

```python
def top_k_heap(nums: list[int], k: int) -> list[int]:
    """基于堆查找数组中最大的 k 个元素"""
    # 初始化小顶堆
    heap = []
    # 将数组的前 k 个元素入堆
    for i in range(k):
        heapq.heappush(heap, nums[i])
    # 从第 k+1 个元素开始，保持堆的长度为 k
    for i in range(k, len(nums)):
        # 若当前元素大于堆顶元素，则将堆顶元素出堆、当前元素入堆
        if nums[i] > heap[0]:
            heapq.heappop(heap)
            heapq.heappush(heap, nums[i])
    return heap
```

总共执行了n轮入堆和出堆，堆的最大长度为k，因此时间复杂度为$O(nlog k)$。该方法的效率很高，当k较小时，时间复杂度趋向$O(n)$；当k较大时，时间复杂度不会超过$O(nlog n)$。

另外，该方法适用于动态数据流的使用场景。在不断加入数据时，我们可以持续维护堆内的元素，从而实现最大的k个元素的动态更新。

#### Comment

![image-20250820182216751](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250820182216751.png)

### 8.4  小结

1. 重点回顾

   - 堆是一棵完全二叉树，根据成立条件可分为大顶堆和小顶堆。大（小）顶堆的堆顶元素是最大（小）的。
   - 优先队列的定义是具有出队优先级的队列，通常使用堆来实现。
   - 堆的常用操作及其对应的时间复杂度包括：元素入堆$O(log n)$、堆顶元素出堆$O(log n)$和访问堆顶元素$O(1)$等。
   - 完全二叉树非常适合用数组表示，因此我们通常使用数组来存储堆。
   - 堆化操作用于维护堆的性质，在入堆和出堆操作中都会用到。
   - 输入n个元素并建堆的时间复杂度可以优化至$O(n)$，非常高效。
   - Top-k 是一个经典算法问题，可以使用堆数据结构高效解决，时间复杂度为$O(nlog k)$。

2.  Q&A

    **Q**：数据结构的“堆”与内存管理的“堆”是同一个概念吗？

    两者不是同一个概念，只是碰巧都叫“堆”。计算机系统内存中的堆是动态内存分配的一部分，程序在运行时可以使用它来存储数据。程序可以请求一定量的堆内存，用于存储如对象和数组等复杂结构。当这些数据不再需要时，程序需要释放这些内存，以防止内存泄漏。相较于栈内存，堆内存的管理和使用需要更谨慎，使用不当可能会导致内存泄漏和野指针等问题。

## 第 9 章  图

### 9.1  图

图（graph）是一种非线性数据结构，由顶点（vertex）和边（edge）组成。我们可以将图G抽象地表示为一组顶点V和一组边E的集合。以下示例展示了一个包含 5 个顶点和 7 条边的图。
$$
V=\{1,2,3,4,5\}
$$

$$
E=\{(1,2),(1,3),(1,5),(2,3),(2,4),(2,5),(4,5)\}
$$

$$
G=\{V,E\}
$$

如果将顶点看作节点，将边看作连接各个节点的引用（指针），我们就可以将图看作一种从链表拓展而来的数据结构。如图 9-1 所示，**相较于线性关系（链表）和分治关系（树），网络关系（图）的自由度更高**，因而更为复杂。

![链表、树、图之间的关系](https://www.hello-algo.com/chapter_graph/graph.assets/linkedlist_tree_graph.png)

图 9-1  链表、树、图之间的关系

#### 9.1.1  图的常见类型与术语

根据边是否具有方向，可分为无向图（undirected graph）和有向图（directed graph），如图 9-2 所示。

- 在无向图中，边表示两顶点之间的“双向”连接关系，例如微信或 QQ 中的“好友关系”。
- 在有向图中，边具有方向性，即A->B和B->A两个方向的边是相互独立的，例如微博或抖音上的“关注”与“被关注”关系。

![有向图与无向图](https://www.hello-algo.com/chapter_graph/graph.assets/directed_graph.png)

图 9-2  有向图与无向图

根据所有顶点是否连通，可分为连通图（connected graph）和非连通图（disconnected graph），如图 9-3 所示。

- 对于连通图，从某个顶点出发，可以到达其余任意顶点。
- 对于非连通图，从某个顶点出发，至少有一个顶点无法到达。

![连通图与非连通图](https://www.hello-algo.com/chapter_graph/graph.assets/connected_graph.png)

图 9-3  连通图与非连通图

我们还可以为边添加“权重”变量，从而得到如图 9-4 所示的有权图（weighted graph）。例如在《王者荣耀》等手游中，系统会根据共同游戏时间来计算玩家之间的“亲密度”，这种亲密度网络就可以用有权图来表示。

![有权图与无权图](https://www.hello-algo.com/chapter_graph/graph.assets/weighted_graph.png)

图 9-4  有权图与无权图

图数据结构包含以下常用术语。

- 邻接（adjacency）：当两顶点之间存在边相连时，称这两顶点“邻接”。在图 9-4 中，顶点 1 的邻接顶点为顶点 2、3、5。
- 路径（path）：从顶点 A 到顶点 B 经过的边构成的序列被称为从 A 到 B 的“路径”。在图 9-4 中，边序列 1-5-2-4 是顶点 1 到顶点 4 的一条路径。
- 度（degree）：一个顶点拥有的边数。对于有向图，入度（in-degree）表示有多少条边指向该顶点，出度（out-degree）表示有多少条边从该顶点指出。

#### 9.1.2  图的表示

图的常用表示方式包括“邻接矩阵”和“邻接表”。以下使用无向图进行举例。

1. 邻接矩阵

   设图的顶点数量为n，邻接矩阵（adjacency matrix）使用一个n*n大小的矩阵来表示图，每一行（列）代表一个顶点，矩阵元素代表边，用1或0表示两个顶点之间是否存在边。

   如图 9-5 所示，设邻接矩阵为M、顶点列表为V，那么矩阵元素M[i,j]=1表示顶点V[i]到顶点V[j]之间存在边，反之M[i,j]=0表示两顶点之间无边。

   ![图的邻接矩阵表示](https://www.hello-algo.com/chapter_graph/graph.assets/adjacency_matrix.png)

   图 9-5  图的邻接矩阵表示

   邻接矩阵具有以下特性。

   - 在简单图中，顶点不能与自身相连，此时邻接矩阵主对角线元素没有意义。
   - 对于无向图，两个方向的边等价，此时邻接矩阵关于主对角线对称。
   - 将邻接矩阵的元素从1和0替换为权重，则可表示有权图。

   使用邻接矩阵表示图时，我们可以直接访问矩阵元素以获取边，因此增删查改操作的效率很高，时间复杂度均为$O(1)$。然而，矩阵的空间复杂度为$O(n^2)$，内存占用较多。

2.  邻接表

    邻接表（adjacency list）使用n个链表来表示图，链表节点表示顶点。第i个链表对应顶点i，其中存储了该顶点的所有邻接顶点（与该顶点相连的顶点）。图 9-6 展示了一个使用邻接表存储的图的示例。

    ![图的邻接表表示](https://www.hello-algo.com/chapter_graph/graph.assets/adjacency_list.png)

    图 9-6  图的邻接表表示

    邻接表仅存储实际存在的边，而边的总数通常远小于$n^2$，因此它更加节省空间。然而，在邻接表中需要通过遍历链表来查找边，因此其时间效率不如邻接矩阵。

    观察图 9-6 ，**邻接表结构与哈希表中的“链式地址”非常相似，因此我们也可以采用类似的方法来优化效率**。比如当链表较长时，可以将链表转化为 AVL 树或红黑树，从而将时间效率从$O(n)$优化至$O(logn)$；还可以把链表转换为哈希表，从而将时间复杂度降至$O(1)$。

#### 9.1.3  图的常见应用

如表 9-1 所示，许多现实系统可以用图来建模，相应的问题也可以约化为图计算问题。

表 9-1  现实生活中常见的图

|          | 顶点 | 边                   | 图计算问题   |
| :------- | :--- | :------------------- | ------------ |
| 社交网络 | 用户 | 好友关系             | 潜在好友推荐 |
| 地铁线路 | 站点 | 站点间的连通性       | 最短路线推荐 |
| 太阳系   | 星体 | 星体间的万有引力作用 | 行星轨道计算 |

### 9.2  图的基础操作

图的基础操作可分为对“边”的操作和对“顶点”的操作。在“邻接矩阵”和“邻接表”两种表示方法下，实现方式有所不同。

#### 9.2.1  基于邻接矩阵的实现

给定一个顶点数量为n的无向图，则各种操作的实现方式如图 9-7 所示。

- **添加或删除边**：直接在邻接矩阵中修改指定的边即可，使用$O(1)$时间。而由于是无向图，因此需要同时更新两个方向的边。
- **添加顶点**：在邻接矩阵的尾部添加一行一列，并全部填0即可，使用$O(n)$时间。
- **删除顶点**：在邻接矩阵中删除一行一列。当删除首行首列时达到最差情况，需要将$(n-1)^2$个元素“向左上移动”，从而使用$O(n^2)$时间。
- **初始化**：传入n个顶点，初始化长度为n的顶点列表 `vertices` ，使用$O(n)$时间；初始化n*n大小的邻接矩阵 `adjMat` ，使用$O(n^2)$时间。

![邻接矩阵的初始化、增删边、增删顶点](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_matrix_step1_initialization.png)

![adjacency_matrix_add_edge](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_matrix_step2_add_edge.png)

![adjacency_matrix_remove_edge](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_matrix_step3_remove_edge.png)

![adjacency_matrix_add_vertex](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_matrix_step4_add_vertex.png)

![adjacency_matrix_remove_vertex](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_matrix_step5_remove_vertex.png)

图 9-7  邻接矩阵的初始化、增删边、增删顶点

以下是基于邻接矩阵表示图的实现代码：

```python
class GraphAdjMat:
    """基于邻接矩阵实现的无向图类"""

    def __init__(self, vertices: list[int], edges: list[list[int]]):
        """构造方法"""
        # 顶点列表，元素代表“顶点值”，索引代表“顶点索引”
        self.vertices: list[int] = []
        # 邻接矩阵，行列索引对应“顶点索引”
        self.adj_mat: list[list[int]] = []
        # 添加顶点
        for val in vertices:
            self.add_vertex(val)
        # 添加边
        # 请注意，edges 元素代表顶点索引，即对应 vertices 元素索引
        for e in edges:
            self.add_edge(e[0], e[1])

    def size(self) -> int:
        """获取顶点数量"""
        return len(self.vertices)

    def add_vertex(self, val: int):
        """添加顶点"""
        n = self.size()
        # 向顶点列表中添加新顶点的值
        self.vertices.append(val)
        # 在邻接矩阵中添加一行
        new_row = [0] * n
        self.adj_mat.append(new_row)
        # 在邻接矩阵中添加一列
        for row in self.adj_mat:
            row.append(0)

    def remove_vertex(self, index: int):
        """删除顶点"""
        if index >= self.size():
            raise IndexError()
        # 在顶点列表中移除索引 index 的顶点
        self.vertices.pop(index)
        # 在邻接矩阵中删除索引 index 的行
        self.adj_mat.pop(index)
        # 在邻接矩阵中删除索引 index 的列
        for row in self.adj_mat:
            row.pop(index)

    def add_edge(self, i: int, j: int):
        """添加边"""
        # 参数 i, j 对应 vertices 元素索引
        # 索引越界与相等处理
        if i < 0 or j < 0 or i >= self.size() or j >= self.size() or i == j:
            raise IndexError()
        # 在无向图中，邻接矩阵关于主对角线对称，即满足 (i, j) == (j, i)
        self.adj_mat[i][j] = 1
        self.adj_mat[j][i] = 1

    def remove_edge(self, i: int, j: int):
        """删除边"""
        # 参数 i, j 对应 vertices 元素索引
        # 索引越界与相等处理
        if i < 0 or j < 0 or i >= self.size() or j >= self.size() or i == j:
            raise IndexError()
        self.adj_mat[i][j] = 0
        self.adj_mat[j][i] = 0

    def print(self):
        """打印邻接矩阵"""
        print("顶点列表 =", self.vertices)
        print("邻接矩阵 =")
        print_matrix(self.adj_mat)
```

#### 9.2.2  基于邻接表的实现

设无向图的顶点总数为n、边总数为m，则可根据图 9-8 所示的方法实现各种操作。

- **添加边**：在顶点对应链表的末尾添加边即可，使用$O(1)$时间。因为是无向图，所以需要同时添加两个方向的边。
- **删除边**：在顶点对应链表中查找并删除指定边，使用$O(m)$时间。在无向图中，需要同时删除两个方向的边。
- **添加顶点**：在邻接表中添加一个链表，并将新增顶点作为链表头节点，使用$O(1)$时间。
- **删除顶点**：需遍历整个邻接表，删除包含指定顶点的所有边，使用$O(n+m)$时间。
- **初始化**：在邻接表中创建n个顶点和2m条边，使用$O(n+m)$时间。

![邻接表的初始化、增删边、增删顶点](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_list_step1_initialization.png)

![adjacency_list_add_edge](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_list_step2_add_edge.png)

![adjacency_list_remove_edge](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_list_step3_remove_edge.png)

![adjacency_list_add_vertex](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_list_step4_add_vertex.png)

![adjacency_list_remove_vertex](https://www.hello-algo.com/chapter_graph/graph_operations.assets/adjacency_list_step5_remove_vertex.png)

图 9-8  邻接表的初始化、增删边、增删顶点

以下是邻接表的代码实现。对比图 9-8 ，实际代码有以下不同。

- 为了方便添加与删除顶点，以及简化代码，我们使用列表（动态数组）来代替链表。
- 使用哈希表来存储邻接表，`key` 为顶点实例，`value` 为该顶点的邻接顶点列表（链表）。

另外，我们在邻接表中使用 `Vertex` 类来表示顶点，这样做的原因是：如果与邻接矩阵一样，用列表索引来区分不同顶点，那么假设要删除索引为 的顶点，则需遍历整个邻接表，将所有大于 的索引全部减 ，效率很低。而如果每个顶点都是唯一的 `Vertex` 实例，删除某一顶点之后就无须改动其他顶点了。

```python
class GraphAdjList:
    """基于邻接表实现的无向图类"""

    def __init__(self, edges: list[list[Vertex]]):
        """构造方法"""
        # 邻接表，key：顶点，value：该顶点的所有邻接顶点
        self.adj_list = dict[Vertex, list[Vertex]]()
        # 添加所有顶点和边
        for edge in edges:
            self.add_vertex(edge[0])
            self.add_vertex(edge[1])
            self.add_edge(edge[0], edge[1])

    def size(self) -> int:
        """获取顶点数量"""
        return len(self.adj_list)

    def add_edge(self, vet1: Vertex, vet2: Vertex):
        """添加边"""
        if vet1 not in self.adj_list or vet2 not in self.adj_list or vet1 == vet2:
            raise ValueError()
        # 添加边 vet1 - vet2
        self.adj_list[vet1].append(vet2)
        self.adj_list[vet2].append(vet1)

    def remove_edge(self, vet1: Vertex, vet2: Vertex):
        """删除边"""
        if vet1 not in self.adj_list or vet2 not in self.adj_list or vet1 == vet2:
            raise ValueError()
        # 删除边 vet1 - vet2
        self.adj_list[vet1].remove(vet2)
        self.adj_list[vet2].remove(vet1)

    def add_vertex(self, vet: Vertex):
        """添加顶点"""
        if vet in self.adj_list:
            return
        # 在邻接表中添加一个新链表
        self.adj_list[vet] = []

    def remove_vertex(self, vet: Vertex):
        """删除顶点"""
        if vet not in self.adj_list:
            raise ValueError()
        # 在邻接表中删除顶点 vet 对应的链表
        self.adj_list.pop(vet)
        # 遍历其他顶点的链表，删除所有包含 vet 的边
        for vertex in self.adj_list:
            if vet in self.adj_list[vertex]:
                self.adj_list[vertex].remove(vet)

    def print(self):
        """打印邻接表"""
        print("邻接表 =")
        for vertex in self.adj_list:
            tmp = [v.val for v in self.adj_list[vertex]]
            print(f"{vertex.val}: {tmp},")
```

#### 9.2.3  效率对比

设图中共有n个顶点和m条边，表 9-2 对比了邻接矩阵和邻接表的时间效率和空间效率。请注意，邻接表（链表）对应本文实现，而邻接表（哈希表）专指将所有链表替换为哈希表后的实现。

表 9-2  邻接矩阵与邻接表对比

|              | 邻接矩阵 | 邻接表（链表） | 邻接表（哈希表） |
| :----------- | :------- | :------------- | ---------------- |
| 判断是否邻接 | $O(1)$   | $O(n)$         | $O(1)$           |
| 添加边       | $O(1)$   | $O(1)$         | $O(1)$           |
| 删除边       | $O(1)$   | $O(n)$         | $O(1)$           |
| 添加顶点     | $O(n)$   | $O(1)$         | $O(1)$           |
| 删除顶点     | $O(n^2)$ | $O(n+m)$       | $O(n)$           |
| 内存空间占用 | $O(n^2)$ | $O(n+m)$       | $O(n+m)$         |

观察表 9-2 ，似乎邻接表（哈希表）的时间效率与空间效率最优。但实际上，在邻接矩阵中操作边的效率更高，只需一次数组访问或赋值操作即可。综合来看，邻接矩阵体现了“以空间换时间”的原则，而邻接表体现了“以时间换空间”的原则。

邻接表存储的图中，删除一条边的时间复杂度为 **O(d)**（d 为边的端点的度），最坏情况下为 **O(n)**（当某个顶点与所有其他顶点相连时）。

### 9.3  图的遍历

树代表的是“一对多”的关系，而图则具有更高的自由度，可以表示任意的“多对多”关系。因此，我们可以把树看作图的一种特例。显然，**树的遍历操作也是图的遍历操作的一种特例**。

图和树都需要应用搜索算法来实现遍历操作。图的遍历方式也可分为两种：广度优先遍历和深度优先遍历。

#### 9.3.1  广度优先遍历

**广度优先遍历是一种由近及远的遍历方式，从某个节点出发，始终优先访问距离最近的顶点，并一层层向外扩张**。如图 9-9 所示，从左上角顶点出发，首先遍历该顶点的所有邻接顶点，然后遍历下一个顶点的所有邻接顶点，以此类推，直至所有顶点访问完毕。

![图的广度优先遍历](https://www.hello-algo.com/chapter_graph/graph_traversal.assets/graph_bfs.png)

图 9-9  图的广度优先遍历

1. 算法实现

   BFS 通常借助队列来实现，代码如下所示。队列具有“先入先出”的性质，这与 BFS 的“由近及远”的思想异曲同工。

   1. 将遍历起始顶点 `startVet` 加入队列，并开启循环。
   2. 在循环的每轮迭代中，弹出队首顶点并记录访问，然后将该顶点的所有邻接顶点加入到队列尾部。
   3. 循环步骤 `2.` ，直到所有顶点被访问完毕后结束。

   为了防止重复遍历顶点，我们需要借助一个哈希集合 `visited` 来记录哪些节点已被访问。

   > 哈希集合可以看作一个只存储 `key` 而不存储 `value` 的哈希表，它可以在$O(1)$时间复杂度下进行 `key` 的增删查改操作。根据 `key` 的唯一性，哈希集合通常用于数据去重等场景。

   ```python
   def graph_bfs(graph: GraphAdjList, start_vet: Vertex) -> list[Vertex]:
       """广度优先遍历"""
       # 使用邻接表来表示图，以便获取指定顶点的所有邻接顶点
       # 顶点遍历序列
       res = []
       # 哈希集合，用于记录已被访问过的顶点
       # set[Vertex]是 Python 的类型注解（Type Hint），表示 visited 是一个集合（set），且集合中元素的类型为 Vertex（顶点类，图中顶点的对象类型）。
       visited = set[Vertex]([start_vet])
       # 队列用于实现 BFS
       que = deque[Vertex]([start_vet])
       # 以顶点 vet 为起点，循环直至访问完所有顶点
       while len(que) > 0:
           vet = que.popleft()  # 队首顶点出队
           res.append(vet)  # 记录访问顶点
           # 遍历该顶点的所有邻接顶点
           for adj_vet in graph.adj_list[vet]:
               if adj_vet in visited:
                   continue  # 跳过已被访问的顶点
               que.append(adj_vet)  # 只入队未访问的顶点
               visited.add(adj_vet)  # 标记该顶点已被访问
       # 返回顶点遍历序列
       return res
   ```

   **广度优先遍历的序列**不唯一。广度优先遍历只要求按“由近及远”的顺序遍历，**而多个相同距离的顶点的遍历顺序允许被任意打乱**。以图 9-10 为例，顶点1、3的访问顺序可以交换，顶点2、4、6的访问顺序也可以任意交换。

2.  复杂度分析

    **时间复杂度**：所有顶点都会入队并出队一次，使用$O(|V|)$时间；在遍历邻接顶点的过程中，由于是无向图，因此所有边都会被访问2次，使用$O(2|E|)$时间；总体使用$O(|V|+|E|)$时间。

    **空间复杂度**：列表 `res` ，哈希集合 `visited` ，队列 `que` 中的顶点数量最多为|V|，使用$O(|V|)$空间。

#### 9.3.2  深度优先遍历

**深度优先遍历是一种优先走到底、无路可走再回头的遍历方式**。如图 9-11 所示，从左上角顶点出发，访问当前顶点的某个邻接顶点，直到走到尽头时返回，再继续走到尽头并返回，以此类推，直至所有顶点遍历完成。

![图的深度优先遍历](https://www.hello-algo.com/chapter_graph/graph_traversal.assets/graph_dfs.png)

图 9-11  图的深度优先遍历

1. 算法实现

   这种“走到尽头再返回”的算法范式通常基于递归来实现。与广度优先遍历类似，在深度优先遍历中，我们也需要借助一个哈希集合 `visited` 来记录已被访问的顶点，以避免重复访问顶点。

   ```python
   def dfs(graph: GraphAdjList, visited: set[Vertex], res: list[Vertex], vet: Vertex):
       """深度优先遍历辅助函数"""
       res.append(vet)  # 记录访问顶点
       visited.add(vet)  # 标记该顶点已被访问
       # 遍历该顶点的所有邻接顶点
       for adjVet in graph.adj_list[vet]:
           if adjVet in visited:
               continue  # 跳过已被访问的顶点
           # 递归访问邻接顶点
           dfs(graph, visited, res, adjVet)
   
   def graph_dfs(graph: GraphAdjList, start_vet: Vertex) -> list[Vertex]:
       """深度优先遍历"""
       # 使用邻接表来表示图，以便获取指定顶点的所有邻接顶点
       # 顶点遍历序列
       res = []
       # 哈希集合，用于记录已被访问过的顶点
       visited = set[Vertex]()
       dfs(graph, visited, res, start_vet)
       return res
   ```

   深度优先遍历的算法流程如图 9-12 所示。

   - **直虚线代表向下递推**，表示开启了一个新的递归方法来访问新顶点。
   - **曲虚线代表向上回溯**，表示此递归方法已经返回，回溯到了开启此方法的位置。























