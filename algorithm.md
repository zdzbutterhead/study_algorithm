![Hello 算法](https://www.hello-algo.com/assets/covers/chapter_hello_algo.jpg)

## 第 0 章  前言

### 0.1  关于本书

![前言](https://www.hello-algo.com/assets/covers/chapter_preface.jpg)

算法犹如美妙的交响乐，每一行代码都像韵律般流淌。

![本书主要内容](https://www.hello-algo.com/chapter_preface/about_the_book.assets/hello_algo_mindmap.png)

### 0.2  如何使用本书

#### 0.2.1  行文风格约定

- 标题后标注 `*` 的是选读章节，内容相对困难。如果你的时间有限，可以先跳过。
- 专业术语会使用黑体（纸质版和 PDF 版）或添加下划线（网页版），例如数组（array）。建议记住它们，以便阅读文献。
- 重点内容和总结性语句会 **加粗**，这类文字值得特别关注。
- 有特指含义的词句会使用“引号”标注，以避免歧义。
- 当涉及编程语言之间不一致的名词时，本书均以 Python 为准，例如使用 `None` 来表示“空”。
- 本书部分放弃了编程语言的注释规范，以换取更加紧凑的内容排版。注释主要分为三种类型：标题注释、内容注释、多行注释。

#### 0.2.3  在代码实践中加深理解

本书的配套代码托管在 [GitHub 仓库](https://github.com/krahets/hello-algo)。如图 0-3 所示，**源代码附有测试样例，可一键运行**。

如果时间允许，**建议你参照代码自行敲一遍**。如果学习时间有限，请至少通读并运行所有代码。

与阅读代码相比，编写代码的过程往往能带来更多收获。**动手学，才是真的学**。

运行代码的前置工作主要分为三步。

**第一步：安装本地编程环境**。请参照附录所示的[教程](https://www.hello-algo.com/chapter_appendix/installation/)进行安装，如果已安装，则可跳过此步骤。

**第二步：克隆或下载代码仓库**。前往 [GitHub 仓库](https://github.com/krahets/hello-algo)。如果已经安装 [Git](https://git-scm.com/downloads) ，可以通过以下命令克隆本仓库：

```
git clone https://github.com/krahets/hello-algo.git
```

当然，你也可以在图 0-4 所示的位置，点击“Download ZIP”按钮直接下载代码压缩包，然后在本地解压即可。

[![克隆仓库与下载代码](https://www.hello-algo.com/chapter_preface/suggestions.assets/download_code.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/download_code.png)

图 0-4  克隆仓库与下载代码

**第三步：运行源代码**。如图 0-5 所示，对于顶部标有文件名称的代码块，我们可以在仓库的 `codes` 文件夹内找到对应的源代码文件。源代码文件可一键运行，将帮助你节省不必要的调试时间，让你能够专注于学习内容。

[![代码块与对应的源代码文件](https://www.hello-algo.com/chapter_preface/suggestions.assets/code_md_to_repo.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/code_md_to_repo.png)

图 0-5  代码块与对应的源代码文件

除了本地运行代码，**网页版还支持 Python 代码的可视化运行**（基于 [pythontutor](https://pythontutor.com/) 实现）。如图 0-6 所示，你可以点击代码块下方的“可视化运行”来展开视图，观察算法代码的执行过程；也可以点击“全屏观看”，以获得更好的阅览体验。

[![Python 代码的可视化运行](https://www.hello-algo.com/chapter_preface/suggestions.assets/pythontutor_example.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/pythontutor_example.png)

图 0-6  Python 代码的可视化运行

#### 0.2.5  算法学习路线

从总体上看，我们可以将学习数据结构与算法的过程划分为三个阶段。

1. **阶段一：算法入门**。我们需要熟悉各种数据结构的特点和用法，学习不同算法的原理、流程、用途和效率等方面的内容。
2. **阶段二：刷算法题**。建议从热门题目开刷，先积累至少 100 道题目，熟悉主流的算法问题。初次刷题时，“知识遗忘”可能是一个挑战，但请放心，这是很正常的。我们可以按照“艾宾浩斯遗忘曲线”来复习题目，通常在进行 3～5 轮的重复后，就能将其牢记在心。推荐的题单和刷题计划请见此 [GitHub 仓库](https://github.com/krahets/LeetCode-Book)。
3. **阶段三：搭建知识体系**。在学习方面，我们可以阅读算法专栏文章、解题框架和算法教材，以不断丰富知识体系。在刷题方面，可以尝试采用进阶刷题策略，如按专题分类、一题多解、一解多题等，相关的刷题心得可以在各个社区找到。

如图 0-8 所示，本书内容主要涵盖“阶段一”，旨在帮助你更高效地展开阶段二和阶段三的学习。

[![算法学习路线](https://www.hello-algo.com/chapter_preface/suggestions.assets/learning_route.png)](https://www.hello-algo.com/chapter_preface/suggestions.assets/learning_route.png)

图 0-8  算法学习路线

## 第 1 章  初识算法 

![初识算法](https://www.hello-algo.com/assets/covers/chapter_introduction.jpg)

### 1.1  算法无处不在

**例一：查字典**。在字典里，每个汉字都对应一个拼音，而字典是按照拼音字母顺序排列的。假设我们需要查找一个拼音首字母为 的字，通常会按照图 1-1 所示的方式实现。

1. 翻开字典约一半的页数，查看该页的首字母是什么，假设首字母为 。
2. 由于在拼音字母表中 位于 之后，所以排除字典前半部分，查找范围缩小到后半部分。
3. 不断重复步骤 `1.` 和步骤 `2.` ，直至找到拼音首字母为 的页码为止。

查字典这个小学生必备技能，实际上就是著名的“二分查找”算法。从数据结构的角度，我们可以把字典视为一个已排序的“数组”；从算法的角度，我们可以将上述查字典的一系列操作看作“二分查找”。

**例二：整理扑克**。我们在打牌时，每局都需要整理手中的扑克牌，使其从小到大排列，实现流程如图 1-2 所示。

1. 将扑克牌划分为“有序”和“无序”两部分，并假设初始状态下最左 1 张扑克牌已经有序。
2. 在无序部分抽出一张扑克牌，插入至有序部分的正确位置；完成后最左 2 张扑克已经有序。
3. 不断循环步骤 `2.` ，每一轮将一张扑克牌从无序部分插入至有序部分，直至所有扑克牌都有序。

[![扑克排序步骤](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/playing_cards_sorting.png)](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/playing_cards_sorting.png)

图 1-2  扑克排序步骤

上述整理扑克牌的方法本质上是“插入排序”算法，它在处理小型数据集时非常高效。许多编程语言的排序库函数中都有插入排序的身影。

**例三：货币找零**。假设我们在超市购买了 元的商品，给了收银员 元，则收银员需要找我们 元。他会很自然地完成如图 1-3 所示的思考。

1. 可选项是比31元面值更小的货币，包括1元、5元、10元、20元。
2. 从可选项中拿出最大的20元，剩余31-20=11元。
3. 从剩余可选项中拿出最大的10元，剩余11-10=1元。
4. 从剩余可选项中拿出最大的1元，剩余1-1=0元。
5. 完成找零，方案为20+10+1=31元。

[![货币找零过程](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/greedy_change.png)](https://www.hello-algo.com/chapter_introduction/algorithms_are_everywhere.assets/greedy_change.png)

图 1-3  货币找零过程

在以上步骤中，我们每一步都采取当前看来最好的选择（尽可能用大面额的货币），最终得到了可行的找零方案。从数据结构与算法的角度看，这种方法本质上是“贪心”算法。

### 1.2  算法是什么

#### 1.2.1  算法定义

算法（algorithm）是在有限时间内解决特定问题的一组指令或操作步骤，它具有以下特性。

- 问题是明确的，包含清晰的输入和输出定义。
- 具有可行性，能够在有限步骤、时间和内存空间下完成。
- 各步骤都有确定的含义，在相同的输入和运行条件下，输出始终相同。

#### 1.2.2  数据结构定义

数据结构（data structure）是组织和存储数据的方式，涵盖数据内容、数据之间关系和数据操作方法，它具有以下设计目标。

- 空间占用尽量少，以节省计算机内存。
- 数据操作尽可能快速，涵盖数据访问、添加、删除、更新等。
- 提供简洁的数据表示和逻辑信息，以便算法高效运行。

**数据结构设计是一个充满权衡的过程**。如果想在某方面取得提升，往往需要在另一方面作出妥协。下面举两个例子。

- 链表相较于数组，在数据添加和删除操作上更加便捷，但牺牲了数据访问速度。
- 图相较于链表，提供了更丰富的逻辑信息，但需要占用更大的内存空间。

#### 1.2.3  数据结构与算法的关系

- 数据结构是算法的基石。数据结构为算法提供了结构化存储的数据，以及操作数据的方法。
- 算法为数据结构注入生命力。数据结构本身仅存储数据信息，结合算法才能解决特定问题。
- 算法通常可以基于不同的数据结构实现，但执行效率可能相差很大，选择合适的数据结构是关键。

[![数据结构与算法的关系](https://www.hello-algo.com/chapter_introduction/what_is_dsa.assets/relationship_between_data_structure_and_algorithm.png)](https://www.hello-algo.com/chapter_introduction/what_is_dsa.assets/relationship_between_data_structure_and_algorithm.png)

图 1-4  数据结构与算法的关系

数据结构与算法犹如拼装积木。一套积木，除了包含许多零件之外，还附有详细的组装说明书。我们按照说明书一步步操作，就能组装出精美的积木模型。

两者的详细对应关系如表 1-1 所示。

表 1-1  将数据结构与算法类比为拼装积木

| 数据结构与算法 | 拼装积木                                 |
| :------------- | :--------------------------------------- |
| 输入数据       | 未拼装的积木                             |
| 数据结构       | 积木组织形式，包括形状、大小、连接方式等 |
| 算法           | 把积木拼成目标形态的一系列操作步骤       |
| 输出数据       | 积木模型                                 |

值得说明的是，数据结构与算法是独立于编程语言的。正因如此，本书得以提供基于多种编程语言的实现。

在实际讨论时，我们通常会将“数据结构与算法”简称为“算法”。比如众所周知的 LeetCode 算法题目，实际上同时考查数据结构和算法两方面的知识。

我认为学算法（以及其他基础科目）的意义不是在于在工作中从零实现它，而是基于学到的知识，在解决问题时能够作出专业的反应和判断，从而提升工作的整体质量。

在工程领域中，大量问题是难以达到最优解的，许多问题只是被“差不多”地解决了。问题的难易程度一方面取决于问题本身的性质，另一方面也取决于观测问题的人的知识储备。人的知识越完备、经验越多，分析问题就会越深入，问题就能被解决得更优雅。

## 第 2 章  复杂度分析

![复杂度分析](https://www.hello-algo.com/assets/covers/chapter_complexity_analysis.jpg)

（第一眼以为三体的封面）

### 2.1  算法效率评估

在算法设计中，我们先后追求以下两个层面的目标。

1. **找到问题解法**：算法需要在规定的输入范围内可靠地求得问题的正确解。
2. **寻求最优解法**：同一个问题可能存在多种解法，我们希望找到尽可能高效的算法。

也就是说，在能够解决问题的前提下，算法效率已成为衡量算法优劣的主要评价指标，它包括以下两个维度。

- **时间效率**：算法运行时间的长短。
- **空间效率**：算法占用内存空间的大小。

效率评估方法主要分为两种：实际测试、理论估算。

#### 2.1.1  实际测试

假设我们现在有算法 `A` 和算法 `B` ，它们都能解决同一问题，现在需要对比这两个算法的效率。最直接的方法是找一台计算机，运行这两个算法，并监控记录它们的运行时间和内存占用情况。这种评估方式能够反映真实情况，但也存在较大的局限性。

一方面，**难以排除测试环境的干扰因素**。硬件配置会影响算法的性能表现。比如一个算法的并行度较高，那么它就更适合在多核 CPU 上运行，一个算法的内存操作密集，那么它在高性能内存上的表现就会更好。也就是说，算法在不同的机器上的测试结果可能是不一致的。这意味着我们需要在各种机器上进行测试，统计平均效率，而这是不现实的。

另一方面，**展开完整测试非常耗费资源**。随着输入数据量的变化，算法会表现出不同的效率。例如，在输入数据量较小时，算法 `A` 的运行时间比算法 `B` 短；而在输入数据量较大时，测试结果可能恰恰相反。因此，为了得到有说服力的结论，我们需要测试各种规模的输入数据，而这需要耗费大量的计算资源。

#### 2.1.2  理论估算

由于实际测试具有较大的局限性，我们可以考虑仅通过一些计算来评估算法的效率。这种估算方法被称为渐近复杂度分析（asymptotic complexity analysis），简称复杂度分析。

复杂度分析能够体现算法运行所需的时间和空间资源与输入数据大小之间的关系。**它描述了随着输入数据大小的增加，算法执行所需时间和空间的增长趋势**。这个定义有些拗口，我们可以将其分为三个重点来理解。

- “时间和空间资源”分别对应时间复杂度（time complexity）和空间复杂度（space complexity）。
- “随着输入数据大小的增加”意味着复杂度反映了算法运行效率与输入数据体量之间的关系。
- “时间和空间的增长趋势”表示复杂度分析关注的不是运行时间或占用空间的具体值，而是时间或空间增长的“快慢”。

**复杂度分析克服了实际测试方法的弊端**，体现在以下几个方面。

- 它无需实际运行代码，更加绿色节能。
- 它独立于测试环境，分析结果适用于所有运行平台。
- 它可以体现不同数据量下的算法效率，尤其是在大数据量下的算法性能。

#### Comment

作者认为：“时间效率”整体上指的就是算法在“时间”上的快慢，而非运行计算次数。还有人则说： 时间效率指算法运行的计算次数。

是的，原因很直接：我们提出时间效率这个概念，最终想要关心的是“时间”上的快慢，而不是“执行次数”。

执行次数更多和时间复杂度关联，它是反映时间效率的有效指标，但很有可能给出错误的结论。我们有时会遇到一种情况：算法 A 比算法 B 的时间复杂度更高（更差），但反而在给定数据下运行地更快（时间更短、效率更高）。一个典型的例子是插入排序 vs. 归并排序在数据量较小时的效率对比。

### 2.2  迭代与递归

在算法中，重复执行某个任务是很常见的，它与复杂度分析息息相关。因此，在介绍时间复杂度和空间复杂度之前，我们先来了解如何在程序中实现重复执行任务，即两种基本的程序控制结构：迭代、递归。

#### 2.2.1  迭代

迭代（iteration）是一种重复执行某个任务的控制结构。在迭代中，程序会在满足一定的条件下重复执行某段代码，直到这个条件不再满足。

1.  for 循环

`for` 循环是最常见的迭代形式之一，**适合在预先知道迭代次数时使用**。

2.  while 循环

与 `for` 循环类似，`while` 循环也是一种实现迭代的方法。在 `while` 循环中，程序每轮都会先检查条件，如果条件为真，则继续执行，否则就结束循环。

**`while` 循环比 `for` 循环的自由度更高**。在 `while` 循环中，我们可以自由地设计条件变量的初始化和更新步骤。

总的来说，**`for` 循环的代码更加紧凑，`while` 循环更加灵活**，两者都可以实现迭代结构。选择使用哪一个应该根据特定问题的需求来决定。

3. 嵌套循环

我们可以在一个循环结构内嵌套另一个循环结构

```python
def nested_for_loop(n: int) -> str:
    """双层 for 循环"""
    res = ""
    # 循环 i = 1, 2, ..., n-1, n
    for i in range(1, n + 1):
        # 循环 j = 1, 2, ..., n-1, n
        for j in range(1, n + 1):
            res += f"({i}, {j}), "
    return res
```

`res += f"({i}, {j}), "` 是一个使用 Python **f-strings**（格式化字符串）的赋值语句，用于动态构建字符串。

#### 2.2.2  递归

递归（recursion）是一种算法策略，通过函数调用自身来解决问题。它主要包含两个阶段。

1. **递**：程序不断深入地调用自身，通常传入更小或更简化的参数，直到达到“终止条件”。
2. **归**：触发“终止条件”后，程序从最深层的递归函数开始逐层返回，汇聚每一层的结果。

而从实现的角度看，递归代码主要包含三个要素。

1. **终止条件**：用于决定什么时候由“递”转“归”。
2. **递归调用**：对应“递”，函数调用自身，通常输入更小或更简化的参数。
3. **返回结果**：对应“归”，将当前递归层级的结果返回至上一层。

虽然从计算角度看，迭代与递归可以得到相同的结果，**但它们代表了两种完全不同的思考和解决问题的范式**。

- **迭代**：“自下而上”地解决问题。从最基础的步骤开始，然后不断重复或累加这些步骤，直到任务完成。
- **递归**：“自上而下”地解决问题。将原问题分解为更小的子问题，这些子问题和原问题具有相同的形式。接下来将子问题继续分解为更小的子问题，直到基本情况时停止（基本情况的解是已知的）。

1.  调用栈

递归函数每次调用自身时，系统都会为新开启的函数分配内存，以存储局部变量、调用地址和其他信息等。这将导致两方面的结果。

- 函数的上下文数据都存储在称为“栈帧空间”的内存区域中，直至函数返回后才会被释放。因此，**递归通常比迭代更加耗费内存空间**。
- 递归调用函数会产生额外的开销。**因此递归通常比循环的时间效率更低**。

在实际中，编程语言允许的递归深度通常是有限的，过深的递归可能导致栈溢出错误。

2. 尾递归

有趣的是，**如果函数在返回前的最后一步才进行递归调用**，则该函数可以被编译器或解释器优化，使其在空间效率上与迭代相当。这种情况被称为尾递归（tail recursion）。

- **普通递归**：当函数返回到上一层级的函数后，需要继续执行代码，因此系统需要保存上一层调用的上下文。
- **尾递归**：递归调用是函数返回前的最后一个操作，这意味着函数返回到上一层级后，无须继续执行其他操作，因此系统无须保存上一层函数的上下文。

```python
# 普通递归
def recur(n: int) -> int:
    """递归"""
    # 终止条件
    if n == 1:
        return 1
    # 递：递归调用
    res = recur(n - 1)
    # 归：返回结果
    return n + res
```

![求和函数的递归过程](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/recursion_sum.png)

```python
# 尾递归
def tail_recur(n, res):
    # 终止条件
    if n == 0:
        return res
    # 尾递归调用
    return tail_recur(n - 1, res + n)

# 不属于尾递归
def recursion(n:int)->int:
    if n == 1:
        return 1
    else:
        return n + recursion(n-1)
# 该递归函数不属于尾递归。尾递归的定义是：递归调用是函数的最后一个操作，且返回值直接传递给上层。而你的代码中，递归调用 recursion(n-1) 之后还需要执行加法操作 n + ...，因此不符合尾递归的条件。
'''
尾递归通常需要通过累加器参数来保存中间结果，避免递归返回后执行额外操作
累加器 acc：用于保存当前的累加和。
递归调用：直接返回 tail_recursion(...)，无后续操作。
'''
```

![尾递归过程](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/tail_recursion_sum.png)

> 请注意，许多编译器或解释器并不支持尾递归优化。例如，Python 默认不支持尾递归优化，因此即使函数是尾递归形式，仍然可能会遇到栈溢出问题。

3. 递归树

当处理与“分治”相关的算法问题时，递归往往比迭代的思路更加直观、代码更加易读。

```python
def fib(n: int) -> int:
    """斐波那契数列：递归"""
    # 终止条件 f(1) = 0, f(2) = 1
    if n == 1 or n == 2:
        return n - 1
    # 递归调用 f(n) = f(n-1) + f(n-2)
    res = fib(n - 1) + fib(n - 2)
    # 返回结果 f(n)
    return res
```

观察以上代码，我们在函数内递归调用了两个函数，**这意味着从一个调用产生了两个调用分支**。如图 2-6 所示，这样不断递归调用下去，最终将产生一棵层数为 的递归树（recursion tree）。

![斐波那契数列的递归树](https://www.hello-algo.com/chapter_computational_complexity/iteration_and_recursion.assets/recursion_tree.png)

图 2-6  斐波那契数列的递归树

递归的执行顺序是**深度优先、先左后右的 “后序处理”**

从本质上看，递归体现了“将问题分解为更小子问题”的思维范式，这种分治策略至关重要。

- 从算法角度看，搜索、排序、回溯、分治、动态规划等许多重要算法策略直接或间接地应用了这种思维方式。
- 从数据结构角度看，递归天然适合处理链表、树和图的相关问题，因为它们非常适合用分治思想进行分析。

#### 2.2.3  两者对比

表 2-1  迭代与递归特点对比

|          | 迭代                                   | 递归                                                         |
| :------- | :------------------------------------- | :----------------------------------------------------------- |
| 实现方式 | 循环结构                               | 函数调用自身                                                 |
| 时间效率 | 效率通常较高，无函数调用开销           | 每次函数调用都会产生开销                                     |
| 内存使用 | 通常使用固定大小的内存空间             | 累积函数调用可能使用大量的栈帧空间                           |
| 适用问题 | 适用于简单循环任务，代码直观、可读性好 | 适用于子问题分解，如树、图、分治、回溯等，代码结构简洁、清晰 |

那么，迭代和递归具有什么内在联系呢？以上述递归函数为例，求和操作在递归的“归”阶段进行。这意味着最初被调用的函数实际上是最后完成其求和操作的，**这种工作机制与栈的“先入后出”原则异曲同工**。

事实上，“调用栈”和“栈帧空间”这类递归术语已经暗示了递归与栈之间的密切关系。

1. **递**：当函数被调用时，系统会在“调用栈”上为该函数分配新的栈帧，用于存储函数的局部变量、参数、返回地址等数据。
2. **归**：当函数完成执行并返回时，对应的栈帧会被从“调用栈”上移除，恢复之前函数的执行环境。

尽管迭代和递归在很多情况下可以互相转化，但不一定值得这样做，有以下两点原因。

- 转化后的代码可能更加难以理解，可读性更差。
- 对于某些复杂问题，模拟系统调用栈的行为可能非常困难。

总之，**选择迭代还是递归取决于特定问题的性质**。在编程实践中，权衡两者的优劣并根据情境选择合适的方法至关重要。

#### Comment

事实上 [所有的递归都能被写成迭代](https://stackoverflow.com/questions/931762/can-every-recursion-be-converted-into-iteration) 。

**普通递归**和**尾递归**这两个概念有点不太好理解，我是不是可以这么想：

- 重要区别有两个：【什么时候**返回**】，【什么时候**计算**】

1. 普通递归，是一直**找到最底，找到了然后才逐层计算并返回结果**，需要记录过程数据📝

> 每次递归调用都会产生一个新的函数实例，每个实例都需要等待其子实例返回结果后才能进行计算并返回自己的结果。

> 这样一来，所有的函数实例都需要在内存中保持活跃状态，直到最底层的实例计算并返回结果，然后逐级传回。

> 因此，需要大量的内存空间来维护这个调用栈。

1. 尾递归，可以**边计算边返回**，不需要记录过程数据📝

> 由于递归调用是函数的最后一步操作，因此在进行递归调用时，不需要保留当前函数实例的状态，可以直接使用新的函数实例替换掉当前实例。

> 无论递归多少次，都只需要一个函数实例的内存空间，大大减少了内存消耗。这也是为什么尾递归对于处理大规模数据或深度递归时具有优势的原因。

当然，这里的`递归调用是函数的最后一步操作`我一开始也有点懵。

如果拿普通递归的代码 ：`return n + res` 和尾递归的代码`return tail_recur(n - 1, res + n)` 单独抽出来理解

- `return n + res` 的 res 是调用递归，整个大函数在调用递归之后还在”等待“，等res回来，要和 n 相加。也就是说，递归调用是函数操作的倒数第二步。
- 而`return tail_recur(n - 1, res + n)` 的 tail_recur(n - 1, res + n)是递归调用，直接就是返回的最后一步操作，对于函数来说，只需要返回这个调用就行，不需要做其他的任何操作，返回之后就结束了，和当前的函数没有任何关系了，可以“释放”了

然后我结合 ChatGPT 给到的类比做了一个优化。

递归这个事情，有点像**拆积木和堆积木**。把 `A 地`的积木拆开，然后**按照顺序**堆到 `B 地`。

1. "递归调用"对应于"拆积木"的动作
2. "返回结果"对应于"堆积木"的动作。
3. 普通递归：把 1、2、3 层的积木先拆开，按顺序摆在桌子上（记住顺序），然后找到最后一层，再开始堆。
4. 尾递归：一边拆积木，一边堆积木，不许要记住顺序，就拆完就堆。

### 2.3  时间复杂度

运行时间可以直观且准确地反映算法的效率。如果我们想准确预估一段代码的运行时间，应该如何操作呢？

1. **确定运行平台**，包括硬件配置、编程语言、系统环境等，这些因素都会影响代码的运行效率。
2. **评估各种计算操作所需的运行时间**，例如加法操作 `+` 需要 1 ns ，乘法操作 `*` 需要 10 ns ，打印操作 `print()` 需要 5 ns 等。
3. **统计代码中所有的计算操作**，并将所有操作的执行时间求和，从而得到运行时间。

但实际上，**统计算法的运行时间既不合理也不现实**。首先，我们不希望将预估时间和运行平台绑定，因为算法需要在各种不同的平台上运行。其次，我们很难获知每种操作的运行时间，这给预估过程带来了极大的难度。

#### 2.3.1  统计时间增长趋势

时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**。

```python
# 算法 A 的时间复杂度：常数阶
def algorithm_A(n: int):
    print(0)
# 算法 B 的时间复杂度：线性阶
def algorithm_B(n: int):
    for _ in range(n):
        print(0)
# 算法 C 的时间复杂度：常数阶
def algorithm_C(n: int):
    for _ in range(1000000):
        print(0)
```

图 2-7 展示了以上三个算法函数的时间复杂度。

- 算法 `A` 只有 个打印操作，算法运行时间不随着 增大而增长。我们称此算法的时间复杂度为“常数阶”。
- 算法 `B` 中的打印操作需要循环 次，算法运行时间随着 增大呈线性增长。此算法的时间复杂度被称为“线性阶”。
- 算法 `C` 中的打印操作需要循环 次，虽然运行时间很长，但它与输入数据大小 无关。因此 `C` 的时间复杂度和 `A` 相同，仍为“常数阶”。

[![算法 A、B 和 C 的时间增长趋势](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_simple_example.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_simple_example.png)

图 2-7  算法 A、B 和 C 的时间增长趋势

相较于直接统计算法的运行时间，时间复杂度分析有哪些特点呢？

- **时间复杂度能够有效评估算法效率**。例如，算法 `B` 的运行时间呈线性增长，在n>1时比算法 `A` 更慢，在n>1000000时比算法 `C` 更慢。事实上，只要输入数据大小n足够大，复杂度为“常数阶”的算法一定优于“线性阶”的算法，这正是时间增长趋势的含义。
- **时间复杂度的推算方法更简便**。显然，运行平台和计算操作类型都与算法运行时间的增长趋势无关。因此在时间复杂度分析中，我们可以简单地将所有计算操作的执行时间视为相同的“单位时间”，从而将“计算操作运行时间统计”简化为“计算操作数量统计”，这样一来估算难度就大大降低了。
- **时间复杂度也存在一定的局限性**。例如，尽管算法 `A` 和 `C` 的时间复杂度相同，但实际运行时间差别很大。同样，尽管算法 `B` 的时间复杂度比 `C` 高，但在输入数据大小n较小时，算法 `B` 明显优于算法 `C` 。对于此类情况，我们时常难以仅凭时间复杂度判断算法效率的高低。当然，尽管存在上述问题，复杂度分析仍然是评判算法效率最有效且常用的方法。

#### 2.3.2  函数渐近上界

```python
def algorithm(n: int):
    a = 1      # +1
    a = a + 1  # +1
    a = a * 2  # +1
    # 循环 n 次
    for i in range(n):  # +1
        print(0)        # +1
```

设算法的操作数量是一个关于输入数据大小n的函数，记为T(n)，则以上函数的操作数量为：T(n)=3+2n


T(n)是一次函数，说明其运行时间的增长趋势是线性的，因此它的时间复杂度是线性阶。

我们将线性阶的时间复杂度记为O(n)，这个数学符号称为大O记号（big-O notation），表示函数T(n)的渐近上界（asymptotic upper bound）。

时间复杂度分析本质上是计算“操作数量T(n)”的渐近上界，它具有明确的数学定义。

如图 2-8 所示，计算渐近上界就是寻找一个函数f(n)，使得当n趋向于无穷大时，T(n)和f(n)处于相同的增长级别，仅相差一个常数系数c。

[![函数的渐近上界](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/asymptotic_upper_bound.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/asymptotic_upper_bound.png)

图 2-8  函数的渐近上界

#### 2.3.3  推算方法

1. 第一步：统计操作数量(其实就是看最深层循环次数或递归次数)

   针对代码，逐行从上到下计算即可。然而，由于上述c*f(n)中的常数系数c可以取任意大小，**因此操作数量T(n)中的各种系数、常数项都可以忽略**。根据此原则，可以总结出以下计数简化技巧。

   1. **忽略T(n)中的常数**。因为它们都与n无关，所以对时间复杂度不产生影响。
   2. **省略所有系数**。例如，循环2n次、5n+1次等，都可以简化记为n次，因为n前面的系数对时间复杂度没有影响。
   3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 `1.` 点和第 `2.` 点的技巧。

2. 第二步：判断渐近上界

   **时间复杂度由T(n)中最高阶的项来决定**。这是因为在n趋于无穷大时，最高阶的项将发挥主导作用，其他项的影响都可以忽略。

#### 2.3.4  常见类型

设输入数据大小为n，常见的时间复杂度类型如图 2-9 所示（按照从低到高的顺序排列）。

O(1)<O($log n$)<O(n)<O($nlog n$)<O($n^2$)<O($2^n$)<O(n!)

常数阶<对数阶<线性阶<线性对数阶<平方阶<指数阶<阶乘阶

![常见的时间复杂度类型](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250715200425838.png)

图 2-9  常见的时间复杂度类型

1. 常数阶O(1)

   常数阶的操作数量与输入数据大小 无关，即不随着 的变化而变化。

2.  线性阶O(n)

    线性阶的操作数量相对于输入数据大小 以线性级别增长。线性阶通常出现在单层循环中：

3.  平方阶O($n^2$)

    平方阶的操作数量相对于输入数据大小n以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环的时间复杂度都为O(n)，因此总体的时间复杂度为O($n^2$)

4.  指数阶O($2^n$)

    生物学的“细胞分裂”是指数阶增长的典型例子：初始状态为1个细胞，分裂一轮后变为2个，分裂两轮后变为4个，以此类推，分裂n轮后有$2^n$个细胞。

    图 2-11 和以下代码模拟了细胞分裂的过程，时间复杂度为O($2^n$) 。请注意，输入n表示分裂轮数，返回值 `count` 表示总分裂次数。

    ```python
    def exponential(n: int) -> int:
        """指数阶（循环实现）"""
        count = 0
        base = 1
        # 细胞每轮一分为二，形成数列 1, 2, 4, 8, ..., 2^(n-1)
        for _ in range(n):
            for _ in range(base):
                count += 1
            base *= 2
        # count = 1 + 2 + 4 + 8 + .. + 2^(n-1) = 2^n - 1
        return count
    ```

    [![指数阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_exponential.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_exponential.png)

    图 2-11  指数阶的时间复杂度

    在实际算法中，指数阶常出现于递归函数中。例如在以下代码中，其递归地一分为二，经过 次分裂后停止：

    ```python
    def exp_recur(n: int) -> int:
        """指数阶（递归实现）"""
        if n == 1:
            return 1
        return exp_recur(n - 1) + exp_recur(n - 1) + 1
    ```

    指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。

5.  对数阶O($log n$)

    与指数阶相反，对数阶反映了“每轮缩减到一半”的情况。设输入数据大小为n，由于每轮缩减到一半，因此循环次数是$\log_2 n$，即$2^n$的反函数。

    图 2-12 和以下代码模拟了“每轮缩减到一半”的过程，时间复杂度为O($log_2 n$)，简记为O($log_ n$)：

    ```python
    def logarithmic(n: int) -> int:
        """对数阶（循环实现）"""
        count = 0
        while n > 1:
            n = n / 2
            count += 1
        return count
    ```

    ![对数阶的时间复杂度](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714165738224.png)

    图 2-12  对数阶的时间复杂度

    与指数阶类似，对数阶也常出现于递归函数中。以下代码形成了一棵高度为$log_2 n$的递归树

    ```python
    def log_recur(n: int) -> int:
        """对数阶（递归实现）"""
        if n <= 1:
            return 0
        return log_recur(n / 2) + 1
    ```

    对数阶常出现于基于分治策略的算法中，体现了“一分为多”和“化繁为简”的算法思想。它增长缓慢，是仅次于常数阶的理想的时间复杂度。

    ![image-20250714165946651](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714165946651.png)

6.  线性对数阶O($nlog n$)

    线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为O($log n$)和O(n)。

    ```python
    def linear_log_recur(n: int) -> int:
        """线性对数阶"""
        if n <= 1:
            return 1
        # 一分为二，子问题的规模减小一半
        count = linear_log_recur(n // 2) + linear_log_recur(n // 2)
        # 当前子问题包含 n 个操作
        for _ in range(n):
            count += 1
        return count
    ```

    图 2-13 展示了线性对数阶的生成方式。二叉树的每一层的操作总数都为n，树共有$log_2 n+1$层，因此时间复杂度为O($nlog n$)。

    [![线性对数阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_logarithmic_linear.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_logarithmic_linear.png)

    图 2-13  线性对数阶的时间复杂度

    主流排序算法的时间复杂度通常为O($nlog n$)，例如快速排序、归并排序、堆排序等。

7.  阶乘阶O(n!)

    阶乘阶对应数学上的“全排列”问题。给定n个互不重复的元素，求其所有可能的排列方案，方案数量为：
    $$
    n!=n*(n-1)*(n-2)*···*2*1
    $$
    阶乘通常使用递归实现。如图 2-14 和以下代码所示，第一层分裂出n个，第二层分裂出n-1个，以此类推，直至第n层时停止分裂

    ```python
    def factorial_recur(n: int) -> int:
        """阶乘阶（递归实现）"""
        if n == 0:
            return 1
        count = 0
        # 从 1 个分裂出 n 个
        for _ in range(n):
            count += factorial_recur(n - 1)
        return count
    ```

    [![阶乘阶的时间复杂度](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_factorial.png)](https://www.hello-algo.com/chapter_computational_complexity/time_complexity.assets/time_complexity_factorial.png)

    图 2-14  阶乘阶的时间复杂度

    请注意，因为当$n>=4$时恒有$n!>2^n$ ，所以阶乘阶比指数阶增长得更快，在n较大时也是不可接受的。

#### 2.3.5  最差、最佳、平均时间复杂度

“最差时间复杂度”对应函数渐近上界，使用大O记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用Ω记号表示：

值得说明的是，我们在实际中很少使用最佳时间复杂度，因为通常只有在很小概率下才能达到，可能会带来一定的误导性。**而最差时间复杂度更为实用，因为它给出了一个效率安全值**，让我们可以放心地使用算法。

从上述示例可以看出，最差时间复杂度和最佳时间复杂度只出现于“特殊的数据分布”，这些情况的出现概率可能很小，并不能真实地反映算法运行效率。相比之下，**平均时间复杂度可以体现算法在随机输入数据下的运行效率**，用Θ记号来表示。

对于部分算法，我们可以简单地推算出随机数据分布下的平均情况。比如上述示例，由于输入数组是被打乱的，因此元素1出现在任意索引的概率都是相等的，那么算法的平均循环次数就是数组长度的一半n/2，平均时间复杂度为Θ(n/2)=Θ(n) 。

但对于较为复杂的算法，计算平均时间复杂度往往比较困难，因为很难分析出在数据分布下的整体数学期望。在这种情况下，我们通常使用最差时间复杂度作为算法效率的评判标准。

![为什么很少看到Θ符号？](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250714171708044.png)

### 2.4  空间复杂度

空间复杂度（space complexity）用于衡量算法占用内存空间随着数据量变大时的增长趋势。这个概念与时间复杂度非常类似，只需将“运行时间”替换为“占用内存空间”。

#### 2.4.1  算法相关空间

算法在运行过程中使用的内存空间主要包括以下几种。

- **输入空间**：用于存储算法的输入数据。
- **暂存空间**：用于存储算法在运行过程中的变量、对象、函数上下文等数据。
- **输出空间**：用于存储算法的输出数据。

一般情况下，空间复杂度的统计范围是“暂存空间”加上“输出空间”。

暂存空间可以进一步划分为三个部分。

- **暂存数据**：用于保存算法运行过程中的各种常量、变量、对象等。
- **栈帧空间**：用于保存调用函数的上下文数据。系统在每次调用函数时都会在栈顶部创建一个栈帧，函数返回后，栈帧空间会被释放。
- **指令空间**：用于保存编译后的程序指令，在实际统计中通常忽略不计。

在分析一段程序的空间复杂度时，**我们通常统计暂存数据、栈帧空间和输出数据三部分**，如图 2-15 所示。

[![算法使用的相关空间](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_types.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_types.png)

图 2-15  算法使用的相关空间

#### 2.4.2  推算方法

空间复杂度的推算方法与时间复杂度大致相同，只需将统计对象从“操作数量”转为“使用空间大小”。

而与时间复杂度不同的是，**我们通常只关注最差空间复杂度**。这是因为内存空间是一项硬性要求，我们必须确保在所有输入数据下都有足够的内存空间预留。

观察以下代码，最差空间复杂度中的“最差”有两层含义。

1. **以最差输入数据为准**：当n<10时，空间复杂度为O(1)；但当n>10时，初始化的数组 `nums` 占用O(n)空间，因此最差空间复杂度为O(n)。
2. **以算法运行中的峰值内存为准**：例如，程序在执行最后一行之前，占用O(1)空间；当初始化数组 `nums` 时，程序占用O(n)空间，因此最差空间复杂度为O(n)。

```python
def algorithm(n: int):
    a = 0               # O(1)
    b = [0] * 10000     # O(1)
    if n > 10:
        nums = [0] * n  # O(n)
```

**在递归函数中，需要注意统计栈帧空间**。观察以下代码：

```python
def function() -> int:
    # 执行某些操作
    return 0

def loop(n: int):
    """循环的空间复杂度为 O(1)"""
    for _ in range(n):
        function()

def recur(n: int):
    """递归的空间复杂度为 O(n)"""
    if n == 1:
        return
    return recur(n - 1)
```

函数 `loop()` 和 `recur()` 的时间复杂度都为O(n)，但空间复杂度不同。

- 函数 `loop()` 在循环中调用了n次 `function()` ，每轮中的 `function()` 都返回并释放了栈帧空间，因此空间复杂度仍为O(1)。
- 递归函数 `recur()` 在运行过程中会同时存在n个未返回的 `recur()` ，从而占用O(n)的栈帧空间。

#### 2.4.3  常见类型

设输入数据大小为n，图 2-16 展示了常见的空间复杂度类型（从低到高排列）。

O(1)<O($log_2 n$)<O(n)<O($n^2$)<O($2^n$)

常数阶 < 对数阶 < 线性阶 < 平方阶 < 指数阶

![常见的空间复杂度类型](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_common_types.png)

图 2-16  常见的空间复杂度类型

1. 常数阶O(1)

   常数阶常见于数量与输入数据大小n无关的常量、变量、对象。

   需要注意的是，在循环中初始化变量或调用函数而占用的内存，在进入下一循环后就会被释放，因此不会累积占用空间，空间复杂度仍为O(1)： 

   ```python
   def function() -> int:
       """函数"""
       # 执行某些操作
       return 0
   
   def constant(n: int):
       """常数阶"""
       # 常量、变量、对象占用 O(1) 空间
       a = 0
       nums = [0] * 10000
       node = ListNode(0)
       # 循环中的变量占用 O(1) 空间
       for _ in range(n):
           c = 0
       # 循环中的函数占用 O(1) 空间
       for _ in range(n):
           function()
   ```

2. 线性阶O(n)

   线性阶常见于元素数量与n成正比的数组、链表、栈、队列等：

   ```python
   def linear(n: int):
       """线性阶"""
       # 长度为 n 的列表占用 O(n) 空间
       nums = [0] * n
       # 长度为 n 的哈希表占用 O(n) 空间
       hmap = dict[int, str]()
       for i in range(n):
           hmap[i] = str(i)
   ```

   如图 2-17 所示，此函数的递归深度为n，即同时存在n个未返回的 `linear_recur()` 函数，使用O(n)大小的栈帧空间：

   ```python
   def linear_recur(n: int):
       """线性阶（递归实现）"""
       print("递归 n =", n)
       if n == 1:
           return
       linear_recur(n - 1)
   ```

   ![递归函数产生的线性阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_linear.png)

   图 2-17  递归函数产生的线性阶空间复杂度

3. 平方阶O($n^2$)

   ```python
   def quadratic(n: int):
       """平方阶"""
       # 二维列表占用 O(n^2) 空间
       num_matrix = [[0] * n for _ in range(n)]
   ```

   如图 2-18 所示，该函数的递归深度为n，在每个递归函数中都初始化了一个数组，长度分别为n、n-1、...、2、1 ，平均长度为n/2，因此总体占用O($n^2$)空间：

   ```python
   def quadratic_recur(n: int) -> int:
       """平方阶（递归实现）"""
       if n <= 0:
           return 0
       # 数组 nums 长度为 n, n-1, ..., 2, 1
       nums = [0] * n
       return quadratic_recur(n - 1)
   ```

   [![递归函数产生的平方阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_quadratic.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_recursive_quadratic.png)

   图 2-18  递归函数产生的平方阶空间复杂度

4. 指数阶O($2^n$)

   指数阶常见于二叉树。观察图 2-19 ，层数为n的“满二叉树”的节点数量为$2^n-1$，占用O($2^n$)空间：

   ```python
   def build_tree(n: int) -> TreeNode | None:
       """指数阶（建立满二叉树）"""
       if n == 0:
           return None
       root = TreeNode(0)
       root.left = build_tree(n - 1)
       root.right = build_tree(n - 1)
       return root
   ```

   [![满二叉树产生的指数阶空间复杂度](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_exponential.png)](https://www.hello-algo.com/chapter_computational_complexity/space_complexity.assets/space_complexity_exponential.png)

   图 2-19  满二叉树产生的指数阶空间复杂度

5. 对数阶O($log n$)

   对数阶常见于分治算法。例如归并排序，输入长度为n的数组，每轮递归将数组从中点处划分为两半，形成高度为$log n$的递归树，使用O($log n$)栈帧空间。

   再例如将数字转化为字符串，输入一个正整数n，它的位数为$⌊log_{10}n⌋+1$，即对应字符串长度为$⌊log_{10}n⌋+1$，因此空间复杂度为 O($log_{10}n+1$)=O($log n$)。

#### 2.4.4  权衡时间与空间

理想情况下，我们希望算法的时间复杂度和空间复杂度都能达到最优。然而在实际情况中，同时优化时间复杂度和空间复杂度通常非常困难。

**降低时间复杂度通常需要以提升空间复杂度为代价，反之亦然**。我们将牺牲内存空间来提升算法运行速度的思路称为“以空间换时间”；反之，则称为“以时间换空间”。

选择哪种思路取决于我们更看重哪个方面。在大多数情况下，时间比空间更宝贵，因此“以空间换时间”通常是更常用的策略。当然，在数据量很大的情况下，控制空间复杂度也非常重要。

### 2.5  Q&A

**Q**：尾递归的空间复杂度是O(1)吗？

理论上，尾递归函数的空间复杂度可以优化至O(1)。不过绝大多数编程语言（例如 Java、Python、C++、Go、C# 等）不支持自动优化尾递归，因此通常认为空间复杂度是O(n)。

**Q**：函数和方法这两个术语的区别是什么？

函数（function）可以被独立执行，所有参数都以显式传递。方法（method）与一个对象关联，被隐式传递给调用它的对象，能够对类的实例中包含的数据进行操作。

下面以几种常见的编程语言为例来说明。

- C 语言是过程式编程语言，没有面向对象的概念，所以只有函数。但我们可以通过创建结构体（struct）来模拟面向对象编程，与结构体相关联的函数就相当于其他编程语言中的方法。
- Java 和 C# 是面向对象的编程语言，代码块（方法）通常作为某个类的一部分。静态方法的行为类似于函数，因为它被绑定在类上，不能访问特定的实例变量。
- C++ 和 Python 既支持过程式编程（函数），也支持面向对象编程（方法）。

**Q**：图解“常见的空间复杂度类型”反映的是否是占用空间的绝对大小？

不是，该图展示的是空间复杂度，其反映的是增长趋势，而不是占用空间的绝对大小。

假设取n=8，你可能会发现每条曲线的值与函数对应不上。这是因为每条曲线都包含一个常数项，用于将取值范围压缩到一个视觉舒适的范围内。

在实际中，因为我们通常不知道每个方法的“常数项”复杂度是多少，所以一般无法仅凭复杂度来选择n=8之下的最优解法。但对于n=8^5就很好选了，这时增长趋势已经占主导了。

## 第 3 章  数据结构

![数据结构](https://www.hello-algo.com/assets/covers/chapter_data_structure.jpg)

### 3.1  数据结构分类

常见的数据结构包括数组、链表、栈、队列、哈希表、树、堆、图，它们可以从“逻辑结构”和“物理结构”两个维度进行分类。

#### 3.1.1  逻辑结构：线性与非线性

**逻辑结构揭示了数据元素之间的逻辑关系**。在数组和链表中，数据按照一定顺序排列，体现了数据之间的线性关系；而在树中，数据从顶部向下按层次排列，表现出“祖先”与“后代”之间的派生关系；图则由节点和边构成，反映了复杂的网络关系。

如图 3-1 所示，逻辑结构可分为“线性”和“非线性”两大类。线性结构比较直观，指数据在逻辑关系上呈线性排列；非线性结构则相反，呈非线性排列。

- **线性数据结构**：数组、链表、栈、队列、哈希表，元素之间是一对一的顺序关系。
- **非线性数据结构**：树、堆、图、哈希表。

![线性数据结构与非线性数据结构](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_logic_structure.png)

图 3-1  线性数据结构与非线性数据结构

#### 3.1.2  物理结构：连续与分散

**当算法程序运行时，正在处理的数据主要存储在内存中**。图 3-2 展示了一个计算机内存条，其中每个黑色方块都包含一块内存空间。我们可以将内存想象成一个巨大的 Excel 表格，其中每个单元格都可以存储一定大小的数据。

**系统通过内存地址来访问目标位置的数据**。如图 3-2 所示，计算机根据特定规则为表格中的每个单元格分配编号，确保每个内存空间都有唯一的内存地址。有了这些地址，程序便可以访问内存中的数据。

[![内存条、内存空间、内存地址](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/computer_memory_location.png)](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/computer_memory_location.png)

图 3-2  内存条、内存空间、内存地址

> 值得说明的是，将内存比作 Excel 表格是一个简化的类比，实际内存的工作机制比较复杂，涉及地址空间、内存管理、缓存机制、虚拟内存和物理内存等概念。

内存是所有程序的共享资源，当某块内存被某个程序占用时，则通常无法被其他程序同时使用了。**因此在数据结构与算法的设计中，内存资源是一个重要的考虑因素**。比如，算法所占用的内存峰值不应超过系统剩余空闲内存；如果缺少连续大块的内存空间，那么所选用的数据结构必须能够存储在分散的内存空间内。

如图 3-3 所示，**物理结构反映了数据在计算机内存中的存储方式**，可分为连续空间存储（数组）和分散空间存储（链表）。物理结构从底层决定了数据的访问、更新、增删等操作方法，两种物理结构在时间效率和空间效率方面呈现出互补的特点。

[![连续空间存储与分散空间存储](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_phisical_structure.png)](https://www.hello-algo.com/chapter_data_structure/classification_of_data_structure.assets/classification_phisical_structure.png)

图 3-3  连续空间存储与分散空间存储

值得说明的是，**所有数据结构都是基于数组、链表或二者的组合实现的**。例如，栈和队列既可以使用数组实现，也可以使用链表实现；而哈希表的实现可能同时包含数组和链表。

- **基于数组可实现**：栈、队列、哈希表、树、堆、图、矩阵、张量（维度 的数组）等。
- **基于链表可实现**：栈、队列、哈希表、树、堆、图等。

链表在初始化后，仍可以在程序运行过程中对其长度进行调整，因此也称“动态数据结构”。数组在初始化后长度不可变，因此也称“静态数据结构”。值得注意的是，数组可通过重新分配内存实现长度变化，从而具备一定的“动态性”。

#### Comment

假设我们初始化一个很大的数组。在虚拟内存中，数组的内存空间是连续的。这样我们才能通过首元素地址加偏移量的方式来访问数组中的任何元素。

然而，在物理内存中，数组可能并不连续。虚拟内存到物理内存的映射涉及到分页（paging）技术。操作系统通过分页系统，将虚拟内存和物理内存都划分为大小相等的页。每个虚拟页都可以单独映射到物理内存中的任意一页。所以，一个大的数组（占据多个虚拟内存页）在物理内存中可能是分散的，每个虚拟页在物理内存中的位置可能不连续。

值得强调的是，虽然物理内存中的连续性可能会对性能有影响，但在实际应用中，这通常并不是主要的性能瓶颈。现代的计算机系统已经采用了许多优化技术，例如缓存、预取等，以尽可能减小这种影响。

### 3.2  基本数据类型

当谈及计算机中的数据时，我们会想到文本、图片、视频、语音、3D 模型等各种形式。尽管这些数据的组织形式各异，但它们都由各种基本数据类型构成。

**基本数据类型是 CPU 可以直接进行运算的类型**，在算法中直接被使用，主要包括以下几种。

- 整数类型 `byte`、`short`、`int`、`long` 。
- 浮点数类型 `float`、`double` ，用于表示小数。
- 字符类型 `char` ，用于表示各种语言的字母、标点符号甚至表情符号等。
- 布尔类型 `bool` ，用于表示“是”与“否”判断。

**基本数据类型以二进制的形式存储在计算机中**。一个二进制位即为1比特。在绝大多数现代操作系统中，1字节（byte）由8比特（bit）组成。

基本数据类型的取值范围取决于其占用的空间大小。下面以 Java 为例。

- 整数类型 `byte` 占用1字节 =8比特 ，可以表示$2^8$个数字。
- 整数类型 `int` 占用4字节 =32比特 ，可以表示$2^{32}$个数字。

表 3-1 列举了 Java 中各种基本数据类型的占用空间、取值范围和默认值。此表格无须死记硬背，大致理解即可，需要时可以通过查表来回忆。

表 3-1  基本数据类型的占用空间和取值范围

![基本数据类型的占用空间和取值范围](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717184144152.png)

请注意，表 3-1 针对的是 Java 的基本数据类型的情况。每种编程语言都有各自的数据类型定义，它们的占用空间、取值范围和默认值可能会有所不同。

- 在 Python 中，整数类型 `int` 可以是任意大小，只受限于可用内存；浮点数 `float` 是双精度 64 位；没有 `char` 类型，单个字符实际上是长度为 1 的字符串 `str` 。
- C 和 C++ 未明确规定基本数据类型的大小，而因实现和平台各异。表 3-1 遵循 LP64 [数据模型](https://en.cppreference.com/w/cpp/language/types#Properties)，其用于包括 Linux 和 macOS 在内的 Unix 64 位操作系统。
- 字符 `char` 的大小在 C 和 C++ 中为 1 字节，在大多数编程语言中取决于特定的字符编码方法，详见“字符编码”章节。
- 即使表示布尔量仅需 1 位（0或1），它在内存中通常也存储为 1 字节。这是因为现代计算机 CPU 通常将 1 字节作为最小寻址内存单元。

那么，基本数据类型与数据结构之间有什么联系呢？我们知道，数据结构是在计算机中组织与存储数据的方式。这句话的主语是“结构”而非“数据”。

如果想表示“一排数字”，我们自然会想到使用数组。这是因为数组的线性结构可以表示数字的相邻关系和顺序关系，但至于存储的内容是整数 `int`、小数 `float` 还是字符 `char` ，则与“数据结构”无关。

换句话说，**基本数据类型提供了数据的“内容类型”，而数据结构提供了数据的“组织方式”**。例如以下代码，我们用相同的数据结构（数组）来存储与表示不同的基本数据类型，包括 `int`、`float`、`char`、`bool` 等。

```python
# 使用多种基本数据类型来初始化数组
numbers: list[int] = [0] * 5
decimals: list[float] = [0.0] * 5
# Python 的字符实际上是长度为 1 的字符串
characters: list[str] = ['0'] * 5
bools: list[bool] = [False] * 5
# Python 的列表可以自由存储各种基本数据类型和对象引用
data = [0, 0.0, 'a', False, ListNode(0)]
```

### 3.3  数字编码 *

#### 3.3.1  原码、反码和补码

在上一节的表格中我们发现，所有整数类型能够表示的负数都比正数多一个，例如 `byte` 的取值范围是[-128,127]。这个现象比较反直觉，它的内在原因涉及原码、反码、补码的相关知识。

首先需要指出，**数字是以“补码”的形式存储在计算机中的**。在分析这样做的原因之前，首先给出三者的定义。

- **原码**：我们将数字的二进制表示的最高位视为符号位，其中0表示正数，1表示负数，其余位表示数字的值。
- **反码**：正数的反码与其原码相同，负数的反码是对其原码除符号位外的所有位取反。
- **补码**：正数的补码与其原码相同，负数的补码是在其反码的基础上加1。

图 3-4 展示了原码、反码和补码之间的转换方法。

负数原码转补码，从右往左找到第一个1，包含1在内的往右都不变，左边全部取反（符号位不变）

![原码、反码与补码之间的相互转换](https://www.hello-algo.com/chapter_data_structure/number_encoding.assets/1s_2s_complement.png)

图 3-4  原码、反码与补码之间的相互转换

原码（sign-magnitude）虽然最直观，但存在一些局限性。一方面，**负数的原码不能直接用于运算**。例如在原码下计算1+(-2)，得到的结果是-3，这显然是不对的。

1+(-2)

->0000  0001+1000  0010

=1000 0011

->-3

为了解决此问题，计算机引入了反码（1's complement）。如果我们先将原码转换为反码，并在反码下计算1+(-2)，最后将结果从反码转换回原码，则可得到正确结果-1。

1+(-2)

->0000  0001(原码)+1000  0010(原码)

=0000  0001(反码)+1111  1101(反码)

=1111  1110(反码)

=1000  0001(原码)

->-1

另一方面，**数字零的原码有-0和+0两种表示方式**。这意味着数字零对应两个不同的二进制编码，这可能会带来歧义。比如在条件判断中，如果没有区分正零和负零，则可能会导致判断结果出错。而如果我们想处理正零和负零歧义，则需要引入额外的判断操作，这可能会降低计算机的运算效率。

+0->0000  0000

-0->1000  0000

与原码一样，反码也存在正负零歧义问题，因此计算机进一步引入了补码（2's complement）。我们先来观察一下负零的原码、反码、补码的转换过程：

-0->1000  0000(原码)

=1111  1111(反码)

=1  0000  0000(补码)

在负零的反码基础上加1会产生进位，但 `byte` 类型的长度只有 8 位，因此溢出到第 9 位的1会被舍弃。也就是说，**负零的补码为0000  0000，与正零的补码相同**。这意味着在补码表示中只存在一个零，正负零歧义从而得到解决。

还剩最后一个疑惑：`byte` 类型的取值范围是[-128,+127] ，多出来的一个负数-128是如何得到的呢？我们注意到，区间\[-127,+127]内的所有整数都有对应的原码、反码和补码，并且原码和补码之间可以互相转换。

然而，**补码1000  0000是一个例外，它并没有对应的原码**。根据转换方法，我们得到该补码的原码为0000  0000。这显然是矛盾的，因为该原码表示数字 ，它的补码应该是自身。计算机规定这个特殊的补码1000 0000代表-128。实际上，(-1)+(-127)在补码下的计算结果就是-128。

(-127)+(-1)

->1111  1111(原码)+1000  0001(原码)

=1000  0000(反码)+1111  1110(反码)

=1000  0001(补码)+1111  1111(补码)

=1000  0000(补码)

->-128

你可能已经发现了，上述所有计算都是加法运算。这暗示着一个重要事实：**计算机内部的硬件电路主要是基于加法运算设计的**。这是因为加法运算相对于其他运算（比如乘法、除法和减法）来说，硬件实现起来更简单，更容易进行并行化处理，运算速度更快。

请注意，这并不意味着计算机只能做加法。**通过将加法与一些基本逻辑运算结合，计算机能够实现各种其他的数学运算**。例如，计算减法a-b可以转换为a+(-b)计算加法 ；计算乘法和除法可以转换为计算多次加法或减法。

现在我们可以总结出计算机使用补码的原因：基于补码表示，计算机可以用同样的电路和操作来处理正数和负数的加法，不需要设计特殊的硬件电路来处理减法，并且无须特别处理正负零的歧义问题。这大大简化了硬件设计，提高了运算效率。

补码的设计非常精妙，因篇幅关系我们就先介绍到这里，建议有兴趣的读者进一步深入了解。

#### 3.3.2  浮点数编码

细心的你可能会发现：`int` 和 `float` 长度相同，都是 4 字节 ，但为什么 `float` 的取值范围远大于 `int` ？这非常反直觉，因为按理说 `float` 需要表示小数，取值范围应该变小才对。

实际上，**这是因为浮点数 `float` 采用了不同的表示方式**。记一个 32 比特长度的二进制数为：
$$
b_{31}b_{30}b_{29}...b_{2}b_{1}b_{0}
$$
据 IEEE 754 标准，32-bit 长度的 `float` 由以下三个部分构成。

- 符号位S：占 1 位 ，对应$b_{31}$。
- 指数位E：占 8 位 ，对应$b_{30}b_{29}...b_{23}$。
- 分数位N：占 23 位 ，对应$b_{22}b_{21}...b_{0}$ 。

二进制数 `float` 对应值的计算方法为：
$$
val=(-1)^{b_{31}}×2^{({{b_{30}b_{29}...b_{23})}_2-127}}×(1.b_{22}b_{21}...b_{0})_2
$$
转化到十进制下的计算公式为：
$$
val=(-1)^S×2^{E-127}×(1+N)
$$
其中各项的取值范围为：

![image-20250717200216151](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717200216151.png)

![IEEE 754 标准下的 float 的计算示例](https://www.hello-algo.com/chapter_data_structure/number_encoding.assets/ieee_754_float.png)

图 3-5  IEEE 754 标准下的 float 的计算示例

现在我们可以回答最初的问题：**`float` 的表示方式包含指数位，导致其取值范围远大于 `int`** 。根据以上计算，`float` 可表示的最大正数为$2^{254-127}×(2-2^{-23})≈3.4×10^{38}$，切换符号位便可得到最小负数。

**尽管浮点数 `float` 扩展了取值范围，但其副作用是牺牲了精度**。整数类型 `int` 将全部 32 比特用于表示数字，数字是均匀分布的；而由于指数位的存在，浮点数 `float` 的数值越大，相邻两个数字之间的差值就会趋向越大。

![image-20250717200740452](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717200740452.png)

#### Comment

![image-20250717203552149](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717203552149.png)

![image-20250717204002910](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717204002910.png)

- 原码：直观但减法复杂，零有冗余；
- 反码：实现减法转加法，但零仍冗余，需处理循环进位；
- 补码：彻底解决零的冗余和进位问题，实现了加减法运算的统一与高效，最终成为计算机中表示有符号整数的通用标准。

**进位循环处理**：反码加法时，若最高位产生进位，需将进位 “循环” 加到结果的最低位（称为 “循环进位”），增加了硬件运算的复杂度。例如 `3 + (-3)`：
`3` 反码 `00000011` + `-3` 反码 `11111100` = `11111111`（进位 1 被循环加到最低位后仍为 `11111111`，即 `-0`），逻辑不够简洁。

### 3.4  字符编码 *

在计算机中，所有数据都是以二进制数的形式存储的，字符 `char` 也不例外。为了表示字符，我们需要建立一套“字符集”，规定每个字符和二进制数之间的一一对应关系。有了字符集之后，计算机就可以通过查表完成二进制数到字符的转换。

#### 3.4.1  ASCII 字符集

ASCII 码是最早出现的字符集，其全称为 American Standard Code for Information Interchange（美国标准信息交换代码）。它使用 7 位二进制数（一个字节的低 7 位）表示一个字符，最多能够表示 128 个不同的字符。如图 3-6 所示，ASCII 码包括英文字母的大小写、数字 0 ~ 9、一些标点符号，以及一些控制字符（如换行符和制表符）。

![ASCII 码](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/ascii_table.png)

图 3-6  ASCII 码

然而，**ASCII 码仅能够表示英文**。随着计算机的全球化，诞生了一种能够表示更多语言的 EASCII 字符集。它在 ASCII 的 7 位基础上扩展到 8 位，能够表示 256 个不同的字符。

在世界范围内，陆续出现了一批适用于不同地区的 EASCII 字符集。这些字符集的前 128 个字符统一为 ASCII 码，后 128 个字符定义不同，以适应不同语言的需求。

#### 3.4.2  GBK 字符集

后来人们发现，**EASCII 码仍然无法满足许多语言的字符数量要求**。比如汉字有近十万个，光日常使用的就有几千个。中国国家标准总局于 1980 年发布了 GB2312 字符集，其收录了 6763 个汉字，基本满足了汉字的计算机处理需要。

然而，GB2312 无法处理部分罕见字和繁体字。GBK 字符集是在 GB2312 的基础上扩展得到的，它共收录了 21886 个汉字。在 GBK 的编码方案中，ASCII 字符使用一个字节表示，汉字使用两个字节表示。

#### 3.4.3  Unicode 字符集

随着计算机技术的蓬勃发展，字符集与编码标准百花齐放，而这带来了许多问题。一方面，这些字符集一般只定义了特定语言的字符，无法在多语言环境下正常工作。另一方面，同一种语言存在多种字符集标准，如果两台计算机使用的是不同的编码标准，则在信息传递时就会出现乱码。

那个时代的研究人员就在想：**如果推出一个足够完整的字符集，将世界范围内的所有语言和符号都收录其中，不就可以解决跨语言环境和乱码问题了吗**？在这种想法的驱动下，一个大而全的字符集 Unicode 应运而生。

Unicode 的中文名称为“统一码”，理论上能容纳 100 多万个字符。它致力于将全球范围内的字符纳入统一的字符集之中，提供一种通用的字符集来处理和显示各种语言文字，减少因为编码标准不同而产生的乱码问题。

自 1991 年发布以来，Unicode 不断扩充新的语言与字符。截至 2022 年 9 月，Unicode 已经包含 149186 个字符，包括各种语言的字符、符号甚至表情符号等。在庞大的 Unicode 字符集中，常用的字符占用 2 字节，有些生僻的字符占用 3 字节甚至 4 字节。

Unicode 是一种通用字符集，本质上是给每个字符分配一个编号（称为“码点”），**但它并没有规定在计算机中如何存储这些字符码点**。我们不禁会问：当多种长度的 Unicode 码点同时出现在一个文本中时，系统如何解析字符？例如给定一个长度为 2 字节的编码，系统如何确认它是一个 2 字节的字符还是两个 1 字节的字符？

对于以上问题，**一种直接的解决方案是将所有字符存储为等长的编码**。如图 3-7 所示，“Hello”中的每个字符占用 1 字节，“算法”中的每个字符占用 2 字节。我们可以通过高位填 0 将“Hello 算法”中的所有字符都编码为 2 字节长度。这样系统就可以每隔 2 字节解析一个字符，恢复这个短语的内容了。

![Unicode 编码示例](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/unicode_hello_algo.png)

图 3-7  Unicode 编码示例

然而 ASCII 码已经向我们证明，编码英文只需 1 字节。若采用上述方案，英文文本占用空间的大小将会是 ASCII 编码下的两倍，非常浪费内存空间。因此，我们需要一种更加高效的 Unicode 编码方法。

#### 3.4.4  UTF-8 编码

目前，UTF-8 已成为国际上使用最广泛的 Unicode 编码方法。**它是一种可变长度的编码**，使用 1 到 4 字节来表示一个字符，根据字符的复杂性而变。ASCII 字符只需 1 字节，拉丁字母和希腊字母需要 2 字节，常用的中文字符需要 3 字节，其他的一些生僻字符需要 4 字节。

UTF-8 的编码规则并不复杂，分为以下两种情况。

- 对于长度为 1 字节的字符，将最高位设置为0，其余 7 位设置为 Unicode 码点。值得注意的是，ASCII 字符在 Unicode 字符集中占据了前 128 个码点。也就是说，**UTF-8 编码可以向下兼容 ASCII 码**。这意味着我们可以使用 UTF-8 来解析年代久远的 ASCII 码文本。
- 对于长度为 字节的字符（其中n>1），将首个字节的高n位都设置为1，第n+1位设置为0；从第二个字节开始，将每个字节的高 2 位都设置为10；其余所有位用于填充字符的 Unicode 码点。

图 3-8 展示了“Hello算法”对应的 UTF-8 编码。观察发现，由于最高n位都设置为1，因此系统可以通过读取最高位1的个数来解析出字符的长度为n。

但为什么要将其余所有字节的高 2 位都设置为10呢？实际上，这个10能够起到校验符的作用。假设系统从一个错误的字节开始解析文本，字节头部的10能够帮助系统快速判断出异常。

之所以将10当作校验符，是因为在 UTF-8 编码规则下，不可能有字符的最高两位是10。这个结论可以用反证法来证明：假设一个字符的最高两位是10，说明该字符的长度为1，对应 ASCII 码。而 ASCII 码的最高位应该是0，与假设矛盾。

![UTF-8 编码示例](https://www.hello-algo.com/chapter_data_structure/character_encoding.assets/utf-8_hello_algo.png)

图 3-8  UTF-8 编码示例

除了 UTF-8 之外，常见的编码方式还包括以下两种。

- **UTF-16 编码**：使用 2 或 4 字节来表示一个字符。所有的 ASCII 字符和常用的非英文字符，都用 2 字节表示；少数字符需要用到 4 字节表示。对于 2 字节的字符，UTF-16 编码与 Unicode 码点相等。
- **UTF-32 编码**：每个字符都使用 4 字节。这意味着 UTF-32 比 UTF-8 和 UTF-16 更占用空间，特别是对于 ASCII 字符占比较高的文本。

从存储空间占用的角度看，使用 UTF-8 表示英文字符非常高效，因为它仅需 1 字节；使用 UTF-16 编码某些非英文字符（例如中文）会更加高效，因为它仅需 2 字节，而 UTF-8 可能需要 3 字节。

从兼容性的角度看，UTF-8 的通用性最佳，许多工具和库优先支持 UTF-8 。

#### 3.4.5  编程语言的字符编码

对于以往的大多数编程语言，程序运行中的字符串都采用 UTF-16 或 UTF-32 这类等长编码。在等长编码下，我们可以将字符串看作数组来处理，这种做法具有以下优点。

- **随机访问**：UTF-16 编码的字符串可以很容易地进行随机访问。UTF-8 是一种变长编码，要想找到第i个字符，我们需要从字符串的开始处遍历到第i个字符，这需要O(n)的时间。
- **字符计数**：与随机访问类似，计算 UTF-16 编码的字符串的长度也是O(1)的操作。但是，计算 UTF-8 编码的字符串的长度需要遍历整个字符串。
- **字符串操作**：在 UTF-16 编码的字符串上，很多字符串操作（如分割、连接、插入、删除等）更容易进行。在 UTF-8 编码的字符串上，进行这些操作通常需要额外的计算，以确保不会产生无效的 UTF-8 编码。

实际上，编程语言的字符编码方案设计是一个很有趣的话题，涉及许多因素。

- Java 的 `String` 类型使用 UTF-16 编码，每个字符占用 2 字节。这是因为 Java 语言设计之初，人们认为 16 位足以表示所有可能的字符。然而，这是一个不正确的判断。后来 Unicode 规范扩展到了超过 16 位，所以 Java 中的字符现在可能由一对 16 位的值（称为“代理对”）表示。
- JavaScript 和 TypeScript 的字符串使用 UTF-16 编码的原因与 Java 类似。当 1995 年 Netscape 公司首次推出 JavaScript 语言时，Unicode 还处于发展早期，那时候使用 16 位的编码就足以表示所有的 Unicode 字符了。
- C# 使用 UTF-16 编码，主要是因为 .NET 平台是由 Microsoft 设计的，而 Microsoft 的很多技术（包括 Windows 操作系统）都广泛使用 UTF-16 编码。

由于以上编程语言对字符数量的低估，它们不得不采取“代理对”的方式来表示超过 16 位长度的 Unicode 字符。这是一个不得已为之的无奈之举。一方面，包含代理对的字符串中，一个字符可能占用 2 字节或 4 字节，从而丧失了等长编码的优势。另一方面，处理代理对需要额外增加代码，这提高了编程的复杂性和调试难度。

出于以上原因，部分编程语言提出了一些不同的编码方案。

- Python 中的 `str` 使用 Unicode 编码，并采用一种灵活的字符串表示，存储的字符长度取决于字符串中最大的 Unicode 码点。若字符串中全部是 ASCII 字符，则每个字符占用 1 字节；如果有字符超出了 ASCII 范围，但全部在基本多语言平面（BMP）内，则每个字符占用 2 字节；如果有超出 BMP 的字符，则每个字符占用 4 字节。
- Go 语言的 `string` 类型在内部使用 UTF-8 编码。Go 语言还提供了 `rune` 类型，它用于表示单个 Unicode 码点。
- Rust 语言的 `str` 和 `String` 类型在内部使用 UTF-8 编码。Rust 也提供了 `char` 类型，用于表示单个 Unicode 码点。

需要注意的是，以上讨论的都是字符串在编程语言中的存储方式，**这和字符串如何在文件中存储或在网络中传输是不同的问题**。在文件存储或网络传输中，我们通常会将字符串编码为 UTF-8 格式，以达到最优的兼容性和空间效率。

#### Comment

Python 中的 `str` 字符串直接用 Unicode 表示（请注意区分：读写文件默认为 UTF-8 编码）。CPython 为 str 对象使用了一种灵活的存储策略，字符长度取决于字符串中最大的字符。观察以下测试：

```python
import sys

eng1 = "a"
eng2 = "ab"
eng3 = "abc"

chn1 = "哈"
chn2 = "哈啰"
chn2_eng1 = "哈啰a"

bmp1 = "𨊻"
bmp2 = "𨊻𨋾"
bmp2_eng1 = "𨊻𨋾a"

print("\n英文：") # 英文长度为 1
print(eng1 + ": ", sys.getsizeof(eng1))
print(eng2 + ": ", sys.getsizeof(eng2))
print(eng3 + ": ", sys.getsizeof(eng3))

print("\n中文:")
print(chn1 + ": ", sys.getsizeof(chn1))
print(chn2 + ": ", sys.getsizeof(chn2))
print(chn2_eng1 + ": ", sys.getsizeof(chn2_eng1))

print("\n补充平面:")
print(bmp1 + ": ", sys.getsizeof(bmp1))
print(bmp2 + ": ", sys.getsizeof(bmp2))
print(bmp2_eng1 + ": ", sys.getsizeof(bmp2_eng1))
```

可以得到以下结论：

1. 纯英文字符串的字符长度为 1 ；
2. 中文字符串下，中文和英文长度都为 2 ；
3. 补充平面字符下，英文字符长度为 4 ；

```python
英文：
a:  50
ab:  51
abc:  52

中文:
哈:  76
哈啰:  78
哈啰a:  80

超平面:
𨊻:  80
𨊻𨋾:  84
𨊻𨋾a:  88
```

![image-20250717214907640](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250717214907640.png)

### 3.5  小结

####  重点回顾

- 数据结构可以从逻辑结构和物理结构两个角度进行分类。逻辑结构描述了数据元素之间的逻辑关系，而物理结构描述了数据在计算机内存中的存储方式。
- 常见的逻辑结构包括线性、树状和网状等。通常我们根据逻辑结构将数据结构分为线性（数组、链表、栈、队列）和非线性（树、图、堆）两种。哈希表的实现可能同时包含线性数据结构和非线性数据结构。
- 当程序运行时，数据被存储在计算机内存中。每个内存空间都拥有对应的内存地址，程序通过这些内存地址访问数据。
- 物理结构主要分为连续空间存储（数组）和分散空间存储（链表）。所有数据结构都是由数组、链表或两者的组合实现的。
- 计算机中的基本数据类型包括整数 `byte`、`short`、`int`、`long` ，浮点数 `float`、`double` ，字符 `char` 和布尔 `bool` 。它们的取值范围取决于占用空间大小和表示方式。
- 原码、反码和补码是在计算机中编码数字的三种方法，它们之间可以相互转换。整数的原码的最高位是符号位，其余位是数字的值。
- 整数在计算机中是以补码的形式存储的。在补码表示下，计算机可以对正数和负数的加法一视同仁，不需要为减法操作单独设计特殊的硬件电路，并且不存在正负零歧义的问题。
- 浮点数的编码由 1 位符号位、8 位指数位和 23 位分数位构成。由于存在指数位，因此浮点数的取值范围远大于整数，代价是牺牲了精度。
- ASCII 码是最早出现的英文字符集，长度为 1 字节，共收录 127 个字符。GBK 字符集是常用的中文字符集，共收录两万多个汉字。Unicode 致力于提供一个完整的字符集标准，收录世界上各种语言的字符，从而解决由于字符编码方法不一致而导致的乱码问题。
- UTF-8 是最受欢迎的 Unicode 编码方法，通用性非常好。它是一种变长的编码方法，具有很好的扩展性，有效提升了存储空间的使用效率。UTF-16 和 UTF-32 是等长的编码方法。在编码中文时，UTF-16 占用的空间比 UTF-8 更小。Java 和 C# 等编程语言默认使用 UTF-16 编码。

#### Q & A

**Q**：为什么哈希表同时包含线性数据结构和非线性数据结构？

哈希表底层是数组，而为了解决哈希冲突，我们可能会使用“链式地址”（后续“哈希冲突”章节会讲）：数组中每个桶指向一个链表，当链表长度超过一定阈值时，又可能被转化为树（通常为红黑树）。

从存储的角度来看，哈希表的底层是数组，其中每一个桶槽位可能包含一个值，也可能包含一个链表或一棵树。因此，哈希表可能同时包含线性数据结构（数组、链表）和非线性数据结构（树）。

**Q**：`char` 类型的长度是 1 字节吗？

`char` 类型的长度由编程语言采用的编码方法决定。例如，Java、JavaScript、TypeScript、C# 都采用 UTF-16 编码（保存 Unicode 码点），因此 `char` 类型的长度为 2 字节。

**Q**：基于数组实现的数据结构也称“静态数据结构” 是否有歧义？栈也可以进行出栈和入栈等操作，这些操作都是“动态”的。

栈确实可以实现动态的数据操作，但数据结构仍然是“静态”（长度不可变）的。尽管基于数组的数据结构可以动态地添加或删除元素，但它们的容量是固定的。如果数据量超出了预分配的大小，就需要创建一个新的更大的数组，并将旧数组的内容复制到新数组中。

**Q**：在构建栈（队列）的时候，未指定它的大小，为什么它们是“静态数据结构”呢？

在高级编程语言中，我们无须人工指定栈（队列）的初始容量，这个工作由类内部自动完成。例如，Java 的 `ArrayList` 的初始容量通常为 10。另外，扩容操作也是自动实现的。详见后续的“列表”章节。

## 第 4 章  数组与链表

### 4.1  数组

数组（array）是一种线性数据结构，其将相同类型的元素存储在连续的内存空间(虚拟内存)中。我们将元素在数组中的位置称为该元素的索引（index）。图 4-1 展示了数组的主要概念和存储方式。

![数组定义与存储方式](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_definition.png)

图 4-1  数组定义与存储方式

#### 4.1.1  数组常用操作

1. 初始化数组

   我们可以根据需求选用数组的两种初始化方式：无初始值、给定初始值。在未指定初始值的情况下，大多数编程语言会将数组元素初始化为 ：

   ```python
   # 初始化数组
   arr: list[int] = [0] * 5  # [ 0, 0, 0, 0, 0 ]
   nums: list[int] = [1, 3, 2, 5, 4]
   ```

2. 访问元素

   数组元素被存储在连续的内存空间中，这意味着计算数组元素的内存地址非常容易。给定数组内存地址（首元素内存地址）和某个元素的索引，我们可以使用图 4-2 所示的公式计算得到该元素的内存地址，从而直接访问该元素。

   ![数组元素的内存地址计算](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_memory_location_calculation.png)

   图 4-2  数组元素的内存地址计算

   观察图 4-2 ，我们发现数组首个元素的索引为0，这似乎有些反直觉，因为从1开始计数会更自然。但从地址计算公式的角度看，**索引本质上是内存地址的偏移量**。首个元素的地址偏移量是0，因此它的索引为0是合理的。

   在数组中访问元素非常高效，我们可以在O(1)时间内随机访问数组中的任意一个元素。

   ```python
   def random_access(nums: list[int]) -> int:
       """随机访问元素"""
       # 在区间 [0, len(nums)-1] 中随机抽取一个数字
       random_index = random.randint(0, len(nums) - 1)
       # 获取并返回随机元素
       random_num = nums[random_index]
       return random_num
   ```

3. 插入元素

   数组元素在内存中是“紧挨着的”，它们之间没有空间再存放任何数据。如图 4-3 所示，如果想在数组中间插入一个元素，则需要将该元素之后的所有元素都向后移动一位，之后再把元素赋值给该索引。

   ![数组插入元素示例](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_insert_element.png)

   图 4-3  数组插入元素示例

   值得注意的是，由于数组的长度是固定的，因此插入一个元素必定会导致数组尾部元素“丢失”。我们将这个问题的解决方案留在“列表”章节中讨论。

   ```python
   def insert(nums: list[int], num: int, index: int):
       """在数组的索引 index 处插入元素 num"""
       # 把索引 index 以及之后的所有元素向后移动一位
       for i in range(len(nums) - 1, index, -1):
           nums[i] = nums[i - 1]
       # 将 num 赋给 index 处的元素
       nums[index] = num
   ```

4. 删除元素

   同理，如图 4-4 所示，若想删除索引i处的元素，则需要把索引 之后的元素都向前移动一位。

   ![数组删除元素示例](https://www.hello-algo.com/chapter_array_and_linkedlist/array.assets/array_remove_element.png)

   图 4-4  数组删除元素示例

   请注意，删除元素完成后，原先末尾的元素变得“无意义”了，所以我们无须特意去修改它。

   ```python
   def remove(nums: list[int], index: int):
       """删除索引 index 处的元素"""
       # 把索引 index 之后的所有元素向前移动一位
       for i in range(index, len(nums) - 1):
           nums[i] = nums[i + 1]
   ```

   总的来看，数组的插入与删除操作有以下缺点。

   - **时间复杂度高**：数组的插入和删除的平均时间复杂度均为O(n)，其中n为数组长度。
   - **丢失元素**：由于数组的长度不可变，因此在插入元素后，超出数组长度范围的元素会丢失。
   - **内存浪费**：我们可以初始化一个比较长的数组，只用前面一部分，这样在插入数据时，丢失的末尾元素都是“无意义”的，但这样做会造成部分内存空间浪费。

5. 遍历数组

   在大多数编程语言中，我们既可以通过索引遍历数组，也可以直接遍历获取数组中的每个元素：

   ```python
   def traverse(nums: list[int]):
       """遍历数组"""
       count = 0
       # 通过索引遍历数组
       for i in range(len(nums)):
           count += nums[i]
       # 直接遍历数组元素
       for num in nums:
           count += num
       # 同时遍历数据索引和元素
       for i, num in enumerate(nums):
           count += nums[i]
           count += num
   ```

6. 查找元素

   在数组中查找指定元素需要遍历数组，每轮判断元素值是否匹配，若匹配则输出对应索引。

   因为数组是线性数据结构，所以上述查找操作被称为“线性查找”。

   ```python
   def find(nums: list[int], target: int) -> int:
       """在数组中查找指定元素"""
       for i in range(len(nums)):
           if nums[i] == target:
               return i
       return -1
   ```

7. 扩容数组

   在复杂的系统环境中，程序难以保证数组之后的内存空间是可用的，从而无法安全地扩展数组容量。因此在大多数编程语言中，**数组的长度是不可变的**。

   如果我们希望扩容数组，则需重新建立一个更大的数组，然后把原数组元素依次复制到新数组。这是一个O(n)的操作，在数组很大的情况下非常耗时。代码如下所示：

   ```python
   def extend(nums: list[int], enlarge: int) -> list[int]:
       """扩展数组长度"""
       # 初始化一个扩展长度后的数组
       res = [0] * (len(nums) + enlarge)
       # 将原数组中的所有元素复制到新数组
       for i in range(len(nums)):
           res[i] = nums[i]
       # 返回扩展后的新数组
       return res
   ```

#### 4.1.2  数组的优点与局限性

数组存储在连续的内存空间内，且元素类型相同。这种做法包含丰富的先验信息，系统可以利用这些信息来优化数据结构的操作效率。

- **空间效率高**：数组为数据分配了连续的内存块，无须额外的结构开销。
- **支持随机访问**：数组允许在O(1)时间内访问任何元素。
- **缓存局部性**：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。

连续空间存储是一把双刃剑，其存在以下局限性。

- **插入与删除效率低**：当数组中元素较多时，插入与删除操作需要移动大量的元素。
- **长度不可变**：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。
- **空间浪费**：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。

#### 4.1.3  数组典型应用

数组是一种基础且常见的数据结构，既频繁应用在各类算法之中，也可用于实现各种复杂数据结构。

- **随机访问**：如果我们想随机抽取一些样本，那么可以用数组存储，并生成一个随机序列，根据索引实现随机抽样。
- **排序和搜索**：数组是排序和搜索算法最常用的数据结构。快速排序、归并排序、二分查找等都主要在数组上进行。
- **查找表**：当需要快速查找一个元素或其对应关系时，可以使用数组作为查找表。假如我们想实现字符到 ASCII 码的映射，则可以将字符的 ASCII 码值作为索引，对应的元素存放在数组中的对应位置。
- **机器学习**：神经网络中大量使用了向量、矩阵、张量之间的线性代数运算，这些数据都是以数组的形式构建的。数组是神经网络编程中最常使用的数据结构。
- **数据结构实现**：数组可以用于实现栈、队列、哈希表、堆、图等数据结构。例如，图的邻接矩阵表示实际上是一个二维数组。

#### Comment

![image-20250719174511179](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250719174511179.png)

### 4.2  链表

内存空间是所有程序的公共资源，在一个复杂的系统运行环境下，空闲的内存空间可能散落在内存各处。我们知道，存储数组的内存空间必须是连续的，而当数组非常大时，内存可能无法提供如此大的连续空间。此时链表的灵活性优势就体现出来了。

链表（linked list）是一种线性数据结构，其中的每个元素都是一个节点对象，各个节点通过“引用”相连接。引用记录了下一个节点的内存地址，通过它可以从当前节点访问到下一个节点。

链表的设计使得各个节点可以分散存储在内存各处，它们的内存地址无须连续。

![链表定义与存储方式](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_definition.png)

图 4-5  链表定义与存储方式

观察图 4-5 ，链表的组成单位是节点（node）对象。每个节点都包含两项数据：节点的“值”和指向下一节点的“引用”。

- 链表的首个节点被称为“头节点”，最后一个节点被称为“尾节点”。
- 尾节点指向的是“空”，它在 Java、C++ 和 Python 中分别被记为 `null`、`nullptr` 和 `None` 。
- 在 C、C++、Go 和 Rust 等支持指针的语言中，上述“引用”应被替换为“指针”。

如以下代码所示，链表节点 `ListNode` 除了包含值，还需额外保存一个引用（指针）。因此在相同数据量下，**链表比数组占用更多的内存空间**。

```python
class ListNode:
    """链表节点类"""
    def __init__(self, val: int):
        self.val: int = val               # 节点值
        self.next: ListNode | None = None # 指向下一节点的引用
```

#### 4.2.1  链表常用操作

1. 初始化链表

   建立链表分为两步，第一步是初始化各个节点对象，第二步是构建节点之间的引用关系。初始化完成后，我们就可以从链表的头节点出发，通过引用指向 `next` 依次访问所有节点。

   ```python
   # 初始化链表 1 -> 3 -> 2 -> 5 -> 4
   # 初始化各个节点
   n0 = ListNode(1)
   n1 = ListNode(3)
   n2 = ListNode(2)
   n3 = ListNode(5)
   n4 = ListNode(4)
   # 构建节点之间的引用
   n0.next = n1
   n1.next = n2
   n2.next = n3
   n3.next = n4
   ```

   数组整体是一个变量，比如数组 `nums` 包含元素 `nums[0]` 和 `nums[1]` 等，而链表是由多个独立的节点对象组成的。**我们通常将头节点当作链表的代称**，比如以上代码中的链表可记作链表 `n0` 。

2. 插入节点

   在链表中插入节点非常容易。如图 4-6 所示，假设我们想在相邻的两个节点 `n0` 和 `n1` 之间插入一个新节点 `P` ，**则只需改变两个节点引用（指针）即可**，时间复杂度为O(1)。

   相比之下，在数组中插入元素的时间复杂度为O(n)，在大数据量下的效率较低。

   ![链表插入节点示例](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_insert_node.png)

   图 4-6  链表插入节点示例

   ```python
   def insert(n0:ListNode,P:ListNode):
       P.next = n0.next
       n0.next = P
   ```

3. 删除节点

   如图 4-7 所示，在链表中删除节点也非常方便，**只需改变一个节点的引用（指针）即可**。

   请注意，尽管在删除操作完成后节点 `P` 仍然指向 `n1` ，但实际上遍历此链表已经无法访问到 `P` ，这意味着 `P` 已经不再属于该链表了。

   ![链表删除节点](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_remove_node.png)

   图 4-7  链表删除节点

   ```python
   def remove(n0: ListNode):
       """删除链表的节点 n0 之后的首个节点"""
       if not n0.next:
           return
       # n0 -> P -> n1
       P = n0.next
       n1 = P.next
       n0.next = n1
   ```

4. 访问节点

   **在链表中访问节点的效率较低**。如上一节所述，我们可以在O(1)时间下访问数组中的任意元素。链表则不然，程序需要从头节点出发，逐个向后遍历，直至找到目标节点。也就是说，访问链表的第i个节点需要循环i-1轮，时间复杂度为O(n) 。

   ```python
   def access(head: ListNode, index: int) -> ListNode | None:
       """访问链表中索引为 index 的节点"""
       for _ in range(index):
           if not head:
               return None
           head = head.next
       return head
   ```

5. 查找结点

   遍历链表，查找其中值为 `target` 的节点，输出该节点在链表中的索引。此过程也属于线性查找。代码如下所示：

   ```python
   def find(head: ListNode, target: int) -> int:
       """在链表中查找值为 target 的首个节点"""
       index = 0
       while head:
           if head.val == target:
               return index
           head = head.next
           index += 1
       return -1
   ```

#### 4.2.2  数组 vs. 链表

表 4-1 总结了数组和链表的各项特点并对比了操作效率。由于它们采用两种相反的存储策略，因此各种性质和操作效率也呈现对立的特点。

表 4-1  数组与链表的效率对比

|          | 数组                           | 链表           |
| :------- | :----------------------------- | -------------- |
| 存储方式 | 连续内存空间                   | 分散内存空间   |
| 容量扩展 | 长度不可变                     | 可灵活扩展     |
| 内存效率 | 元素占用内存少、但可能浪费空间 | 元素占用内存多 |
| 访问元素 | O(1)                           | O(n)           |
| 添加元素 | O(n)                           | O(1)           |
| 删除元素 | O(n)                           | O(1)           |

#### 4.2.3  常见链表类型

如图 4-8 所示，常见的链表类型包括三种。

- **单向链表**：即前面介绍的普通链表。单向链表的节点包含值和指向下一节点的引用两项数据。我们将首个节点称为头节点，将最后一个节点称为尾节点，尾节点指向空 `None` 。
- **环形链表**：如果我们令单向链表的尾节点指向头节点（首尾相接），则得到一个环形链表。在环形链表中，任意节点都可以视作头节点。
- **双向链表**：与单向链表相比，双向链表记录了两个方向的引用。双向链表的节点定义同时包含指向后继节点（下一个节点）和前驱节点（上一个节点）的引用（指针）。相较于单向链表，双向链表更具灵活性，可以朝两个方向遍历链表，但相应地也需要占用更多的内存空间。

```python
class ListNode:
    """双向链表节点类"""
    def __init__(self, val: int):
        self.val: int = val                # 节点值
        self.next: ListNode | None = None  # 指向后继节点的引用
        self.prev: ListNode | None = None  # 指向前驱节点的引用
```

![常见链表种类](https://www.hello-algo.com/chapter_array_and_linkedlist/linked_list.assets/linkedlist_common_types.png)

图 4-8  常见链表种类

#### 4.2.4  链表典型应用

单向链表通常用于实现栈、队列、哈希表和图等数据结构。

- **栈与队列**：当插入和删除操作都在链表的一端进行时，它表现的特性为先进后出，对应栈；当插入操作在链表的一端进行，删除操作在链表的另一端进行，它表现的特性为先进先出，对应队列。
- **哈希表**：链式地址是解决哈希冲突的主流方案之一，在该方案中，所有冲突的元素都会被放到一个链表中。
- **图**：邻接表是表示图的一种常用方式，其中图的每个顶点都与一个链表相关联，链表中的每个元素都代表与该顶点相连的其他顶点。

双向链表常用于需要快速查找前一个和后一个元素的场景。

- **高级数据结构**：比如在红黑树、B 树中，我们需要访问节点的父节点，这可以通过在节点中保存一个指向父节点的引用来实现，类似于双向链表。
- **浏览器历史**：在网页浏览器中，当用户点击前进或后退按钮时，浏览器需要知道用户访问过的前一个和后一个网页。双向链表的特性使得这种操作变得简单。
- **LRU 算法**：在缓存淘汰（LRU）算法中，我们需要快速找到最近最少使用的数据，以及支持快速添加和删除节点。这时候使用双向链表就非常合适。

环形链表常用于需要周期性操作的场景，比如操作系统的资源调度。

- **时间片轮转调度算法**：在操作系统中，时间片轮转调度算法是一种常见的 CPU 调度算法，它需要对一组进程进行循环。每个进程被赋予一个时间片，当时间片用完时，CPU 将切换到下一个进程。这种循环操作可以通过环形链表来实现。
- **数据缓冲区**：在某些数据缓冲区的实现中，也可能会使用环形链表。比如在音频、视频播放器中，数据流可能会被分成多个缓冲块并放入一个环形链表，以便实现无缝播放。

#### Comment

![image-20250719210234637](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250719210234637.png)

### 4.3  列表

列表（list）是一个抽象的数据结构概念，它表示元素的有序集合，支持元素访问、修改、添加、删除和遍历等操作，无须使用者考虑容量限制的问题。列表可以基于链表或数组实现。

- 链表天然可以看作一个列表，其支持元素增删查改操作，并且可以灵活动态扩容。
- 数组也支持元素增删查改，但由于其长度不可变，因此只能看作一个具有长度限制的列表。

当使用数组实现列表时，**长度不可变的性质会导致列表的实用性降低**。这是因为我们通常无法事先确定需要存储多少数据，从而难以选择合适的列表长度。若长度过小，则很可能无法满足使用需求；若长度过大，则会造成内存空间浪费。

为解决此问题，我们可以使用动态数组（dynamic array）来实现列表。它继承了数组的各项优点，并且可以在程序运行过程中进行动态扩容。

实际上，**许多编程语言中的标准库提供的列表是基于动态数组实现的**，例如 Python 中的 `list` 、Java 中的 `ArrayList` 、C++ 中的 `vector` 和 C# 中的 `List` 等。在接下来的讨论中，我们将把“列表”和“动态数组”视为等同的概念。

#### 4.3.1  列表常用操作

1. 初始化列表

   我们通常使用“无初始值”和“有初始值”这两种初始化方法：

   ```python
   # 初始化列表
   # 无初始值
   nums1: list[int] = []
   # 有初始值
   nums: list[int] = [1, 3, 2, 5, 4]
   ```

2. 访问元素

   列表本质上是数组，因此可以在O(1)时间内访问和更新元素，效率很高。

   ```python
   # 访问元素
   num: int = nums[1]  # 访问索引 1 处的元素
   
   # 更新元素
   nums[1] = 0    # 将索引 1 处的元素更新为 0
   ```

3. 插入和删除元素

   相较于数组，列表可以自由地添加与删除元素。在列表尾部添加元素的时间复杂度为O(1)，但插入和删除元素的效率仍与数组相同，时间复杂度为O(n)。

   ```python
   # 清空列表
   nums.clear()
   
   # 在尾部添加元素
   nums.append(1)
   nums.append(3)
   nums.append(2)
   nums.append(5)
   nums.append(4)
   
   # 在中间插入元素
   nums.insert(3, 6)  # 在索引 3 处插入数字 6
   
   # 删除元素
   nums.pop(3)        # 删除索引 3 处的元素
   ```

4. 遍历列表

   与数组一样，列表可以根据索引遍历，也可以直接遍历各元素。

   ```python
   # 通过索引遍历列表
   count = 0
   for i in range(len(nums)):
       count += nums[i]
   
   # 直接遍历列表元素
   for num in nums:
       count += num
   ```

5. 拼接列表

   给定一个新列表 `nums1` ，我们可以将其拼接到原列表的尾部。

   ```python
   # 拼接两个列表
   nums1: list[int] = [6, 8, 7, 10, 9]
   nums += nums1  # 将列表 nums1 拼接到 nums 之后
   ```

6. 排序列表

   完成列表排序后，我们便可以使用在数组类算法题中经常考查的“二分查找”和“双指针”算法。

   ```python
   # 排序列表
   nums.sort()  # 排序后，列表元素从小到大排列
   ```

#### 4.3.2  列表实现

许多编程语言内置了列表，例如 Java、C++、Python 等。它们的实现比较复杂，各个参数的设定也非常考究，例如初始容量、扩容倍数等。感兴趣的读者可以查阅源码进行学习。

为了加深对列表工作原理的理解，我们尝试实现一个简易版列表，包括以下三个重点设计。

- **初始容量**：选取一个合理的数组初始容量。在本示例中，我们选择 10 作为初始容量。
- **数量记录**：声明一个变量 `size` ，用于记录列表当前元素数量，并随着元素插入和删除实时更新。根据此变量，我们可以定位列表尾部，以及判断是否需要扩容。
- **扩容机制**：若插入元素时列表容量已满，则需要进行扩容。先根据扩容倍数创建一个更大的数组，再将当前数组的所有元素依次移动至新数组。在本示例中，我们规定每次将数组扩容至之前的 2 倍。

```python
class MyList:
    """列表类"""

    def __init__(self):
        """构造方法"""
        self._capacity: int = 10  # 列表容量
        self._arr: list[int] = [0] * self._capacity  # 数组（存储列表元素）
        self._size: int = 0  # 列表长度（当前元素数量）
        self._extend_ratio: int = 2  # 每次列表扩容的倍数

    def size(self) -> int:
        """获取列表长度（当前元素数量）"""
        return self._size

    def capacity(self) -> int:
        """获取列表容量"""
        return self._capacity

    def get(self, index: int) -> int:
        """访问元素"""
        # 索引如果越界，则抛出异常，下同
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        return self._arr[index]

    def set(self, num: int, index: int):
        """更新元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        self._arr[index] = num

    def add(self, num: int):
        """在尾部添加元素"""
        # 元素数量超出容量时，触发扩容机制
        if self.size() == self.capacity():
            self.extend_capacity()
        self._arr[self._size] = num
        self._size += 1

    def insert(self, num: int, index: int):
        """在中间插入元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        # 元素数量超出容量时，触发扩容机制
        if self._size == self.capacity():
            self.extend_capacity()
        # 将索引 index 以及之后的元素都向后移动一位
        for j in range(self._size - 1, index - 1, -1):
            self._arr[j + 1] = self._arr[j]
        self._arr[index] = num
        # 更新元素数量
        self._size += 1

    def remove(self, index: int) -> int:
        """删除元素"""
        if index < 0 or index >= self._size:
            raise IndexError("索引越界")
        num = self._arr[index]
        # 将索引 index 之后的元素都向前移动一位
        for j in range(index, self._size - 1):
            self._arr[j] = self._arr[j + 1]
        # 更新元素数量
        self._size -= 1
        # 返回被删除的元素
        return num

    def extend_capacity(self):
        """列表扩容"""
        # 新建一个长度为原数组 _extend_ratio 倍的新数组，并将原数组复制到新数组
        self._arr = self._arr + [0] * self.capacity() * (self._extend_ratio - 1)
        # 更新列表容量
        self._capacity = len(self._arr)

    def to_array(self) -> list[int]:
        """返回有效长度的列表"""
        return self._arr[: self._size]
```

#### Comment

在 Python 中使用加号（`+`）运算符拼接两个列表时，**时间复杂度为 O (n + m)**，其中 `n` 和 `m` 分别是两个列表的长度。

原因解析：

使用 `+` 拼接列表时，Python 会创建一个**新的列表**，并将两个原始列表中的所有元素依次复制到新列表中。这个过程需要遍历第一个列表的 `n` 个元素和第二个列表的 `m` 个元素，因此总操作次数与两个列表的总长度成正比，即时间复杂度为 O (n + m)。

![image-20250724143704223](C:\Users\zdz1411\AppData\Roaming\Typora\typora-user-images\image-20250724143704223.png)

### 4.4  内存与缓存 *

在本章的前两节中，我们探讨了数组和链表这两种基础且重要的数据结构，它们分别代表了“连续存储”和“分散存储”两种物理结构。

实际上，**物理结构在很大程度上决定了程序对内存和缓存的使用效率**，进而影响算法程序的整体性能。

#### 4.4.1  计算机存储设备

计算机中包括三种类型的存储设备：硬盘（hard disk）、内存（random-access memory, RAM）、缓存（cache memory）。表 4-2 展示了它们在计算机系统中的不同角色和性能特点。

表 4-2  计算机的存储设备

|                | 硬盘                                     | 内存                                   | 缓存                                              |
| :------------- | :--------------------------------------- | :------------------------------------- | ------------------------------------------------- |
| 用途           | 长期存储数据，包括操作系统、程序、文件等 | 临时存储当前运行的程序和正在处理的数据 | 存储经常访问的数据和指令，减少 CPU 访问内存的次数 |
| 易失性         | 断电后数据不会丢失                       | 断电后数据会丢失                       | 断电后数据会丢失                                  |
| 容量           | 较大，TB 级别                            | 较小，GB 级别                          | 非常小，MB 级别                                   |
| 速度           | 较慢，几百到几千 MB/s                    | 较快，几十 GB/s                        | 非常快，几十到几百 GB/s                           |
| 价格（人民币） | 较便宜，几毛到几元 / GB                  | 较贵，几十到几百元 / GB                | 非常贵，随 CPU 打包计价                           |

我们可以将计算机存储系统想象为图 4-9 所示的金字塔结构。越靠近金字塔顶端的存储设备的速度越快、容量越小、成本越高。这种多层级的设计并非偶然，而是计算机科学家和工程师们经过深思熟虑的结果。

- **硬盘难以被内存取代**。首先，内存中的数据在断电后会丢失，因此它不适合长期存储数据；其次，内存的成本是硬盘的几十倍，这使得它难以在消费者市场普及。
- **缓存的大容量和高速度难以兼得**。随着 L1、L2、L3 缓存的容量逐步增大，其物理尺寸会变大，与 CPU 核心之间的物理距离会变远，从而导致数据传输时间增加，元素访问延迟变高。在当前技术下，多层级的缓存结构是容量、速度和成本之间的最佳平衡点。

![计算机存储系统](https://www.hello-algo.com/chapter_array_and_linkedlist/ram_and_cache.assets/storage_pyramid.png)

图 4-9  计算机存储系统

> 计算机的存储层次结构体现了速度、容量和成本三者之间的精妙平衡。实际上，这种权衡普遍存在于所有工业领域，它要求我们在不同的优势和限制之间找到最佳平衡点。

总的来说，**硬盘用于长期存储大量数据，内存用于临时存储程序运行中正在处理的数据，而缓存则用于存储经常访问的数据和指令**，以提高程序运行效率。三者共同协作，确保计算机系统高效运行。

如图 4-10 所示，在程序运行时，数据会从硬盘中被读取到内存中，供 CPU 计算使用。缓存可以看作 CPU 的一部分，**它通过智能地从内存加载数据**，给 CPU 提供高速的数据读取，从而显著提升程序的执行效率，减少对较慢的内存的依赖。

![硬盘、内存和缓存之间的数据流通](https://www.hello-algo.com/chapter_array_and_linkedlist/ram_and_cache.assets/computer_storage_devices.png)

图 4-10  硬盘、内存和缓存之间的数据流通

#### 4.4.2  数据结构的内存效率

在内存空间利用方面，数组和链表各自具有优势和局限性。

一方面，**内存是有限的，且同一块内存不能被多个程序共享**，因此我们希望数据结构能够尽可能高效地利用空间。数组的元素紧密排列，不需要额外的空间来存储链表节点间的引用（指针），因此空间效率更高。然而，数组需要一次性分配足够的连续内存空间，这可能导致内存浪费，数组扩容也需要额外的时间和空间成本。相比之下，链表以“节点”为单位进行动态内存分配和回收，提供了更大的灵活性。

另一方面，在程序运行时，**随着反复申请与释放内存，空闲内存的碎片化程度会越来越高**，从而导致内存的利用效率降低。数组由于其连续的存储方式，相对不容易导致内存碎片化。相反，链表的元素是分散存储的，在频繁的插入与删除操作中，更容易导致内存碎片化。

#### 4.4.3  数据结构的缓存效率

缓存虽然在空间容量上远小于内存，但它比内存快得多，在程序执行速度上起着至关重要的作用。由于缓存的容量有限，只能存储一小部分频繁访问的数据，因此当 CPU 尝试访问的数据不在缓存中时，就会发生缓存未命中（cache miss），此时 CPU 不得不从速度较慢的内存中加载所需数据。

显然，**“缓存未命中”越少，CPU 读写数据的效率就越高**，程序性能也就越好。我们将 CPU 从缓存中成功获取数据的比例称为缓存命中率（cache hit rate），这个指标通常用来衡量缓存效率。

为了尽可能达到更高的效率，缓存会采取以下数据加载机制。

- **缓存行**：缓存不是单个字节地存储与加载数据，而是以缓存行为单位。相比于单个字节的传输，缓存行的传输形式更加高效。
- **预取机制**：处理器会尝试预测数据访问模式（例如顺序访问、固定步长跳跃访问等），并根据特定模式将数据加载至缓存之中，从而提升命中率。
- **空间局部性**：如果一个数据被访问，那么它附近的数据可能近期也会被访问。因此，缓存在加载某一数据时，也会加载其附近的数据，以提高命中率。
- **时间局部性**：如果一个数据被访问，那么它在不久的将来很可能再次被访问。缓存利用这一原理，通过保留最近访问过的数据来提高命中率。

实际上，**数组和链表对缓存的利用效率是不同的**，主要体现在以下几个方面。

- **占用空间**：链表元素比数组元素占用空间更多，导致缓存中容纳的有效数据量更少。
- **缓存行**：链表数据分散在内存各处，而缓存是“按行加载”的，因此加载到无效数据的比例更高。
- **预取机制**：数组比链表的数据访问模式更具“可预测性”，即系统更容易猜出即将被加载的数据。
- **空间局部性**：数组被存储在集中的内存空间中，因此被加载数据附近的数据更有可能即将被访问。

总体而言，**数组具有更高的缓存命中率，因此它在操作效率上通常优于链表**。这使得在解决算法问题时，基于数组实现的数据结构往往更受欢迎。

需要注意的是，**高缓存效率并不意味着数组在所有情况下都优于链表**。实际应用中选择哪种数据结构，应根据具体需求来决定。例如，数组和链表都可以实现“栈”数据结构（下一章会详细介绍），但它们适用于不同场景。

- 在做算法题时，我们会倾向于选择基于数组实现的栈，因为它提供了更高的操作效率和随机访问的能力，代价仅是需要预先为数组分配一定的内存空间。
- 如果数据量非常大、动态性很高、栈的预期大小难以估计，那么基于链表实现的栈更加合适。链表能够将大量数据分散存储于内存的不同部分，并且避免了数组扩容产生的额外开销。

### 4.5  小结

#### 1.重点回顾

- 数组和链表是两种基本的数据结构，分别代表数据在计算机内存中的两种存储方式：连续空间存储和分散空间存储。两者的特点呈现出互补的特性。
- 数组支持随机访问、占用内存较少；但插入和删除元素效率低，且初始化后长度不可变。
- 链表通过更改引用（指针）实现高效的节点插入与删除，且可以灵活调整长度；但节点访问效率低、占用内存较多。常见的链表类型包括单向链表、环形链表、双向链表。
- 列表是一种支持增删查改的元素有序集合，通常基于动态数组实现。它保留了数组的优势，同时可以灵活调整长度。
- 列表的出现大幅提高了数组的实用性，但可能导致部分内存空间浪费。
- 程序运行时，数据主要存储在内存中。数组可提供更高的内存空间效率，而链表则在内存使用上更加灵活。
- 缓存通过缓存行、预取机制以及空间局部性和时间局部性等数据加载机制，为 CPU 提供快速数据访问，显著提升程序的执行效率。
- 由于数组具有更高的缓存命中率，因此它通常比链表更高效。在选择数据结构时，应根据具体需求和场景做出恰当选择。

#### 2.Q&A

**Q**：数组存储在栈上和存储在堆上，对时间效率和空间效率是否有影响？

存储在栈上和堆上的数组都被存储在连续内存空间内，数据操作效率基本一致。然而，栈和堆具有各自的特点，从而导致以下不同点。

1. 分配和释放效率：栈是一块较小的内存，分配由编译器自动完成；而堆内存相对更大，可以在代码中动态分配，更容易碎片化。因此，堆上的分配和释放操作通常比栈上的慢。
2. 大小限制：栈内存相对较小，堆的大小一般受限于可用内存。因此堆更加适合存储大型数组。
3. 灵活性：栈上的数组的大小需要在编译时确定，而堆上的数组的大小可以在运行时动态确定。

**Q**：为什么数组要求相同类型的元素，而在链表中却没有强调相同类型呢？

链表由节点组成，节点之间通过引用（指针）连接，各个节点可以存储不同类型的数据，例如 `int`、`double`、`string`、`object` 等。

相对地，数组元素则必须是相同类型的，这样才能通过计算偏移量来获取对应元素位置。例如，数组同时包含 `int` 和 `long` 两种类型，单个元素分别占用 4 字节和 8 字节 ，此时就不能用以下公式计算偏移量了，因为数组中包含了两种“元素长度”。

```
# 元素内存地址 = 数组内存地址（首元素内存地址） + 元素长度 * 元素索引
```

**Q**：删除节点 `P` 后，是否需要把 `P.next` 设为 `None` 呢？

不修改 `P.next` 也可以。从该链表的角度看，从头节点遍历到尾节点已经不会遇到 `P` 了。这意味着节点 `P` 已经从链表中删除了，此时节点 `P` 指向哪里都不会对该链表产生影响。

从数据结构与算法（做题）的角度看，不断开没有关系，只要保证程序的逻辑是正确的就行。从标准库的角度看，断开更加安全、逻辑更加清晰。如果不断开，假设被删除节点未被正常回收，那么它会影响后继节点的内存回收。

**Q**：在链表中插入和删除操作的时间复杂度是O(1)。但是增删之前都需要O(n)的时间查找元素，那为什么时间复杂度不是O(n)呢？

如果是先查找元素、再删除元素，时间复杂度确实是O(n)。然而，链表的O(1)增删的优势可以在其他应用上得到体现。例如，双向队列适合使用链表实现，我们维护一个指针变量始终指向头节点、尾节点，每次插入与删除操作都是O(1)。

**Q**：图“链表定义与存储方式”中，浅蓝色的存储节点指针是占用一块内存地址吗？还是和节点值各占一半呢？

该示意图只是定性表示，定量表示需要根据具体情况进行分析。

- 不同类型的节点值占用的空间是不同的，比如 `int`、`long`、`double` 和实例对象等。
- 指针变量占用的内存空间大小根据所使用的操作系统及编译环境而定，大多为 8 字节或 4 字节。

**Q**：在列表末尾添加元素是否时时刻刻都为O(1)？

如果添加元素时超出列表长度，则需要先扩容列表再添加。系统会申请一块新的内存，并将原列表的所有元素搬运过去，这时候时间复杂度就会是O(n)。

**Q**：“列表的出现极大地提高了数组的实用性，但可能导致部分内存空间浪费”，这里的空间浪费是指额外增加的变量如容量、长度、扩容倍数所占的内存吗？

这里的空间浪费主要有两方面含义：一方面，列表都会设定一个初始长度，我们不一定需要用这么多；另一方面，为了防止频繁扩容，扩容一般会乘以一个系数，比如×1.5。这样一来，也会出现很多空位，我们通常不能完全填满它们。

**Q**：在 Python 中初始化 `n = [1, 2, 3]` 后，这 3 个元素的地址是相连的，但是初始化 `m = [2, 1, 3]` 会发现它们每个元素的 id 并不是连续的，而是分别跟 `n` 中的相同。这些元素的地址不连续，那么 `m` 还是数组吗？

假如把列表元素换成链表节点 `n = [n1, n2, n3, n4, n5]` ，通常情况下这 5 个节点对象也分散存储在内存各处。然而，给定一个列表索引，我们仍然可以在 时间内获取节点内存地址，从而访问到对应的节点。这是因为数组中存储的是节点的引用，而非节点本身。

与许多语言不同，Python 中的数字也被包装为对象，列表中存储的不是数字本身，而是对数字的引用。因此，我们会发现两个数组中的相同数字拥有同一个 id ，并且这些数字的内存地址无须连续。

**Q**：操作 `res = [[0]] * n` 生成了一个二维列表，其中每一个 `[0]` 都是独立的吗？

不是独立的。此二维列表中，所有的 `[0]` 实际上是同一个对象的引用。如果我们修改其中一个元素，会发现所有的对应元素都会随之改变。

如果希望二维列表中的每个 `[0]` 都是独立的，可以使用 `res = [[0] for _ in range(n)]` 来实现。这种方式的原理是初始化了n个独立的 `[0]` 列表对象。

**Q**：操作 `res = [0] * n` 生成了一个列表，其中每一个整数 0 都是独立的吗？

在该列表中，所有整数 0 都是同一个对象的引用。这是因为 Python 对小整数（通常是 -5 到 256）采用了缓存池机制，以便最大化对象复用，从而提升性能。

虽然它们指向同一个对象，但我们仍然可以独立修改列表中的每个元素，这是因为 Python 的整数是“不可变对象”。当我们修改某个元素时，实际上是切换为另一个对象的引用，而不是改变原有对象本身。

然而，当列表元素是“可变对象”时（例如列表、字典或类实例等），修改某个元素会直接改变该对象本身，所有引用该对象的元素都会产生相同变化。

> Python 的缓存池机制（也称为 “对象池” 或 “小整数缓存”）是一种**内存优化策略**，通过复用频繁使用的简单对象（如小整数、短字符串），减少内存开销和对象创建 / 销毁的效率损耗。
>
> 原理：对于一些使用频率极高的简单对象（如 `-5~256` 的整数、长度较短的字符串），Python 会在启动时提前创建这些对象并放入 “缓存池” 中。当程序再次需要使用这些对象时，不会重新创建新对象，而是直接复用缓存池中的已有对象（即多个变量指向同一个内存地址）。

